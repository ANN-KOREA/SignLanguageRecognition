{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook for loading and training models.\n",
    "Furthermore it provides simple documentation for different approaches used for training a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the command below to see command-completion on pressing `TAB`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "import tools\n",
    "import models.py as c_models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "# Ignore future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Root CSV files directory\n",
    "dirname = \"/home/datagroup/Videos/SL/output/csv/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation Stage\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tools.load(dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data\n",
    "Split the dataset up into the following segments:\n",
    "1. Training Data: 66%\n",
    "2. Test Data: 33%\n",
    "3. Validation Data: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [n[1] for n in data]\n",
    "labels = [n[0] for n in data]\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 347\n",
      "Training: 232 66.85878962536023\n",
      "Test: 115 33.14121037463977\n"
     ]
    }
   ],
   "source": [
    "# Display train data\n",
    "print(\"Total:\", len(labels))\n",
    "print(\"Training:\", len(y_train), len(y_train) / len(labels) * 100)\n",
    "print(\"Test:\", len(y_test), len(y_test) / len(labels) * 100)\n",
    "#print(\"Validation:\", len(y_val), len(y_val) / len(labels) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize (One Hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 1, 'hallo': 2, 'welt': 3, 'deutschland': 4}\n",
      "[[0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import tools\n",
    "tokenizer = tools.tokenize(dirname)\n",
    "print(tokenizer.word_index)\n",
    "encoded_train=tokenizer.texts_to_sequences([y_train])[0]\n",
    "encoded_test=tokenizer.texts_to_sequences([y_test])[0]\n",
    "one_hot_train = to_categorical(encoded_train)\n",
    "one_hot_test = to_categorical(encoded_test)\n",
    "print(one_hot_train)\n",
    "train = (x_train, one_hot_train)\n",
    "test = (x_test, one_hot_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras.models' has no attribute 'build_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-32c31d24726d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras.models' has no attribute 'build_model'"
     ]
    }
   ],
   "source": [
    "model = models.build_model();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondaec67d936d9664dd4875ec3c30ec1cb02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
