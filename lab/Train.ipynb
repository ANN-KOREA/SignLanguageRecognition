{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook for loading and training models.\n",
    "Furthermore it provides simple documentation for different approaches used for training a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the command below to see command-completion on pressing `TAB`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datagroup/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/datagroup/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/datagroup/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/datagroup/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/datagroup/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/datagroup/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import warnings\n",
    "import tools\n",
    "import models as c_models\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "# Ignore future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Root CSV files directory\n",
    "dirname = \"/home/datagroup/Videos/SL/output/csv/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation Stage\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>face_x</th>\n",
       "      <th>face_y</th>\n",
       "      <th>landmark_x_1</th>\n",
       "      <th>landmark_y_1</th>\n",
       "      <th>landmark_x_2</th>\n",
       "      <th>landmark_y_2</th>\n",
       "      <th>landmark_x_3</th>\n",
       "      <th>landmark_y_3</th>\n",
       "      <th>landmark_x_4</th>\n",
       "      <th>landmark_y_4</th>\n",
       "      <th>...</th>\n",
       "      <th>landmark_x_38</th>\n",
       "      <th>landmark_y_38</th>\n",
       "      <th>landmark_x_39</th>\n",
       "      <th>landmark_y_39</th>\n",
       "      <th>landmark_x_40</th>\n",
       "      <th>landmark_y_40</th>\n",
       "      <th>landmark_x_41</th>\n",
       "      <th>landmark_y_41</th>\n",
       "      <th>landmark_x_42</th>\n",
       "      <th>landmark_y_42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.423129</td>\n",
       "      <td>0.299152</td>\n",
       "      <td>0.165766</td>\n",
       "      <td>0.308951</td>\n",
       "      <td>0.175622</td>\n",
       "      <td>0.313200</td>\n",
       "      <td>0.183943</td>\n",
       "      <td>0.313322</td>\n",
       "      <td>0.190281</td>\n",
       "      <td>0.314959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464880</td>\n",
       "      <td>0.734882</td>\n",
       "      <td>0.481533</td>\n",
       "      <td>0.667846</td>\n",
       "      <td>0.480131</td>\n",
       "      <td>0.681474</td>\n",
       "      <td>0.476105</td>\n",
       "      <td>0.712190</td>\n",
       "      <td>0.472616</td>\n",
       "      <td>0.733929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.011926</td>\n",
       "      <td>0.005767</td>\n",
       "      <td>0.195172</td>\n",
       "      <td>0.342159</td>\n",
       "      <td>0.198999</td>\n",
       "      <td>0.345818</td>\n",
       "      <td>0.204568</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.209548</td>\n",
       "      <td>0.345273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105641</td>\n",
       "      <td>0.040387</td>\n",
       "      <td>0.146333</td>\n",
       "      <td>0.046403</td>\n",
       "      <td>0.136060</td>\n",
       "      <td>0.041896</td>\n",
       "      <td>0.130853</td>\n",
       "      <td>0.045907</td>\n",
       "      <td>0.127918</td>\n",
       "      <td>0.049162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.403872</td>\n",
       "      <td>0.286105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349456</td>\n",
       "      <td>0.695250</td>\n",
       "      <td>0.319757</td>\n",
       "      <td>0.631866</td>\n",
       "      <td>0.330062</td>\n",
       "      <td>0.652155</td>\n",
       "      <td>0.332186</td>\n",
       "      <td>0.670832</td>\n",
       "      <td>0.331810</td>\n",
       "      <td>0.688324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.414330</td>\n",
       "      <td>0.294871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352188</td>\n",
       "      <td>0.715104</td>\n",
       "      <td>0.322756</td>\n",
       "      <td>0.634509</td>\n",
       "      <td>0.332311</td>\n",
       "      <td>0.655918</td>\n",
       "      <td>0.334262</td>\n",
       "      <td>0.684355</td>\n",
       "      <td>0.334761</td>\n",
       "      <td>0.708868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.424998</td>\n",
       "      <td>0.298880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522606</td>\n",
       "      <td>0.717050</td>\n",
       "      <td>0.584762</td>\n",
       "      <td>0.657085</td>\n",
       "      <td>0.572692</td>\n",
       "      <td>0.657265</td>\n",
       "      <td>0.559502</td>\n",
       "      <td>0.693566</td>\n",
       "      <td>0.553065</td>\n",
       "      <td>0.712975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.430079</td>\n",
       "      <td>0.302729</td>\n",
       "      <td>0.312071</td>\n",
       "      <td>0.606342</td>\n",
       "      <td>0.349289</td>\n",
       "      <td>0.636691</td>\n",
       "      <td>0.373045</td>\n",
       "      <td>0.654049</td>\n",
       "      <td>0.391925</td>\n",
       "      <td>0.661954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530460</td>\n",
       "      <td>0.748390</td>\n",
       "      <td>0.589919</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>0.578837</td>\n",
       "      <td>0.691057</td>\n",
       "      <td>0.566640</td>\n",
       "      <td>0.726587</td>\n",
       "      <td>0.555823</td>\n",
       "      <td>0.745653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.441718</td>\n",
       "      <td>0.312287</td>\n",
       "      <td>0.618617</td>\n",
       "      <td>0.886661</td>\n",
       "      <td>0.578861</td>\n",
       "      <td>0.883760</td>\n",
       "      <td>0.563470</td>\n",
       "      <td>0.878666</td>\n",
       "      <td>0.549722</td>\n",
       "      <td>0.858838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569689</td>\n",
       "      <td>0.798616</td>\n",
       "      <td>0.590473</td>\n",
       "      <td>0.745866</td>\n",
       "      <td>0.586751</td>\n",
       "      <td>0.750975</td>\n",
       "      <td>0.587936</td>\n",
       "      <td>0.785609</td>\n",
       "      <td>0.587621</td>\n",
       "      <td>0.813824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          face_x     face_y  landmark_x_1  landmark_y_1  landmark_x_2  \\\n",
       "count  54.000000  54.000000     54.000000     54.000000     54.000000   \n",
       "mean    0.423129   0.299152      0.165766      0.308951      0.175622   \n",
       "std     0.011926   0.005767      0.195172      0.342159      0.198999   \n",
       "min     0.403872   0.286105      0.000000      0.000000      0.000000   \n",
       "25%     0.414330   0.294871      0.000000      0.000000      0.000000   \n",
       "50%     0.424998   0.298880      0.000000      0.000000      0.000000   \n",
       "75%     0.430079   0.302729      0.312071      0.606342      0.349289   \n",
       "max     0.441718   0.312287      0.618617      0.886661      0.578861   \n",
       "\n",
       "       landmark_y_2  landmark_x_3  landmark_y_3  landmark_x_4  landmark_y_4  \\\n",
       "count     54.000000     54.000000     54.000000     54.000000     54.000000   \n",
       "mean       0.313200      0.183943      0.313322      0.190281      0.314959   \n",
       "std        0.345818      0.204568      0.344697      0.209548      0.345273   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.636691      0.373045      0.654049      0.391925      0.661954   \n",
       "max        0.883760      0.563470      0.878666      0.549722      0.858838   \n",
       "\n",
       "       ...  landmark_x_38  landmark_y_38  landmark_x_39  landmark_y_39  \\\n",
       "count  ...       5.000000       5.000000       5.000000       5.000000   \n",
       "mean   ...       0.464880       0.734882       0.481533       0.667846   \n",
       "std    ...       0.105641       0.040387       0.146333       0.046403   \n",
       "min    ...       0.349456       0.695250       0.319757       0.631866   \n",
       "25%    ...       0.352188       0.715104       0.322756       0.634509   \n",
       "50%    ...       0.522606       0.717050       0.584762       0.657085   \n",
       "75%    ...       0.530460       0.748390       0.589919       0.669903   \n",
       "max    ...       0.569689       0.798616       0.590473       0.745866   \n",
       "\n",
       "       landmark_x_40  landmark_y_40  landmark_x_41  landmark_y_41  \\\n",
       "count       5.000000       5.000000       5.000000       5.000000   \n",
       "mean        0.480131       0.681474       0.476105       0.712190   \n",
       "std         0.136060       0.041896       0.130853       0.045907   \n",
       "min         0.330062       0.652155       0.332186       0.670832   \n",
       "25%         0.332311       0.655918       0.334262       0.684355   \n",
       "50%         0.572692       0.657265       0.559502       0.693566   \n",
       "75%         0.578837       0.691057       0.566640       0.726587   \n",
       "max         0.586751       0.750975       0.587936       0.785609   \n",
       "\n",
       "       landmark_x_42  landmark_y_42  \n",
       "count       5.000000       5.000000  \n",
       "mean        0.472616       0.733929  \n",
       "std         0.127918       0.049162  \n",
       "min         0.331810       0.688324  \n",
       "25%         0.334761       0.708868  \n",
       "50%         0.553065       0.712975  \n",
       "75%         0.555823       0.745653  \n",
       "max         0.587621       0.813824  \n",
       "\n",
       "[8 rows x 86 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listfile = os.listdir(dirname)\n",
    "contents = []\n",
    "for wordname in listfile:\n",
    "    if wordname == \".DS_Store\":\n",
    "        continue\n",
    "    for csv in os.listdir(dirname + wordname):\n",
    "        filepath = os.path.join(dirname, wordname, csv)\n",
    "        content = pd.read_csv(filepath, sep=';')\n",
    "        content = content.reindex(list(range(0, 100)))\n",
    "        for i in range(55, 100):\n",
    "            content = content.append(pd.Series(), ignore_index=True)\n",
    "        content.fillna(0.0)\n",
    "        contents.append((wordname, content))\n",
    "data = contents\n",
    "contents[0][1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize\n",
    "For training it's required to extend/reduce every dataset to n frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "extend() takes exactly one argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4ca4c3c8788c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: extend() takes exactly one argument (0 given)"
     ]
    }
   ],
   "source": [
    "# Frame count\n",
    "frames = 100\n",
    "for i in range(0, 100):\n",
    "    data.extend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data\n",
    "Split the dataset up into the following segments:\n",
    "1. Training Data: 66%\n",
    "2. Test Data: 33%\n",
    "3. Validation Data: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [n[1] for n in data]\n",
    "labels = [n[0] for n in data]\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 347\n",
      "Training: 232 66.85878962536023\n",
      "Test: 115 33.14121037463977\n"
     ]
    }
   ],
   "source": [
    "# Display train data\n",
    "print(\"Total:\", len(labels))\n",
    "print(\"Training:\", len(y_train), len(y_train) / len(labels) * 100)\n",
    "print(\"Test:\", len(y_test), len(y_test) / len(labels) * 100)\n",
    "#print(\"Validation:\", len(y_val), len(y_val) / len(labels) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize (One Hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 1, 'hallo': 2, 'welt': 3, 'deutschland': 4}\n",
      "[[0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import tools\n",
    "tokenizer = tools.tokenize(dirname)\n",
    "print(tokenizer.word_index)\n",
    "encoded_train=tokenizer.texts_to_sequences([y_train])[0]\n",
    "encoded_test=tokenizer.texts_to_sequences([y_test])[0]\n",
    "y_train = to_categorical(encoded_train)\n",
    "y_test = to_categorical(encoded_test)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/datagroup/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = c_models.build_model();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_input to have 3 dimensions, but got array with shape (145, 86)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-2e8b52f73f49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)\u001b[0m\n\u001b[1;32m   2380\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2382\u001b[0;31m         exception_prefix='input')\n\u001b[0m\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    351\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_input to have 3 dimensions, but got array with shape (145, 86)"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,epochs=100,batch_size=32,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondaec67d936d9664dd4875ec3c30ec1cb02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
