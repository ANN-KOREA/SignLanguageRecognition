{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook for loading and training models.\n",
    "Furthermore it provides simple documentation for different approaches used for training a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the command below to see command-completion on pressing `TAB`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import warnings\n",
    "import tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "\n",
    "# Ignore future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Root CSV files directory\n",
    "dirname = \"./data/\"  \n",
    "\n",
    "# Constant frame count.\n",
    "frames = 100\n",
    "\n",
    "\n",
    "#Preparation Stage - Load data and normalize\n",
    "listfile = os.listdir(dirname)\n",
    "data = []\n",
    "for wordname in listfile:\n",
    "    if wordname == \".DS_Store\":\n",
    "        continue\n",
    "    for csv in os.listdir(dirname + wordname):\n",
    "        filepath = os.path.join(dirname, wordname, csv)\n",
    "        content = pd.read_csv(filepath, sep=';')\n",
    "        content = content.reindex(list(range(0, frames)), fill_value=0.0)\n",
    "        content.fillna(0.0, inplace = True) \n",
    "        data.append((wordname, content))\n",
    "        \n",
    "#Split data 60-20-20\n",
    "\n",
    "features = [n[1] for n in data]\n",
    "features = [f.to_numpy() for f in features]\n",
    "labels = [n[0] for n in data]\n",
    "x_train, x_val, y_train, y_val = train_test_split(features, labels, test_size=0.40, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.50, random_state=42)\n",
    "\n",
    "#Enumerate\n",
    "def printCountDataSets(dataset):\n",
    "    wortCounter = []\n",
    "    #Liste mit einmaligen Labels erstellen\n",
    "    labels = sorted(set(dataset), key=dataset.index)\n",
    "    #Liste nochmal Alphabetisch sortieren\n",
    "    labels = sorted(labels)\n",
    "    for label in labels:\n",
    "        wortCounter.append(0)\n",
    "    for row in dataset:\n",
    "        for i in range(len(labels)):\n",
    "            if str(labels[i]).startswith(row):\n",
    "                wortCounter[i] += 1\n",
    "    for i in range(len(labels)):\n",
    "        print(labels[i], ': ', wortCounter[i], end =\";  \")\n",
    "    print(' ')        \n",
    "    \n",
    "print('Amount Datasets by word total:')\n",
    "printCountDataSets(labels)\n",
    "print('')\n",
    "\n",
    "print('Amount Datasets by word training:')\n",
    "printCountDataSets(y_train)\n",
    "print('')\n",
    "\n",
    "print('Amount Datasets by word validiation:')\n",
    "printCountDataSets(y_val)\n",
    "print('')\n",
    "\n",
    "print('Amount Datasets by word test:')\n",
    "printCountDataSets(y_test)\n",
    "print('')\n",
    "\n",
    "\n",
    "# Display data distribution\n",
    "print('Distribution of data:')\n",
    "print(\"Amount total:\", len(labels))\n",
    "print(\"Amount training:\", len(y_train))\n",
    "print(\"Amount validiation:\", len(y_val))\n",
    "print(\"Amount test:\", len(y_test))\n",
    "print('')\n",
    "\n",
    "#Tokenize (One Hot)\n",
    "tokenizer = tools.tokenize(dirname)\n",
    "print('Tokens:')\n",
    "print(tokenizer.word_index)\n",
    "print('')\n",
    "with open('tokens_json.txt', 'w') as outfile:\n",
    "    outfile.write(tokenizer.to_json())\n",
    "\n",
    "encoded_train=tokenizer.texts_to_sequences([y_train])[0]\n",
    "encoded_val=tokenizer.texts_to_sequences([y_val])[0]\n",
    "encoded_test=tokenizer.texts_to_sequences([y_test])[0]\n",
    "\n",
    "y_train = to_categorical(encoded_train)\n",
    "y_val = to_categorical(encoded_val)\n",
    "y_test = to_categorical(encoded_test)\n",
    "\n",
    "print('Categories in OneHot anotation:')\n",
    "print(y_train)\n",
    "print('')\n",
    "# Making numpy arrays\n",
    "x_train=np.array(x_train)\n",
    "y_train=np.array(y_train)\n",
    "x_val=np.array(x_val)\n",
    "y_val=np.array(y_val)\n",
    "x_test=np.array(x_test)\n",
    "y_test=np.array(y_test)\n",
    "\n",
    "print('Dataset coordinate Values:')\n",
    "print(x_train)\n",
    "print('')\n",
    "\n",
    "#import winsound\n",
    "#def finished(num):\n",
    "#    frequency = 2000  # Set Frequency To 2500 Hertz\n",
    "#    duration = 500  # Set Duration To 1000 ms == 1 second\n",
    "#    for i in range(0, num):\n",
    "#        winsound.Beep(frequency, duration)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Stage\n",
    "Configure the model and train it.\n",
    "\n",
    "Metrics:\n",
    "<div float=\"right\">\n",
    "    <img src=\"assets/accuracy.png\" width=\"400\"> \n",
    "    <img src=\"assets/precision_recall_formula.png\" width=\"400\">\n",
    "</div>\n",
    "<img src=\"assets/precision_recall.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"color:blue\"> Hyperparametertuned LSTM </span>\n",
    "##### Here it is necessary to install the Keras-Tuner Module by executing:\n",
    "#####  <span style=\"color:green\"> via Conda:</span>\n",
    "conda install -c conda-forge keras-tuner\n",
    "#####  <span style=\"color:green\"> for pip:</span>\n",
    "pip install keras-tuner\n",
    "\n",
    "Right now there are three different builds we are testing:\n",
    "- classic LSTM\n",
    "- CuDNNLSTM\n",
    "- bidriectional LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.tuners import Hyperband\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from time import time, strftime\n",
    "\n",
    "\n",
    "starttime= strftime(\"%Y_%m_%d_%H%M%S\")\n",
    "LOG_DIR = \"C:\\ML\\Optimization_\"f\"{starttime}\" #<-In Windows below Log_dir Path will maybe be too long for Windows to handle, so use a shorter path like this here\n",
    "#LOG_DIR = \"./Optimization_\"f\"{starttime}\" # LOG_DIR holds json files with information and a model of each single trial\n",
    "\n",
    "def build_model_lstm(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(layers.LSTM(hp.Int(\"LSTM_input\", min_value =64, max_value=256,step=64, default=64), #kerastuner will randomly choose a value for nodes between 128 and 256 in steps of 64\n",
    "                            return_sequences=True,\n",
    "                            input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    \n",
    "    for i in range(hp.Int(\"n_layers\" , 1, 3)):    #number of layers ramdom between 1 an 3\n",
    "        model.add(layers.LSTM(hp.Int(f\"LSTM_{i}_units\", min_value =64, max_value=256,step=64, default=64),return_sequences=True))\n",
    "    \n",
    "    model.add(layers.LSTM(hp.Int(f\"LSTM_End\", min_value =32, max_value=128,step=32, default=32)))\n",
    "    model.add(layers.Dense(12, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  #optimizer=hp.Choice('optimizer',values=['Adam','RMSprop','SGD']),\n",
    "                  optimizer=hp.Choice('optimizer',values=['Adagrad','Adamax','Adam','RMSprop']),\n",
    "                  metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    model.summary()\n",
    "    print(model.optimizer.get_config()[\"name\"])\n",
    "    print('')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def build_model_CuDNNLSTM(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "\n",
    "    \n",
    "    model.add(tf.compat.v1.keras.layers.CuDNNLSTM(hp.Int(\"LSTM_input\", min_value =64, max_value=256,step=64, default=64), #kerastuner will randomly choose a value for nodes between 128 and 256 in steps of 64\n",
    "                            return_sequences=True,\n",
    "                            input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    \n",
    "    for i in range(hp.Int(\"n_layers\" , 1, 3)):    #number of layers ramdom between 1 an 3\n",
    "        model.add(tf.compat.v1.keras.layers.CuDNNLSTM(hp.Int(f\"LSTM_{i}_units\", min_value =64, max_value=256,step=64, default=64),return_sequences=True))\n",
    "    \n",
    "    model.add(tf.compat.v1.keras.layers.CuDNNLSTM(hp.Int(f\"LSTM_End\", min_value =32, max_value=128,step=32, default=32)))\n",
    "    model.add(layers.Dense(12, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  #optimizer=hp.Choice('optimizer',values=['Adam','RMSprop','SGD']),\n",
    "                  optimizer=hp.Choice('optimizer',values=['Adagrad','Adamax','Adam','RMSprop']),\n",
    "                  metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    model.summary()\n",
    "    print(model.optimizer.get_config()[\"name\"])\n",
    "    print('')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def build_model_bdlstm(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(layers.LSTM(hp.Int(\"LSTM_input\", min_value =64, max_value=256,step=64, default=64),\n",
    "                                        return_sequences=True),\n",
    "                                        input_shape=(100, 86)))\n",
    "    \n",
    "    for i in range(hp.Int(\"n_layers\" , 1, 3)):    #number of layers ramdom between 1 an 3\n",
    "        model.add(layers.Bidirectional(layers.LSTM(hp.Int(f\"LSTM_{i}_units\", min_value =64, max_value=256,step=64, default=64),return_sequences=True)))\n",
    "    \n",
    "    model.add(layers.Bidirectional(layers.LSTM(hp.Int(f\"LSTM_End\", min_value =32, max_value=128,step=32, default=32))))\n",
    "    model.add(layers.Dense(12, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=hp.Choice('optimizer',values=['Adagrad','Adamax','Adam','RMSprop']),\n",
    "                  metrics=['accuracy']) \n",
    "    model.summary()\n",
    "    print(model.optimizer.get_config()[\"name\"])\n",
    "    print('')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   <span style=\"color:red\">Necesarry only in case of using Nvidia GPU  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "print(\"Num GPUs:\", len(physical_devices)) \n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Keras-Tuner Approaches\n",
    "### 1 - RandomSearch\n",
    "Parameter of variables are ranomly used (number of layers, number of nodes) and \"best\" model is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner  = RandomSearch(\n",
    "    build_model_CuDNNLSTM,     #Function to use search in... See different builds above\n",
    "    objective = \"val_accuracy\",  #Chooses \"best model\" looking for highest value of val_accuracy\n",
    "    max_trials = 30,       # Number of different combinations tried Nodes and layers\n",
    "    executions_per_trial = 1, \n",
    "    directory = LOG_DIR,\n",
    "    project_name='SignLagnuageModelOptimization'\n",
    "    )\n",
    "\n",
    "#tuner.search_space_summary()\n",
    "\n",
    "tuner.search(x=x_train,      #syntax just like in fit\n",
    "                y= y_train,\n",
    "            epochs=200,\n",
    "            batch_size=32,\n",
    "            validation_data=(x_val,y_val),\n",
    "            verbose=2\n",
    "            )\n",
    "\n",
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.results_summary())\n",
    "\n",
    "finished(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Hyperband\n",
    "Variation of RandomSearch http://jmlr.org/papers/volume18/16-558/16-558.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner  = Hyperband(\n",
    "    build_model,\n",
    "    objective = \"val_accuracy\",\n",
    "    hyperband_iterations=2,\n",
    "    max_epochs=150,\n",
    "    directory = LOG_DIR,\n",
    "    project_name='SignLagnuageModelOptimization'\n",
    "    )\n",
    "\n",
    "#tuner.search_space_summary()\n",
    "\n",
    "tuner.search(x=x_train, \n",
    "            y= y_train,\n",
    "            batch_size=32,\n",
    "            validation_data=(x_val,y_val))\n",
    "\n",
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.results_summary())\n",
    "\n",
    "finished(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 100, 128)          110080    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 100, 64)           49408     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                1164      \n",
      "=================================================================\n",
      "Total params: 222,476\n",
      "Trainable params: 222,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Laut Randomsearch bestes Model am 23.06.2020\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.LSTM(128, return_sequences=True,\n",
    "               input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(layers.LSTM(64, return_sequences=True)) \n",
    "model.add(layers.LSTM(96))  \n",
    "model.add(layers.Dense(12, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "model.summary()\n",
    "\n",
    "history=model.fit(x_train,y_train,epochs=170,validation_data=(x_val,y_val),shuffle=False,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export tuner object into pickle file\n",
    "so it can be used in other scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"tuner_\"f\"{starttime}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tuner, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get best Trial from Tuner Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "bestmodel= tuner.hypermodel.build(best_hp)\n",
    "\n",
    "bestmodel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14/14 - 1s - loss: 2.4135 - accuracy: 0.1244 - precision_2: 0.5000 - recall_2: 0.0070 - val_loss: 2.2545 - val_accuracy: 0.1690 - val_precision_2: 0.2727 - val_recall_2: 0.0211\n",
      "Epoch 2/200\n",
      "14/14 - 0s - loss: 2.1473 - accuracy: 0.2042 - precision_2: 0.5385 - recall_2: 0.0329 - val_loss: 1.9987 - val_accuracy: 0.1620 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 3/200\n",
      "14/14 - 0s - loss: 1.9705 - accuracy: 0.2254 - precision_2: 0.6667 - recall_2: 0.0047 - val_loss: 1.9349 - val_accuracy: 0.2324 - val_precision_2: 0.3333 - val_recall_2: 0.0211\n",
      "Epoch 4/200\n",
      "14/14 - 0s - loss: 1.8903 - accuracy: 0.2324 - precision_2: 0.4762 - recall_2: 0.0235 - val_loss: 1.9650 - val_accuracy: 0.2254 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 5/200\n",
      "14/14 - 0s - loss: 1.8208 - accuracy: 0.2559 - precision_2: 0.5682 - recall_2: 0.0587 - val_loss: 1.8764 - val_accuracy: 0.2324 - val_precision_2: 0.3750 - val_recall_2: 0.0211\n",
      "Epoch 6/200\n",
      "14/14 - 0s - loss: 1.7582 - accuracy: 0.2723 - precision_2: 0.6216 - recall_2: 0.0540 - val_loss: 1.8943 - val_accuracy: 0.2535 - val_precision_2: 0.3636 - val_recall_2: 0.0282\n",
      "Epoch 7/200\n",
      "14/14 - 0s - loss: 1.7663 - accuracy: 0.2817 - precision_2: 0.7059 - recall_2: 0.0563 - val_loss: 1.8889 - val_accuracy: 0.1761 - val_precision_2: 0.6000 - val_recall_2: 0.0211\n",
      "Epoch 8/200\n",
      "14/14 - 0s - loss: 1.7520 - accuracy: 0.2817 - precision_2: 0.6458 - recall_2: 0.0728 - val_loss: 1.8104 - val_accuracy: 0.2606 - val_precision_2: 0.3333 - val_recall_2: 0.0282\n",
      "Epoch 9/200\n",
      "14/14 - 0s - loss: 1.6980 - accuracy: 0.3075 - precision_2: 0.6591 - recall_2: 0.0681 - val_loss: 1.8360 - val_accuracy: 0.2324 - val_precision_2: 0.2500 - val_recall_2: 0.0211\n",
      "Epoch 10/200\n",
      "14/14 - 0s - loss: 1.6685 - accuracy: 0.3286 - precision_2: 0.6531 - recall_2: 0.0751 - val_loss: 1.8421 - val_accuracy: 0.2465 - val_precision_2: 0.4615 - val_recall_2: 0.0423\n",
      "Epoch 11/200\n",
      "14/14 - 0s - loss: 1.6552 - accuracy: 0.3521 - precision_2: 0.5932 - recall_2: 0.0822 - val_loss: 1.8136 - val_accuracy: 0.2606 - val_precision_2: 0.4615 - val_recall_2: 0.0423\n",
      "Epoch 12/200\n",
      "14/14 - 0s - loss: 1.5814 - accuracy: 0.3685 - precision_2: 0.6790 - recall_2: 0.1291 - val_loss: 1.7564 - val_accuracy: 0.2817 - val_precision_2: 0.3750 - val_recall_2: 0.0211\n",
      "Epoch 13/200\n",
      "14/14 - 0s - loss: 1.5805 - accuracy: 0.3944 - precision_2: 0.7321 - recall_2: 0.0962 - val_loss: 1.7104 - val_accuracy: 0.3169 - val_precision_2: 0.4706 - val_recall_2: 0.0563\n",
      "Epoch 14/200\n",
      "14/14 - 0s - loss: 1.6211 - accuracy: 0.3685 - precision_2: 0.6279 - recall_2: 0.1268 - val_loss: 1.9187 - val_accuracy: 0.2535 - val_precision_2: 0.3077 - val_recall_2: 0.0282\n",
      "Epoch 15/200\n",
      "14/14 - 0s - loss: 1.6400 - accuracy: 0.3192 - precision_2: 0.5862 - recall_2: 0.0798 - val_loss: 1.8002 - val_accuracy: 0.2254 - val_precision_2: 0.5000 - val_recall_2: 0.0493\n",
      "Epoch 16/200\n",
      "14/14 - 0s - loss: 1.5185 - accuracy: 0.3920 - precision_2: 0.7167 - recall_2: 0.1009 - val_loss: 1.6898 - val_accuracy: 0.4296 - val_precision_2: 0.5000 - val_recall_2: 0.0704\n",
      "Epoch 17/200\n",
      "14/14 - 0s - loss: 1.4314 - accuracy: 0.4437 - precision_2: 0.7308 - recall_2: 0.1338 - val_loss: 1.5906 - val_accuracy: 0.4437 - val_precision_2: 0.6190 - val_recall_2: 0.1831\n",
      "Epoch 18/200\n",
      "14/14 - 0s - loss: 1.2616 - accuracy: 0.5141 - precision_2: 0.7014 - recall_2: 0.2371 - val_loss: 2.7961 - val_accuracy: 0.1972 - val_precision_2: 0.2923 - val_recall_2: 0.1338\n",
      "Epoch 19/200\n",
      "14/14 - 0s - loss: 2.0032 - accuracy: 0.2653 - precision_2: 0.4741 - recall_2: 0.1291 - val_loss: 1.7733 - val_accuracy: 0.2887 - val_precision_2: 0.6190 - val_recall_2: 0.0915\n",
      "Epoch 20/200\n",
      "14/14 - 0s - loss: 1.5275 - accuracy: 0.3357 - precision_2: 0.5745 - recall_2: 0.0634 - val_loss: 1.7473 - val_accuracy: 0.3169 - val_precision_2: 0.5000 - val_recall_2: 0.0915\n",
      "Epoch 21/200\n",
      "14/14 - 0s - loss: 1.4811 - accuracy: 0.4319 - precision_2: 0.6479 - recall_2: 0.1080 - val_loss: 1.8405 - val_accuracy: 0.2958 - val_precision_2: 0.2821 - val_recall_2: 0.0775\n",
      "Epoch 22/200\n",
      "14/14 - 0s - loss: 1.4571 - accuracy: 0.4272 - precision_2: 0.6866 - recall_2: 0.1080 - val_loss: 1.6081 - val_accuracy: 0.3592 - val_precision_2: 0.6207 - val_recall_2: 0.1268\n",
      "Epoch 23/200\n",
      "14/14 - 0s - loss: 1.3426 - accuracy: 0.4648 - precision_2: 0.6054 - recall_2: 0.2089 - val_loss: 1.6837 - val_accuracy: 0.3803 - val_precision_2: 0.5745 - val_recall_2: 0.1901\n",
      "Epoch 24/200\n",
      "14/14 - 0s - loss: 1.5438 - accuracy: 0.4108 - precision_2: 0.6082 - recall_2: 0.1385 - val_loss: 1.7389 - val_accuracy: 0.3099 - val_precision_2: 0.7826 - val_recall_2: 0.1268\n",
      "Epoch 25/200\n",
      "14/14 - 0s - loss: 1.3783 - accuracy: 0.4648 - precision_2: 0.7748 - recall_2: 0.2019 - val_loss: 1.5982 - val_accuracy: 0.3028 - val_precision_2: 0.5526 - val_recall_2: 0.1479\n",
      "Epoch 26/200\n",
      "14/14 - 0s - loss: 1.3670 - accuracy: 0.4577 - precision_2: 0.7597 - recall_2: 0.2300 - val_loss: 1.6602 - val_accuracy: 0.4155 - val_precision_2: 0.5882 - val_recall_2: 0.2113\n",
      "Epoch 27/200\n",
      "14/14 - 0s - loss: 1.2710 - accuracy: 0.5117 - precision_2: 0.7041 - recall_2: 0.2793 - val_loss: 1.5849 - val_accuracy: 0.3732 - val_precision_2: 0.6458 - val_recall_2: 0.2183\n",
      "Epoch 28/200\n",
      "14/14 - 0s - loss: 1.2302 - accuracy: 0.5282 - precision_2: 0.7622 - recall_2: 0.2559 - val_loss: 1.5904 - val_accuracy: 0.3803 - val_precision_2: 0.5918 - val_recall_2: 0.2042\n",
      "Epoch 29/200\n",
      "14/14 - 0s - loss: 1.1625 - accuracy: 0.5235 - precision_2: 0.7515 - recall_2: 0.2981 - val_loss: 1.5885 - val_accuracy: 0.3521 - val_precision_2: 0.6042 - val_recall_2: 0.2042\n",
      "Epoch 30/200\n",
      "14/14 - 0s - loss: 1.1789 - accuracy: 0.5516 - precision_2: 0.7516 - recall_2: 0.2770 - val_loss: 1.6245 - val_accuracy: 0.3239 - val_precision_2: 0.5098 - val_recall_2: 0.1831\n",
      "Epoch 31/200\n",
      "14/14 - 0s - loss: 1.2695 - accuracy: 0.4977 - precision_2: 0.7063 - recall_2: 0.2653 - val_loss: 1.5155 - val_accuracy: 0.3592 - val_precision_2: 0.5294 - val_recall_2: 0.1901\n",
      "Epoch 32/200\n",
      "14/14 - 0s - loss: 1.1883 - accuracy: 0.5423 - precision_2: 0.7751 - recall_2: 0.3075 - val_loss: 1.6208 - val_accuracy: 0.3310 - val_precision_2: 0.5455 - val_recall_2: 0.2113\n",
      "Epoch 33/200\n",
      "14/14 - 0s - loss: 1.1444 - accuracy: 0.5352 - precision_2: 0.7435 - recall_2: 0.3333 - val_loss: 1.4632 - val_accuracy: 0.4014 - val_precision_2: 0.5763 - val_recall_2: 0.2394\n",
      "Epoch 34/200\n",
      "14/14 - 0s - loss: 1.0396 - accuracy: 0.5634 - precision_2: 0.8270 - recall_2: 0.3592 - val_loss: 1.3992 - val_accuracy: 0.4648 - val_precision_2: 0.7143 - val_recall_2: 0.2817\n",
      "Epoch 35/200\n",
      "14/14 - 0s - loss: 1.0120 - accuracy: 0.6056 - precision_2: 0.8053 - recall_2: 0.3592 - val_loss: 1.5757 - val_accuracy: 0.4085 - val_precision_2: 0.5970 - val_recall_2: 0.2817\n",
      "Epoch 36/200\n",
      "14/14 - 0s - loss: 1.0176 - accuracy: 0.5728 - precision_2: 0.7797 - recall_2: 0.4155 - val_loss: 1.4614 - val_accuracy: 0.4648 - val_precision_2: 0.6232 - val_recall_2: 0.3028\n",
      "Epoch 37/200\n",
      "14/14 - 0s - loss: 1.1742 - accuracy: 0.5376 - precision_2: 0.7264 - recall_2: 0.3427 - val_loss: 1.6250 - val_accuracy: 0.4225 - val_precision_2: 0.4933 - val_recall_2: 0.2606\n",
      "Epoch 38/200\n",
      "14/14 - 0s - loss: 1.1374 - accuracy: 0.5493 - precision_2: 0.7227 - recall_2: 0.3732 - val_loss: 1.4481 - val_accuracy: 0.4014 - val_precision_2: 0.6029 - val_recall_2: 0.2887\n",
      "Epoch 39/200\n",
      "14/14 - 0s - loss: 1.1207 - accuracy: 0.5446 - precision_2: 0.7454 - recall_2: 0.3779 - val_loss: 1.6031 - val_accuracy: 0.3944 - val_precision_2: 0.4875 - val_recall_2: 0.2746\n",
      "Epoch 40/200\n",
      "14/14 - 0s - loss: 1.1021 - accuracy: 0.5563 - precision_2: 0.7479 - recall_2: 0.4108 - val_loss: 1.5520 - val_accuracy: 0.4507 - val_precision_2: 0.5915 - val_recall_2: 0.2958\n",
      "Epoch 41/200\n",
      "14/14 - 0s - loss: 1.0465 - accuracy: 0.5939 - precision_2: 0.8069 - recall_2: 0.3826 - val_loss: 1.4012 - val_accuracy: 0.5070 - val_precision_2: 0.6232 - val_recall_2: 0.3028\n",
      "Epoch 42/200\n",
      "14/14 - 0s - loss: 0.9532 - accuracy: 0.6268 - precision_2: 0.8058 - recall_2: 0.4577 - val_loss: 1.3831 - val_accuracy: 0.4930 - val_precision_2: 0.6341 - val_recall_2: 0.3662\n",
      "Epoch 43/200\n",
      "14/14 - 0s - loss: 0.9002 - accuracy: 0.6291 - precision_2: 0.7976 - recall_2: 0.4624 - val_loss: 1.3528 - val_accuracy: 0.4930 - val_precision_2: 0.6515 - val_recall_2: 0.3028\n",
      "Epoch 44/200\n",
      "14/14 - 0s - loss: 0.8541 - accuracy: 0.6526 - precision_2: 0.8175 - recall_2: 0.4836 - val_loss: 1.4552 - val_accuracy: 0.4789 - val_precision_2: 0.6216 - val_recall_2: 0.3239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200\n",
      "14/14 - 0s - loss: 0.9526 - accuracy: 0.6362 - precision_2: 0.8059 - recall_2: 0.4484 - val_loss: 1.6407 - val_accuracy: 0.3803 - val_precision_2: 0.5116 - val_recall_2: 0.3099\n",
      "Epoch 46/200\n",
      "14/14 - 0s - loss: 0.9579 - accuracy: 0.6338 - precision_2: 0.7581 - recall_2: 0.4413 - val_loss: 1.6465 - val_accuracy: 0.4507 - val_precision_2: 0.6067 - val_recall_2: 0.3803\n",
      "Epoch 47/200\n",
      "14/14 - 0s - loss: 0.9195 - accuracy: 0.6362 - precision_2: 0.7595 - recall_2: 0.5188 - val_loss: 1.3503 - val_accuracy: 0.5493 - val_precision_2: 0.6800 - val_recall_2: 0.3592\n",
      "Epoch 48/200\n",
      "14/14 - 0s - loss: 1.0755 - accuracy: 0.6009 - precision_2: 0.7235 - recall_2: 0.4484 - val_loss: 1.5986 - val_accuracy: 0.4085 - val_precision_2: 0.5479 - val_recall_2: 0.2817\n",
      "Epoch 49/200\n",
      "14/14 - 0s - loss: 1.1109 - accuracy: 0.5399 - precision_2: 0.7897 - recall_2: 0.3615 - val_loss: 1.5237 - val_accuracy: 0.4155 - val_precision_2: 0.5789 - val_recall_2: 0.3099\n",
      "Epoch 50/200\n",
      "14/14 - 0s - loss: 0.9767 - accuracy: 0.6103 - precision_2: 0.7904 - recall_2: 0.4249 - val_loss: 1.3968 - val_accuracy: 0.4859 - val_precision_2: 0.6429 - val_recall_2: 0.3169\n",
      "Epoch 51/200\n",
      "14/14 - 0s - loss: 0.9566 - accuracy: 0.6268 - precision_2: 0.8078 - recall_2: 0.4836 - val_loss: 1.3702 - val_accuracy: 0.5563 - val_precision_2: 0.6750 - val_recall_2: 0.3803\n",
      "Epoch 52/200\n",
      "14/14 - 0s - loss: 0.7841 - accuracy: 0.6995 - precision_2: 0.8188 - recall_2: 0.5516 - val_loss: 1.4230 - val_accuracy: 0.4789 - val_precision_2: 0.5545 - val_recall_2: 0.3944\n",
      "Epoch 53/200\n",
      "14/14 - 0s - loss: 0.7775 - accuracy: 0.6901 - precision_2: 0.7702 - recall_2: 0.5822 - val_loss: 1.3568 - val_accuracy: 0.5915 - val_precision_2: 0.6436 - val_recall_2: 0.4577\n",
      "Epoch 54/200\n",
      "14/14 - 0s - loss: 0.7650 - accuracy: 0.6972 - precision_2: 0.8153 - recall_2: 0.5493 - val_loss: 1.2911 - val_accuracy: 0.5141 - val_precision_2: 0.6706 - val_recall_2: 0.4014\n",
      "Epoch 55/200\n",
      "14/14 - 0s - loss: 0.7578 - accuracy: 0.7066 - precision_2: 0.8215 - recall_2: 0.5728 - val_loss: 1.3515 - val_accuracy: 0.5070 - val_precision_2: 0.5464 - val_recall_2: 0.3732\n",
      "Epoch 56/200\n",
      "14/14 - 0s - loss: 0.6996 - accuracy: 0.7230 - precision_2: 0.7965 - recall_2: 0.6432 - val_loss: 1.3548 - val_accuracy: 0.5000 - val_precision_2: 0.6186 - val_recall_2: 0.4225\n",
      "Epoch 57/200\n",
      "14/14 - 0s - loss: 0.6565 - accuracy: 0.7324 - precision_2: 0.8018 - recall_2: 0.6268 - val_loss: 1.3634 - val_accuracy: 0.5634 - val_precision_2: 0.6735 - val_recall_2: 0.4648\n",
      "Epoch 58/200\n",
      "14/14 - 0s - loss: 0.6722 - accuracy: 0.7277 - precision_2: 0.7959 - recall_2: 0.6408 - val_loss: 1.4097 - val_accuracy: 0.4789 - val_precision_2: 0.5596 - val_recall_2: 0.4296\n",
      "Epoch 59/200\n",
      "14/14 - 0s - loss: 0.8343 - accuracy: 0.6690 - precision_2: 0.7593 - recall_2: 0.5775 - val_loss: 1.4394 - val_accuracy: 0.5141 - val_precision_2: 0.6429 - val_recall_2: 0.3803\n",
      "Epoch 60/200\n",
      "14/14 - 0s - loss: 0.6760 - accuracy: 0.7160 - precision_2: 0.8274 - recall_2: 0.5962 - val_loss: 1.3811 - val_accuracy: 0.5493 - val_precision_2: 0.6344 - val_recall_2: 0.4155\n",
      "Epoch 61/200\n",
      "14/14 - 0s - loss: 0.6465 - accuracy: 0.7441 - precision_2: 0.8242 - recall_2: 0.6385 - val_loss: 1.4418 - val_accuracy: 0.5352 - val_precision_2: 0.6214 - val_recall_2: 0.4507\n",
      "Epoch 62/200\n",
      "14/14 - 0s - loss: 0.8949 - accuracy: 0.6784 - precision_2: 0.7530 - recall_2: 0.5869 - val_loss: 1.4767 - val_accuracy: 0.4859 - val_precision_2: 0.5761 - val_recall_2: 0.3732\n",
      "Epoch 63/200\n",
      "14/14 - 0s - loss: 0.7448 - accuracy: 0.6878 - precision_2: 0.7753 - recall_2: 0.5751 - val_loss: 1.4746 - val_accuracy: 0.5352 - val_precision_2: 0.5536 - val_recall_2: 0.4366\n",
      "Epoch 64/200\n",
      "14/14 - 0s - loss: 0.6745 - accuracy: 0.7371 - precision_2: 0.8204 - recall_2: 0.6221 - val_loss: 1.3128 - val_accuracy: 0.5563 - val_precision_2: 0.6701 - val_recall_2: 0.4577\n",
      "Epoch 65/200\n",
      "14/14 - 0s - loss: 0.6106 - accuracy: 0.7465 - precision_2: 0.8298 - recall_2: 0.6408 - val_loss: 1.2784 - val_accuracy: 0.5986 - val_precision_2: 0.6604 - val_recall_2: 0.4930\n",
      "Epoch 66/200\n",
      "14/14 - 0s - loss: 0.5739 - accuracy: 0.7629 - precision_2: 0.8519 - recall_2: 0.6479 - val_loss: 1.5190 - val_accuracy: 0.5423 - val_precision_2: 0.6055 - val_recall_2: 0.4648\n",
      "Epoch 67/200\n",
      "14/14 - 0s - loss: 0.5992 - accuracy: 0.7488 - precision_2: 0.8049 - recall_2: 0.6878 - val_loss: 1.3928 - val_accuracy: 0.5563 - val_precision_2: 0.6071 - val_recall_2: 0.4789\n",
      "Epoch 68/200\n",
      "14/14 - 0s - loss: 0.5143 - accuracy: 0.8028 - precision_2: 0.8765 - recall_2: 0.6995 - val_loss: 1.2276 - val_accuracy: 0.5915 - val_precision_2: 0.6695 - val_recall_2: 0.5563\n",
      "Epoch 69/200\n",
      "14/14 - 0s - loss: 0.4771 - accuracy: 0.8028 - precision_2: 0.8411 - recall_2: 0.7582 - val_loss: 1.4155 - val_accuracy: 0.5845 - val_precision_2: 0.6435 - val_recall_2: 0.5211\n",
      "Epoch 70/200\n",
      "14/14 - 0s - loss: 0.5853 - accuracy: 0.7864 - precision_2: 0.8389 - recall_2: 0.7089 - val_loss: 1.3951 - val_accuracy: 0.5282 - val_precision_2: 0.6176 - val_recall_2: 0.4437\n",
      "Epoch 71/200\n",
      "14/14 - 0s - loss: 0.7904 - accuracy: 0.6878 - precision_2: 0.7660 - recall_2: 0.5915 - val_loss: 1.6029 - val_accuracy: 0.4859 - val_precision_2: 0.6067 - val_recall_2: 0.3803\n",
      "Epoch 72/200\n",
      "14/14 - 0s - loss: 0.7354 - accuracy: 0.7136 - precision_2: 0.8007 - recall_2: 0.5563 - val_loss: 1.3732 - val_accuracy: 0.5211 - val_precision_2: 0.6596 - val_recall_2: 0.4366\n",
      "Epoch 73/200\n",
      "14/14 - 0s - loss: 0.5541 - accuracy: 0.7700 - precision_2: 0.8984 - recall_2: 0.6643 - val_loss: 1.3531 - val_accuracy: 0.5845 - val_precision_2: 0.6417 - val_recall_2: 0.5423\n",
      "Epoch 74/200\n",
      "14/14 - 0s - loss: 0.5057 - accuracy: 0.7958 - precision_2: 0.8376 - recall_2: 0.7629 - val_loss: 1.3544 - val_accuracy: 0.6127 - val_precision_2: 0.6887 - val_recall_2: 0.5141\n",
      "Epoch 75/200\n",
      "14/14 - 0s - loss: 0.4927 - accuracy: 0.8146 - precision_2: 0.8713 - recall_2: 0.6995 - val_loss: 1.4238 - val_accuracy: 0.5775 - val_precision_2: 0.6000 - val_recall_2: 0.4648\n",
      "Epoch 76/200\n",
      "14/14 - 0s - loss: 0.5281 - accuracy: 0.7981 - precision_2: 0.8457 - recall_2: 0.7207 - val_loss: 1.4833 - val_accuracy: 0.5845 - val_precision_2: 0.6466 - val_recall_2: 0.5282\n",
      "Epoch 77/200\n",
      "14/14 - 0s - loss: 0.5030 - accuracy: 0.7958 - precision_2: 0.8663 - recall_2: 0.7300 - val_loss: 1.3756 - val_accuracy: 0.5915 - val_precision_2: 0.6083 - val_recall_2: 0.5141\n",
      "Epoch 78/200\n",
      "14/14 - 0s - loss: 0.4677 - accuracy: 0.8099 - precision_2: 0.8819 - recall_2: 0.7535 - val_loss: 1.3673 - val_accuracy: 0.5845 - val_precision_2: 0.6195 - val_recall_2: 0.4930\n",
      "Epoch 79/200\n",
      "14/14 - 0s - loss: 0.4641 - accuracy: 0.8216 - precision_2: 0.8889 - recall_2: 0.7512 - val_loss: 1.6255 - val_accuracy: 0.5352 - val_precision_2: 0.5929 - val_recall_2: 0.4718\n",
      "Epoch 80/200\n",
      "14/14 - 0s - loss: 0.5491 - accuracy: 0.7746 - precision_2: 0.8068 - recall_2: 0.7254 - val_loss: 1.5370 - val_accuracy: 0.5423 - val_precision_2: 0.5738 - val_recall_2: 0.4930\n",
      "Epoch 81/200\n",
      "14/14 - 0s - loss: 0.6627 - accuracy: 0.7418 - precision_2: 0.8118 - recall_2: 0.6784 - val_loss: 1.6457 - val_accuracy: 0.5141 - val_precision_2: 0.5741 - val_recall_2: 0.4366\n",
      "Epoch 82/200\n",
      "14/14 - 0s - loss: 0.6450 - accuracy: 0.7324 - precision_2: 0.8462 - recall_2: 0.6455 - val_loss: 1.3932 - val_accuracy: 0.5634 - val_precision_2: 0.6442 - val_recall_2: 0.4718\n",
      "Epoch 83/200\n",
      "14/14 - 0s - loss: 0.4687 - accuracy: 0.8404 - precision_2: 0.8757 - recall_2: 0.7606 - val_loss: 1.2787 - val_accuracy: 0.6268 - val_precision_2: 0.6803 - val_recall_2: 0.5845\n",
      "Epoch 84/200\n",
      "14/14 - 0s - loss: 0.4008 - accuracy: 0.8545 - precision_2: 0.8802 - recall_2: 0.7934 - val_loss: 1.4095 - val_accuracy: 0.6408 - val_precision_2: 0.6484 - val_recall_2: 0.5845\n",
      "Epoch 85/200\n",
      "14/14 - 0s - loss: 0.3777 - accuracy: 0.8545 - precision_2: 0.8816 - recall_2: 0.8216 - val_loss: 1.5147 - val_accuracy: 0.5775 - val_precision_2: 0.6172 - val_recall_2: 0.5563\n",
      "Epoch 86/200\n",
      "14/14 - 0s - loss: 0.3999 - accuracy: 0.8451 - precision_2: 0.8706 - recall_2: 0.8052 - val_loss: 1.4976 - val_accuracy: 0.5423 - val_precision_2: 0.5692 - val_recall_2: 0.5211\n",
      "Epoch 87/200\n",
      "14/14 - 0s - loss: 0.4690 - accuracy: 0.8075 - precision_2: 0.8346 - recall_2: 0.7700 - val_loss: 1.3442 - val_accuracy: 0.6056 - val_precision_2: 0.6154 - val_recall_2: 0.5634\n",
      "Epoch 88/200\n",
      "14/14 - 0s - loss: 0.4157 - accuracy: 0.8333 - precision_2: 0.8554 - recall_2: 0.8052 - val_loss: 1.4093 - val_accuracy: 0.5915 - val_precision_2: 0.6142 - val_recall_2: 0.5493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200\n",
      "14/14 - 0s - loss: 0.4413 - accuracy: 0.8333 - precision_2: 0.8601 - recall_2: 0.7934 - val_loss: 1.5056 - val_accuracy: 0.5704 - val_precision_2: 0.5821 - val_recall_2: 0.5493\n",
      "Epoch 90/200\n",
      "14/14 - 0s - loss: 0.3482 - accuracy: 0.8615 - precision_2: 0.8797 - recall_2: 0.8239 - val_loss: 1.5086 - val_accuracy: 0.5775 - val_precision_2: 0.5906 - val_recall_2: 0.5282\n",
      "Epoch 91/200\n",
      "14/14 - 0s - loss: 0.5213 - accuracy: 0.8146 - precision_2: 0.8471 - recall_2: 0.7934 - val_loss: 1.4205 - val_accuracy: 0.5845 - val_precision_2: 0.6116 - val_recall_2: 0.5211\n",
      "Epoch 92/200\n",
      "14/14 - 0s - loss: 0.4446 - accuracy: 0.8451 - precision_2: 0.8699 - recall_2: 0.8005 - val_loss: 1.4344 - val_accuracy: 0.5704 - val_precision_2: 0.6094 - val_recall_2: 0.5493\n",
      "Epoch 93/200\n",
      "14/14 - 0s - loss: 0.4056 - accuracy: 0.8474 - precision_2: 0.8990 - recall_2: 0.8146 - val_loss: 1.3958 - val_accuracy: 0.6408 - val_precision_2: 0.6508 - val_recall_2: 0.5775\n",
      "Epoch 94/200\n",
      "14/14 - 0s - loss: 0.3327 - accuracy: 0.8756 - precision_2: 0.9033 - recall_2: 0.8333 - val_loss: 1.5053 - val_accuracy: 0.5986 - val_precision_2: 0.6165 - val_recall_2: 0.5775\n",
      "Epoch 95/200\n",
      "14/14 - 0s - loss: 0.3252 - accuracy: 0.8638 - precision_2: 0.8881 - recall_2: 0.8380 - val_loss: 1.4425 - val_accuracy: 0.5915 - val_precision_2: 0.6260 - val_recall_2: 0.5775\n",
      "Epoch 96/200\n",
      "14/14 - 0s - loss: 0.2995 - accuracy: 0.9014 - precision_2: 0.9122 - recall_2: 0.8779 - val_loss: 1.4103 - val_accuracy: 0.6479 - val_precision_2: 0.6496 - val_recall_2: 0.6268\n",
      "Epoch 97/200\n",
      "14/14 - 0s - loss: 0.2761 - accuracy: 0.8826 - precision_2: 0.9046 - recall_2: 0.8685 - val_loss: 1.5907 - val_accuracy: 0.5493 - val_precision_2: 0.5878 - val_recall_2: 0.5423\n",
      "Epoch 98/200\n",
      "14/14 - 0s - loss: 0.2318 - accuracy: 0.9178 - precision_2: 0.9223 - recall_2: 0.8920 - val_loss: 1.4624 - val_accuracy: 0.6197 - val_precision_2: 0.6343 - val_recall_2: 0.5986\n",
      "Epoch 99/200\n",
      "14/14 - 0s - loss: 0.3643 - accuracy: 0.8803 - precision_2: 0.8961 - recall_2: 0.8709 - val_loss: 1.9455 - val_accuracy: 0.5563 - val_precision_2: 0.5735 - val_recall_2: 0.5493\n",
      "Epoch 100/200\n",
      "14/14 - 0s - loss: 0.3755 - accuracy: 0.8615 - precision_2: 0.8917 - recall_2: 0.8310 - val_loss: 1.4632 - val_accuracy: 0.6268 - val_precision_2: 0.6466 - val_recall_2: 0.6056\n",
      "Epoch 101/200\n",
      "14/14 - 0s - loss: 0.3223 - accuracy: 0.8732 - precision_2: 0.9046 - recall_2: 0.8685 - val_loss: 1.4790 - val_accuracy: 0.6408 - val_precision_2: 0.6667 - val_recall_2: 0.6338\n",
      "Epoch 102/200\n",
      "14/14 - 0s - loss: 0.4836 - accuracy: 0.8263 - precision_2: 0.8342 - recall_2: 0.7911 - val_loss: 1.8136 - val_accuracy: 0.5493 - val_precision_2: 0.5814 - val_recall_2: 0.5282\n",
      "Epoch 103/200\n",
      "14/14 - 0s - loss: 0.7477 - accuracy: 0.7300 - precision_2: 0.7682 - recall_2: 0.6925 - val_loss: 1.3935 - val_accuracy: 0.5493 - val_precision_2: 0.6167 - val_recall_2: 0.5211\n",
      "Epoch 104/200\n",
      "14/14 - 0s - loss: 0.4320 - accuracy: 0.8427 - precision_2: 0.8740 - recall_2: 0.7817 - val_loss: 1.5256 - val_accuracy: 0.6127 - val_precision_2: 0.6220 - val_recall_2: 0.5563\n",
      "Epoch 105/200\n",
      "14/14 - 0s - loss: 0.3684 - accuracy: 0.8592 - precision_2: 0.8866 - recall_2: 0.8263 - val_loss: 1.3887 - val_accuracy: 0.6408 - val_precision_2: 0.6567 - val_recall_2: 0.6197\n",
      "Epoch 106/200\n",
      "14/14 - 0s - loss: 0.2840 - accuracy: 0.8967 - precision_2: 0.9212 - recall_2: 0.8779 - val_loss: 1.5189 - val_accuracy: 0.6268 - val_precision_2: 0.6496 - val_recall_2: 0.6268\n",
      "Epoch 107/200\n",
      "14/14 - 0s - loss: 0.3054 - accuracy: 0.8873 - precision_2: 0.8897 - recall_2: 0.8709 - val_loss: 1.7231 - val_accuracy: 0.5563 - val_precision_2: 0.5612 - val_recall_2: 0.5493\n",
      "Epoch 108/200\n",
      "14/14 - 0s - loss: 0.3030 - accuracy: 0.8756 - precision_2: 0.8916 - recall_2: 0.8498 - val_loss: 1.3585 - val_accuracy: 0.6761 - val_precision_2: 0.6940 - val_recall_2: 0.6549\n",
      "Epoch 109/200\n",
      "14/14 - 0s - loss: 0.2540 - accuracy: 0.8967 - precision_2: 0.9053 - recall_2: 0.8756 - val_loss: 1.4448 - val_accuracy: 0.6549 - val_precision_2: 0.6642 - val_recall_2: 0.6408\n",
      "Epoch 110/200\n",
      "14/14 - 0s - loss: 0.2513 - accuracy: 0.9038 - precision_2: 0.9153 - recall_2: 0.8873 - val_loss: 1.5015 - val_accuracy: 0.6408 - val_precision_2: 0.6642 - val_recall_2: 0.6268\n",
      "Epoch 111/200\n",
      "14/14 - 0s - loss: 0.2698 - accuracy: 0.8944 - precision_2: 0.9014 - recall_2: 0.8803 - val_loss: 1.7309 - val_accuracy: 0.5704 - val_precision_2: 0.5926 - val_recall_2: 0.5634\n",
      "Epoch 112/200\n",
      "14/14 - 0s - loss: 0.4028 - accuracy: 0.8380 - precision_2: 0.8621 - recall_2: 0.8216 - val_loss: 1.5887 - val_accuracy: 0.5563 - val_precision_2: 0.5778 - val_recall_2: 0.5493\n",
      "Epoch 113/200\n",
      "14/14 - 0s - loss: 0.4738 - accuracy: 0.8239 - precision_2: 0.8511 - recall_2: 0.8052 - val_loss: 1.4933 - val_accuracy: 0.6268 - val_precision_2: 0.6444 - val_recall_2: 0.6127\n",
      "Epoch 114/200\n",
      "14/14 - 0s - loss: 0.2711 - accuracy: 0.8873 - precision_2: 0.9044 - recall_2: 0.8662 - val_loss: 1.6900 - val_accuracy: 0.5775 - val_precision_2: 0.6061 - val_recall_2: 0.5634\n",
      "Epoch 115/200\n",
      "14/14 - 0s - loss: 0.3797 - accuracy: 0.8709 - precision_2: 0.8808 - recall_2: 0.8498 - val_loss: 1.6878 - val_accuracy: 0.6127 - val_precision_2: 0.6212 - val_recall_2: 0.5775\n",
      "Epoch 116/200\n",
      "14/14 - 0s - loss: 0.2903 - accuracy: 0.8944 - precision_2: 0.9160 - recall_2: 0.8709 - val_loss: 1.6669 - val_accuracy: 0.5775 - val_precision_2: 0.5926 - val_recall_2: 0.5634\n",
      "Epoch 117/200\n",
      "14/14 - 0s - loss: 0.2953 - accuracy: 0.8756 - precision_2: 0.8981 - recall_2: 0.8685 - val_loss: 1.4242 - val_accuracy: 0.6479 - val_precision_2: 0.6594 - val_recall_2: 0.6408\n",
      "Epoch 118/200\n",
      "14/14 - 0s - loss: 0.2837 - accuracy: 0.8850 - precision_2: 0.9002 - recall_2: 0.8685 - val_loss: 1.5644 - val_accuracy: 0.6127 - val_precision_2: 0.6194 - val_recall_2: 0.5845\n",
      "Epoch 119/200\n",
      "14/14 - 0s - loss: 0.2650 - accuracy: 0.8991 - precision_2: 0.9095 - recall_2: 0.8967 - val_loss: 1.5053 - val_accuracy: 0.6408 - val_precision_2: 0.6741 - val_recall_2: 0.6408\n",
      "Epoch 120/200\n",
      "14/14 - 0s - loss: 0.2233 - accuracy: 0.9178 - precision_2: 0.9257 - recall_2: 0.9061 - val_loss: 1.4261 - val_accuracy: 0.6549 - val_precision_2: 0.6739 - val_recall_2: 0.6549\n",
      "Epoch 121/200\n",
      "14/14 - 0s - loss: 0.1921 - accuracy: 0.9202 - precision_2: 0.9485 - recall_2: 0.9085 - val_loss: 1.4730 - val_accuracy: 0.6056 - val_precision_2: 0.6103 - val_recall_2: 0.5845\n",
      "Epoch 122/200\n",
      "14/14 - 0s - loss: 0.1604 - accuracy: 0.9366 - precision_2: 0.9542 - recall_2: 0.9296 - val_loss: 1.3972 - val_accuracy: 0.6620 - val_precision_2: 0.6912 - val_recall_2: 0.6620\n",
      "Epoch 123/200\n",
      "14/14 - 0s - loss: 0.1513 - accuracy: 0.9366 - precision_2: 0.9498 - recall_2: 0.9319 - val_loss: 1.3823 - val_accuracy: 0.6127 - val_precision_2: 0.6515 - val_recall_2: 0.6056\n",
      "Epoch 124/200\n",
      "14/14 - 0s - loss: 0.1540 - accuracy: 0.9484 - precision_2: 0.9523 - recall_2: 0.9366 - val_loss: 1.3626 - val_accuracy: 0.6690 - val_precision_2: 0.6934 - val_recall_2: 0.6690\n",
      "Epoch 125/200\n",
      "14/14 - 0s - loss: 0.1528 - accuracy: 0.9296 - precision_2: 0.9405 - recall_2: 0.9272 - val_loss: 1.4548 - val_accuracy: 0.6690 - val_precision_2: 0.6765 - val_recall_2: 0.6479\n",
      "Epoch 126/200\n",
      "14/14 - 0s - loss: 0.1243 - accuracy: 0.9437 - precision_2: 0.9477 - recall_2: 0.9366 - val_loss: 1.5534 - val_accuracy: 0.6338 - val_precision_2: 0.6544 - val_recall_2: 0.6268\n",
      "Epoch 127/200\n",
      "14/14 - 0s - loss: 0.1802 - accuracy: 0.9296 - precision_2: 0.9333 - recall_2: 0.9202 - val_loss: 1.4962 - val_accuracy: 0.6408 - val_precision_2: 0.6493 - val_recall_2: 0.6127\n",
      "Epoch 128/200\n",
      "14/14 - 0s - loss: 0.1481 - accuracy: 0.9437 - precision_2: 0.9476 - recall_2: 0.9343 - val_loss: 1.6168 - val_accuracy: 0.6268 - val_precision_2: 0.6397 - val_recall_2: 0.6127\n",
      "Epoch 129/200\n",
      "14/14 - 0s - loss: 0.1813 - accuracy: 0.9319 - precision_2: 0.9424 - recall_2: 0.9225 - val_loss: 1.4383 - val_accuracy: 0.6690 - val_precision_2: 0.6838 - val_recall_2: 0.6549\n",
      "Epoch 130/200\n",
      "14/14 - 0s - loss: 0.1314 - accuracy: 0.9484 - precision_2: 0.9548 - recall_2: 0.9413 - val_loss: 1.6540 - val_accuracy: 0.6197 - val_precision_2: 0.6444 - val_recall_2: 0.6127\n",
      "Epoch 131/200\n",
      "14/14 - 0s - loss: 0.1117 - accuracy: 0.9577 - precision_2: 0.9573 - recall_2: 0.9484 - val_loss: 1.7419 - val_accuracy: 0.6268 - val_precision_2: 0.6312 - val_recall_2: 0.6268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/200\n",
      "14/14 - 0s - loss: 0.1130 - accuracy: 0.9601 - precision_2: 0.9600 - recall_2: 0.9577 - val_loss: 1.6942 - val_accuracy: 0.6127 - val_precision_2: 0.6397 - val_recall_2: 0.6127\n",
      "Epoch 133/200\n",
      "14/14 - 0s - loss: 0.1011 - accuracy: 0.9577 - precision_2: 0.9645 - recall_2: 0.9554 - val_loss: 1.5623 - val_accuracy: 0.6479 - val_precision_2: 0.6667 - val_recall_2: 0.6338\n",
      "Epoch 134/200\n",
      "14/14 - 0s - loss: 0.0858 - accuracy: 0.9695 - precision_2: 0.9717 - recall_2: 0.9671 - val_loss: 1.8197 - val_accuracy: 0.6479 - val_precision_2: 0.6475 - val_recall_2: 0.6338\n",
      "Epoch 135/200\n",
      "14/14 - 0s - loss: 0.0838 - accuracy: 0.9718 - precision_2: 0.9718 - recall_2: 0.9718 - val_loss: 1.5597 - val_accuracy: 0.6549 - val_precision_2: 0.6643 - val_recall_2: 0.6549\n",
      "Epoch 136/200\n",
      "14/14 - 0s - loss: 0.0740 - accuracy: 0.9789 - precision_2: 0.9811 - recall_2: 0.9765 - val_loss: 1.5722 - val_accuracy: 0.6690 - val_precision_2: 0.6835 - val_recall_2: 0.6690\n",
      "Epoch 137/200\n",
      "14/14 - 0s - loss: 0.0678 - accuracy: 0.9789 - precision_2: 0.9789 - recall_2: 0.9789 - val_loss: 1.5632 - val_accuracy: 0.6831 - val_precision_2: 0.7007 - val_recall_2: 0.6761\n",
      "Epoch 138/200\n",
      "14/14 - 0s - loss: 0.0616 - accuracy: 0.9789 - precision_2: 0.9789 - recall_2: 0.9789 - val_loss: 1.5911 - val_accuracy: 0.6690 - val_precision_2: 0.6835 - val_recall_2: 0.6690\n",
      "Epoch 139/200\n",
      "14/14 - 0s - loss: 0.0494 - accuracy: 0.9906 - precision_2: 0.9929 - recall_2: 0.9906 - val_loss: 1.6322 - val_accuracy: 0.6690 - val_precision_2: 0.6861 - val_recall_2: 0.6620\n",
      "Epoch 140/200\n",
      "14/14 - 0s - loss: 0.0593 - accuracy: 0.9812 - precision_2: 0.9858 - recall_2: 0.9765 - val_loss: 1.7164 - val_accuracy: 0.6338 - val_precision_2: 0.6475 - val_recall_2: 0.6338\n",
      "Epoch 141/200\n",
      "14/14 - 0s - loss: 0.0461 - accuracy: 0.9930 - precision_2: 0.9930 - recall_2: 0.9930 - val_loss: 1.6539 - val_accuracy: 0.6901 - val_precision_2: 0.6978 - val_recall_2: 0.6831\n",
      "Epoch 142/200\n",
      "14/14 - 0s - loss: 0.0592 - accuracy: 0.9836 - precision_2: 0.9859 - recall_2: 0.9836 - val_loss: 1.7828 - val_accuracy: 0.6690 - val_precision_2: 0.6763 - val_recall_2: 0.6620\n",
      "Epoch 143/200\n",
      "14/14 - 0s - loss: 0.0710 - accuracy: 0.9742 - precision_2: 0.9764 - recall_2: 0.9718 - val_loss: 1.8072 - val_accuracy: 0.6549 - val_precision_2: 0.6569 - val_recall_2: 0.6338\n",
      "Epoch 144/200\n",
      "14/14 - 0s - loss: 0.2306 - accuracy: 0.9202 - precision_2: 0.9211 - recall_2: 0.9038 - val_loss: 1.7867 - val_accuracy: 0.6620 - val_precision_2: 0.6739 - val_recall_2: 0.6549\n",
      "Epoch 145/200\n",
      "14/14 - 0s - loss: 0.4831 - accuracy: 0.8474 - precision_2: 0.8527 - recall_2: 0.8427 - val_loss: 1.8362 - val_accuracy: 0.5915 - val_precision_2: 0.6061 - val_recall_2: 0.5634\n",
      "Epoch 146/200\n",
      "14/14 - 0s - loss: 0.4758 - accuracy: 0.8239 - precision_2: 0.8460 - recall_2: 0.8122 - val_loss: 1.6378 - val_accuracy: 0.6056 - val_precision_2: 0.6222 - val_recall_2: 0.5915\n",
      "Epoch 147/200\n",
      "14/14 - 0s - loss: 0.3440 - accuracy: 0.8850 - precision_2: 0.8954 - recall_2: 0.8638 - val_loss: 1.7557 - val_accuracy: 0.5282 - val_precision_2: 0.5692 - val_recall_2: 0.5211\n",
      "Epoch 148/200\n",
      "14/14 - 0s - loss: 0.3473 - accuracy: 0.8568 - precision_2: 0.8780 - recall_2: 0.8451 - val_loss: 1.6002 - val_accuracy: 0.6197 - val_precision_2: 0.6328 - val_recall_2: 0.5704\n",
      "Epoch 149/200\n",
      "14/14 - 0s - loss: 0.4299 - accuracy: 0.8286 - precision_2: 0.8486 - recall_2: 0.8028 - val_loss: 1.6686 - val_accuracy: 0.5634 - val_precision_2: 0.5669 - val_recall_2: 0.5070\n",
      "Epoch 150/200\n",
      "14/14 - 0s - loss: 0.3651 - accuracy: 0.8615 - precision_2: 0.8762 - recall_2: 0.8474 - val_loss: 1.5824 - val_accuracy: 0.6268 - val_precision_2: 0.6519 - val_recall_2: 0.6197\n",
      "Epoch 151/200\n",
      "14/14 - 0s - loss: 0.2501 - accuracy: 0.9038 - precision_2: 0.9265 - recall_2: 0.8873 - val_loss: 1.6677 - val_accuracy: 0.6408 - val_precision_2: 0.6403 - val_recall_2: 0.6268\n",
      "Epoch 152/200\n",
      "14/14 - 0s - loss: 0.2389 - accuracy: 0.9085 - precision_2: 0.9177 - recall_2: 0.8897 - val_loss: 1.3133 - val_accuracy: 0.6690 - val_precision_2: 0.6815 - val_recall_2: 0.6479\n",
      "Epoch 153/200\n",
      "14/14 - 0s - loss: 0.1795 - accuracy: 0.9390 - precision_2: 0.9455 - recall_2: 0.9366 - val_loss: 1.5030 - val_accuracy: 0.6268 - val_precision_2: 0.6519 - val_recall_2: 0.6197\n",
      "Epoch 154/200\n",
      "14/14 - 0s - loss: 0.1630 - accuracy: 0.9437 - precision_2: 0.9522 - recall_2: 0.9343 - val_loss: 1.5266 - val_accuracy: 0.6268 - val_precision_2: 0.6493 - val_recall_2: 0.6127\n",
      "Epoch 155/200\n",
      "14/14 - 0s - loss: 0.1399 - accuracy: 0.9484 - precision_2: 0.9501 - recall_2: 0.9390 - val_loss: 1.5483 - val_accuracy: 0.6549 - val_precision_2: 0.6571 - val_recall_2: 0.6479\n",
      "Epoch 156/200\n",
      "14/14 - 0s - loss: 0.1781 - accuracy: 0.9390 - precision_2: 0.9500 - recall_2: 0.9366 - val_loss: 1.3096 - val_accuracy: 0.7254 - val_precision_2: 0.7234 - val_recall_2: 0.7183\n",
      "Epoch 157/200\n",
      "14/14 - 0s - loss: 0.1909 - accuracy: 0.9249 - precision_2: 0.9381 - recall_2: 0.9249 - val_loss: 1.4974 - val_accuracy: 0.6479 - val_precision_2: 0.6547 - val_recall_2: 0.6408\n",
      "Epoch 158/200\n",
      "14/14 - 0s - loss: 0.1917 - accuracy: 0.9413 - precision_2: 0.9480 - recall_2: 0.9413 - val_loss: 1.3625 - val_accuracy: 0.7042 - val_precision_2: 0.7111 - val_recall_2: 0.6761\n",
      "Epoch 159/200\n",
      "14/14 - 0s - loss: 0.1325 - accuracy: 0.9484 - precision_2: 0.9502 - recall_2: 0.9413 - val_loss: 1.6187 - val_accuracy: 0.6620 - val_precision_2: 0.6691 - val_recall_2: 0.6408\n",
      "Epoch 160/200\n",
      "14/14 - 0s - loss: 0.1157 - accuracy: 0.9648 - precision_2: 0.9669 - recall_2: 0.9601 - val_loss: 1.3945 - val_accuracy: 0.6972 - val_precision_2: 0.7153 - val_recall_2: 0.6901\n",
      "Epoch 161/200\n",
      "14/14 - 0s - loss: 0.0946 - accuracy: 0.9671 - precision_2: 0.9694 - recall_2: 0.9671 - val_loss: 1.4893 - val_accuracy: 0.6690 - val_precision_2: 0.6812 - val_recall_2: 0.6620\n",
      "Epoch 162/200\n",
      "14/14 - 0s - loss: 0.1233 - accuracy: 0.9531 - precision_2: 0.9527 - recall_2: 0.9460 - val_loss: 1.4629 - val_accuracy: 0.7183 - val_precision_2: 0.7226 - val_recall_2: 0.6972\n",
      "Epoch 163/200\n",
      "14/14 - 0s - loss: 0.0910 - accuracy: 0.9671 - precision_2: 0.9693 - recall_2: 0.9648 - val_loss: 1.4678 - val_accuracy: 0.6690 - val_precision_2: 0.6786 - val_recall_2: 0.6690\n",
      "Epoch 164/200\n",
      "14/14 - 0s - loss: 0.0875 - accuracy: 0.9742 - precision_2: 0.9764 - recall_2: 0.9695 - val_loss: 1.5631 - val_accuracy: 0.6479 - val_precision_2: 0.6475 - val_recall_2: 0.6338\n",
      "Epoch 165/200\n",
      "14/14 - 0s - loss: 0.1709 - accuracy: 0.9343 - precision_2: 0.9423 - recall_2: 0.9202 - val_loss: 1.5731 - val_accuracy: 0.6338 - val_precision_2: 0.6449 - val_recall_2: 0.6268\n",
      "Epoch 166/200\n",
      "14/14 - 0s - loss: 0.2435 - accuracy: 0.9202 - precision_2: 0.9265 - recall_2: 0.9178 - val_loss: 1.9830 - val_accuracy: 0.5915 - val_precision_2: 0.6131 - val_recall_2: 0.5915\n",
      "Epoch 167/200\n",
      "14/14 - 0s - loss: 0.4578 - accuracy: 0.8451 - precision_2: 0.8561 - recall_2: 0.8380 - val_loss: 1.7674 - val_accuracy: 0.5634 - val_precision_2: 0.5940 - val_recall_2: 0.5563\n",
      "Epoch 168/200\n",
      "14/14 - 0s - loss: 0.3012 - accuracy: 0.8920 - precision_2: 0.9031 - recall_2: 0.8756 - val_loss: 1.6086 - val_accuracy: 0.6056 - val_precision_2: 0.6148 - val_recall_2: 0.5845\n",
      "Epoch 169/200\n",
      "14/14 - 0s - loss: 0.1792 - accuracy: 0.9202 - precision_2: 0.9262 - recall_2: 0.9131 - val_loss: 1.5528 - val_accuracy: 0.5986 - val_precision_2: 0.6176 - val_recall_2: 0.5915\n",
      "Epoch 170/200\n",
      "14/14 - 0s - loss: 0.1881 - accuracy: 0.9296 - precision_2: 0.9333 - recall_2: 0.9202 - val_loss: 1.5724 - val_accuracy: 0.6408 - val_precision_2: 0.6471 - val_recall_2: 0.6197\n",
      "Epoch 171/200\n",
      "14/14 - 0s - loss: 0.2296 - accuracy: 0.9108 - precision_2: 0.9121 - recall_2: 0.9014 - val_loss: 1.5042 - val_accuracy: 0.6268 - val_precision_2: 0.6343 - val_recall_2: 0.5986\n",
      "Epoch 172/200\n",
      "14/14 - 0s - loss: 0.1834 - accuracy: 0.9131 - precision_2: 0.9212 - recall_2: 0.9061 - val_loss: 1.4264 - val_accuracy: 0.6338 - val_precision_2: 0.6496 - val_recall_2: 0.6268\n",
      "Epoch 173/200\n",
      "14/14 - 0s - loss: 0.1694 - accuracy: 0.9413 - precision_2: 0.9456 - recall_2: 0.9390 - val_loss: 1.6069 - val_accuracy: 0.6268 - val_precision_2: 0.6286 - val_recall_2: 0.6197\n",
      "Epoch 174/200\n",
      "14/14 - 0s - loss: 0.1367 - accuracy: 0.9577 - precision_2: 0.9621 - recall_2: 0.9531 - val_loss: 1.5095 - val_accuracy: 0.6479 - val_precision_2: 0.6569 - val_recall_2: 0.6338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "14/14 - 0s - loss: 0.0873 - accuracy: 0.9742 - precision_2: 0.9787 - recall_2: 0.9718 - val_loss: 1.3901 - val_accuracy: 0.6901 - val_precision_2: 0.6906 - val_recall_2: 0.6761\n",
      "Epoch 176/200\n",
      "14/14 - 0s - loss: 0.0720 - accuracy: 0.9789 - precision_2: 0.9788 - recall_2: 0.9765 - val_loss: 1.4882 - val_accuracy: 0.6831 - val_precision_2: 0.6861 - val_recall_2: 0.6620\n",
      "Epoch 177/200\n",
      "14/14 - 0s - loss: 0.0778 - accuracy: 0.9765 - precision_2: 0.9810 - recall_2: 0.9718 - val_loss: 1.5805 - val_accuracy: 0.6761 - val_precision_2: 0.6857 - val_recall_2: 0.6761\n",
      "Epoch 178/200\n",
      "14/14 - 0s - loss: 0.0580 - accuracy: 0.9883 - precision_2: 0.9882 - recall_2: 0.9859 - val_loss: 1.5455 - val_accuracy: 0.6549 - val_precision_2: 0.6838 - val_recall_2: 0.6549\n",
      "Epoch 179/200\n",
      "14/14 - 0s - loss: 0.0882 - accuracy: 0.9695 - precision_2: 0.9718 - recall_2: 0.9695 - val_loss: 1.5596 - val_accuracy: 0.6549 - val_precision_2: 0.6739 - val_recall_2: 0.6549\n",
      "Epoch 180/200\n",
      "14/14 - 0s - loss: 0.1710 - accuracy: 0.9460 - precision_2: 0.9505 - recall_2: 0.9460 - val_loss: 1.8660 - val_accuracy: 0.6127 - val_precision_2: 0.6232 - val_recall_2: 0.6056\n",
      "Epoch 181/200\n",
      "14/14 - 0s - loss: 0.3119 - accuracy: 0.9085 - precision_2: 0.9102 - recall_2: 0.9038 - val_loss: 1.5943 - val_accuracy: 0.6831 - val_precision_2: 0.6906 - val_recall_2: 0.6761\n",
      "Epoch 182/200\n",
      "14/14 - 0s - loss: 0.1117 - accuracy: 0.9671 - precision_2: 0.9716 - recall_2: 0.9624 - val_loss: 1.5475 - val_accuracy: 0.6761 - val_precision_2: 0.6786 - val_recall_2: 0.6690\n",
      "Epoch 183/200\n",
      "14/14 - 0s - loss: 0.1664 - accuracy: 0.9460 - precision_2: 0.9482 - recall_2: 0.9460 - val_loss: 1.5863 - val_accuracy: 0.6901 - val_precision_2: 0.6957 - val_recall_2: 0.6761\n",
      "Epoch 184/200\n",
      "14/14 - 0s - loss: 0.1271 - accuracy: 0.9648 - precision_2: 0.9645 - recall_2: 0.9577 - val_loss: 1.4289 - val_accuracy: 0.6761 - val_precision_2: 0.6934 - val_recall_2: 0.6690\n",
      "Epoch 185/200\n",
      "14/14 - 0s - loss: 0.0996 - accuracy: 0.9671 - precision_2: 0.9717 - recall_2: 0.9671 - val_loss: 1.5179 - val_accuracy: 0.6408 - val_precision_2: 0.6594 - val_recall_2: 0.6408\n",
      "Epoch 186/200\n",
      "14/14 - 0s - loss: 0.0554 - accuracy: 0.9883 - precision_2: 0.9952 - recall_2: 0.9836 - val_loss: 1.5217 - val_accuracy: 0.6901 - val_precision_2: 0.6879 - val_recall_2: 0.6831\n",
      "Epoch 187/200\n",
      "14/14 - 0s - loss: 0.0595 - accuracy: 0.9836 - precision_2: 0.9835 - recall_2: 0.9812 - val_loss: 1.5112 - val_accuracy: 0.6549 - val_precision_2: 0.6643 - val_recall_2: 0.6549\n",
      "Epoch 188/200\n",
      "14/14 - 0s - loss: 0.0670 - accuracy: 0.9765 - precision_2: 0.9788 - recall_2: 0.9742 - val_loss: 1.4951 - val_accuracy: 0.6831 - val_precision_2: 0.6831 - val_recall_2: 0.6831\n",
      "Epoch 189/200\n",
      "14/14 - 0s - loss: 0.0571 - accuracy: 0.9789 - precision_2: 0.9835 - recall_2: 0.9765 - val_loss: 1.5535 - val_accuracy: 0.6901 - val_precision_2: 0.6929 - val_recall_2: 0.6831\n",
      "Epoch 190/200\n",
      "14/14 - 0s - loss: 0.0437 - accuracy: 0.9930 - precision_2: 0.9930 - recall_2: 0.9930 - val_loss: 1.5938 - val_accuracy: 0.6620 - val_precision_2: 0.6667 - val_recall_2: 0.6620\n",
      "Epoch 191/200\n",
      "14/14 - 0s - loss: 0.0425 - accuracy: 0.9836 - precision_2: 0.9836 - recall_2: 0.9836 - val_loss: 1.5718 - val_accuracy: 0.6479 - val_precision_2: 0.6525 - val_recall_2: 0.6479\n",
      "Epoch 192/200\n",
      "14/14 - 0s - loss: 0.0252 - accuracy: 0.9977 - precision_2: 0.9977 - recall_2: 0.9977 - val_loss: 1.6008 - val_accuracy: 0.6831 - val_precision_2: 0.7164 - val_recall_2: 0.6761\n",
      "Epoch 193/200\n",
      "14/14 - 0s - loss: 0.0210 - accuracy: 0.9977 - precision_2: 0.9977 - recall_2: 0.9977 - val_loss: 1.5720 - val_accuracy: 0.6690 - val_precision_2: 0.6812 - val_recall_2: 0.6620\n",
      "Epoch 194/200\n",
      "14/14 - 0s - loss: 0.0163 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - val_loss: 1.5406 - val_accuracy: 0.6761 - val_precision_2: 0.6861 - val_recall_2: 0.6620\n",
      "Epoch 195/200\n",
      "14/14 - 0s - loss: 0.0139 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - val_loss: 1.5389 - val_accuracy: 0.6831 - val_precision_2: 0.6957 - val_recall_2: 0.6761\n",
      "Epoch 196/200\n",
      "14/14 - 0s - loss: 0.0116 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - val_loss: 1.5469 - val_accuracy: 0.6831 - val_precision_2: 0.6957 - val_recall_2: 0.6761\n",
      "Epoch 197/200\n",
      "14/14 - 0s - loss: 0.0102 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - val_loss: 1.5447 - val_accuracy: 0.6901 - val_precision_2: 0.7050 - val_recall_2: 0.6901\n",
      "Epoch 198/200\n",
      "14/14 - 0s - loss: 0.0092 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - val_loss: 1.5494 - val_accuracy: 0.6901 - val_precision_2: 0.7050 - val_recall_2: 0.6901\n",
      "Epoch 199/200\n",
      "14/14 - 0s - loss: 0.0086 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - val_loss: 1.5581 - val_accuracy: 0.6901 - val_precision_2: 0.7050 - val_recall_2: 0.6901\n",
      "Epoch 200/200\n",
      "14/14 - 0s - loss: 0.0081 - accuracy: 1.0000 - precision_2: 1.0000 - recall_2: 1.0000 - val_loss: 1.5680 - val_accuracy: 0.6972 - val_precision_2: 0.7101 - val_recall_2: 0.6901\n"
     ]
    }
   ],
   "source": [
    "#tmp_chekpoints= \"tmp\\epoch{epoch:02d}-{val_accuracy:.2f}-{val_loss:.2f}.hdf5\"\n",
    "tmp_chekpoints= \"C:\\\\ML\\\\checkpoints\\\\tmp\\\\epoch{epoch:02d}-{val_accuracy:.2f}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "#csv_log = tf.keras.callbacks.CSVLogger(\"log.csv\", separator=',', append=False)\n",
    "csv_log = tf.keras.callbacks.CSVLogger(\"C:\\ML\\logs\\log.csv\", separator=',', append=False)\n",
    "\n",
    "#tb = tf.keras.callbacks.TensorBoard(log_dir='logs', histogram_freq=1, write_graph=False, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=1, embeddings_metadata=None)\n",
    "tb = tf.keras.callbacks.TensorBoard(log_dir='C:\\ML\\logs', histogram_freq=1, write_graph=False, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=1, embeddings_metadata=None)\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=20, verbose=0, mode='max', baseline=None, restore_best_weights=True)\n",
    "chk= tf.keras.callbacks.ModelCheckpoint(tmp_chekpoints, monitor='val_accuracy', verbose=0, save_best_only=False, save_weights_only=False, mode='max', save_freq='epoch')\n",
    "\n",
    "\n",
    "history = model.fit(x_train,y_train,epochs=200,batch_size=32, validation_data=(x_val,y_val),shuffle=False, verbose=2, callbacks=[csv_log, chk])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training history of your LSTM models can be used to diagnose the behavior of your model.\n",
    "\n",
    "You can plot the performance of your model using the Matplotlib library. For example, you can plot training loss vs test loss as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.savefig(\"C:/ML/loss\"f\"{starttime}.png\")\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('accuracy')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='lower right')\n",
    "pyplot.savefig(\"C:/ML/accuracy_\"f\"{starttime}.png\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Underfit Example\n",
    "Running this example produces a plot of train and validation loss showing the characteristic of an underfit model. In this case, performance may be improved by increasing the number of training epochs.\n",
    "\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-an-Underfit-Model.png\" width=\"400\">\n",
    "\n",
    "\n",
    "Running this example shows the characteristic of an underfit model that appears under-provisioned.\n",
    "In this case, performance may be improved by increasing the capacity of the model, such as the number of memory cells in a hidden layer or number of hidden layers.\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-an-Underfit-Model-via-Status.png\" width=\"400\">\n",
    "\n",
    "#### Good Fit Example\n",
    "Running the example creates a line plot showing the train and validation loss meeting.\n",
    "Ideally, we would like to see model performance like this if possible, although this may not be possible on challenging problems with a lot of data.\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-a-Good-Fit-for-a-Model.png\" width=\"400\">\n",
    "\n",
    "#### Overfit Example\n",
    "Running this example creates a plot showing the characteristic inflection point in validation loss of an overfit model.\n",
    "This may be a sign of too many training epochs.\n",
    "In this case, the model training could be stopped at the inflection point. Alternately, the number of training examples could be increased.\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-an-Overfit-Model.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model('./tmp/epoch49-0.90-0.39.hdf5')\n",
    "\n",
    "\n",
    "#bestmodel.evaluate(x=x_test, y=y_test, verbose=2)\n",
    "model.evaluate(x=x_test, y=y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodel.save(\"sign_lang_recognition_tuned.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor-gpu",
   "language": "python",
   "name": "tensor-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
