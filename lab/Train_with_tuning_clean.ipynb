{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook for loading and training models.\n",
    "Furthermore it provides simple documentation for different approaches used for training a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the command below to see command-completion on pressing `TAB`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount Datasets by word total:\n",
      "Computer :  57;  Deutschland :  65;  Haben :  68;  Hallo :  57;  Mainz :  65;  Software :  67;  Welt :  66;  du :  66;  ich :  66;  unser :  64;  zeigen :  69;   \n",
      "\n",
      "Amount Datasets by word training:\n",
      "Computer :  31;  Deutschland :  30;  Haben :  38;  Hallo :  34;  Mainz :  38;  Software :  46;  Welt :  43;  du :  42;  ich :  37;  unser :  43;  zeigen :  44;   \n",
      "\n",
      "Amount Datasets by word validiation:\n",
      "Computer :  13;  Deutschland :  15;  Haben :  11;  Hallo :  11;  Mainz :  10;  Software :  13;  Welt :  14;  du :  13;  ich :  19;  unser :  10;  zeigen :  13;   \n",
      "\n",
      "Amount Datasets by word test:\n",
      "Computer :  13;  Deutschland :  20;  Haben :  19;  Hallo :  12;  Mainz :  17;  Software :  8;  Welt :  9;  du :  11;  ich :  10;  unser :  11;  zeigen :  12;   \n",
      "\n",
      "Distribution of data:\n",
      "Amount total: 710\n",
      "Amount training: 426\n",
      "Amount validiation: 142\n",
      "Amount test: 142\n",
      "\n",
      "Tokens:\n",
      "{'computer': 1, 'deutschland': 2, 'du': 3, 'haben': 4, 'hallo': 5, 'ich': 6, 'mainz': 7, 'software': 8, 'unser': 9, 'welt': 10, 'zeigen': 11}\n",
      "\n",
      "Categories in OneHot anotation:\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n",
      "\n",
      "Dataset coordinate Values:\n",
      "[[[ 0.39615   0.398918  0.267371 ...  0.981109  0.505336  0.997934]\n",
      "  [ 0.395785  0.39586   0.249782 ...  1.0012    0.500846  1.02185 ]\n",
      "  [ 0.397311  0.395266  0.247748 ...  0.954924  0.514182  0.971554]\n",
      "  ...\n",
      "  [-1.       -1.       -1.       ... -1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.       ... -1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.       ... -1.       -1.       -1.      ]]\n",
      "\n",
      " [[ 0.374127  0.427507  0.466542 ... -1.       -1.       -1.      ]\n",
      "  [ 0.371845  0.434132  0.453027 ... -1.       -1.       -1.      ]\n",
      "  [ 0.369134  0.440652  0.450106 ... -1.       -1.       -1.      ]\n",
      "  ...\n",
      "  [-1.       -1.       -1.       ... -1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.       ... -1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.       ... -1.       -1.       -1.      ]]\n",
      "\n",
      " [[ 0.441569  0.323025  0.       ... -1.       -1.       -1.      ]\n",
      "  [ 0.442028  0.322752  0.       ... -1.       -1.       -1.      ]\n",
      "  [ 0.440985  0.323315  0.       ... -1.       -1.       -1.      ]\n",
      "  ...\n",
      "  [-1.       -1.       -1.       ... -1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.       ... -1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.       ... -1.       -1.       -1.      ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.445863  0.426787  0.       ... -1.       -1.       -1.      ]\n",
      "  [ 0.447222  0.427649  0.       ... -1.       -1.       -1.      ]\n",
      "  [ 0.447077  0.426849  0.       ... -1.       -1.       -1.      ]\n",
      "  ...\n",
      "  [-1.       -1.       -1.       ... -1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.       ... -1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.       ... -1.       -1.       -1.      ]]\n",
      "\n",
      " [[ 0.493763  0.242344  0.       ... -1.       -1.       -1.      ]\n",
      "  [ 0.494503  0.237877  0.       ... -1.       -1.       -1.      ]\n",
      "  [ 0.495819  0.230682  0.       ... -1.       -1.       -1.      ]\n",
      "  ...\n",
      "  [-1.       -1.       -1.       ... -1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.       ... -1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.       ... -1.       -1.       -1.      ]]\n",
      "\n",
      " [[ 0.47383   0.146982  0.       ... -1.       -1.       -1.      ]\n",
      "  [ 0.474502  0.146467  0.       ... -1.       -1.       -1.      ]\n",
      "  [ 0.474695  0.146444  0.       ... -1.       -1.       -1.      ]\n",
      "  ...\n",
      "  [-1.       -1.       -1.       ... -1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.       ... -1.       -1.       -1.      ]\n",
      "  [-1.       -1.       -1.       ... -1.       -1.       -1.      ]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import wandb\n",
    "import os\n",
    "import warnings\n",
    "import tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "\n",
    "# Ignore future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Root CSV files directory\n",
    "dirname = \"./data/\"  \n",
    "\n",
    "# Constant frame count.\n",
    "frames = 100\n",
    "\n",
    "\n",
    "#Preparation Stage - Load data and normalize\n",
    "listfile = os.listdir(dirname)\n",
    "data = []\n",
    "for wordname in listfile:\n",
    "    if wordname == \".DS_Store\":\n",
    "        continue\n",
    "    for csv in os.listdir(dirname + wordname):\n",
    "        filepath = os.path.join(dirname, wordname, csv)\n",
    "        content = pd.read_csv(filepath, sep=';')\n",
    "        content = content.reindex(list(range(0, frames)), fill_value=0.0)\n",
    "        content.fillna(0.0, inplace = True)\n",
    "#        content = content.reindex(list(range(0, frames)), fill_value=-1.0)\n",
    "#        content.fillna(-1.0, inplace = True) \n",
    "        data.append((wordname, content))\n",
    "        \n",
    "#Split data 60-20-20\n",
    "\n",
    "features = [n[1] for n in data]\n",
    "features = [f.to_numpy() for f in features]\n",
    "labels = [n[0] for n in data]\n",
    "x_train, x_val, y_train, y_val = train_test_split(features, labels, test_size=0.40, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.50, random_state=42)\n",
    "\n",
    "#Enumerate\n",
    "def printCountDataSets(dataset):\n",
    "    wortCounter = []\n",
    "    #Liste mit einmaligen Labels erstellen\n",
    "    labels = sorted(set(dataset), key=dataset.index)\n",
    "    #Liste nochmal Alphabetisch sortieren\n",
    "    labels = sorted(labels)\n",
    "    for label in labels:\n",
    "        wortCounter.append(0)\n",
    "    for row in dataset:\n",
    "        for i in range(len(labels)):\n",
    "            if str(labels[i]).startswith(row):\n",
    "                wortCounter[i] += 1\n",
    "    for i in range(len(labels)):\n",
    "        print(labels[i], ': ', wortCounter[i], end =\";  \")\n",
    "    print(' ')        \n",
    "    \n",
    "print('Amount Datasets by word total:')\n",
    "printCountDataSets(labels)\n",
    "print('')\n",
    "\n",
    "print('Amount Datasets by word training:')\n",
    "printCountDataSets(y_train)\n",
    "print('')\n",
    "\n",
    "print('Amount Datasets by word validiation:')\n",
    "printCountDataSets(y_val)\n",
    "print('')\n",
    "\n",
    "print('Amount Datasets by word test:')\n",
    "printCountDataSets(y_test)\n",
    "print('')\n",
    "\n",
    "\n",
    "# Display data distribution\n",
    "print('Distribution of data:')\n",
    "print(\"Amount total:\", len(labels))\n",
    "print(\"Amount training:\", len(y_train))\n",
    "print(\"Amount validiation:\", len(y_val))\n",
    "print(\"Amount test:\", len(y_test))\n",
    "print('')\n",
    "\n",
    "#Tokenize (One Hot)\n",
    "tokenizer = tools.tokenize(dirname)\n",
    "print('Tokens:')\n",
    "print(tokenizer.word_index)\n",
    "print('')\n",
    "with open('tokens_json.txt', 'w') as outfile:\n",
    "    outfile.write(tokenizer.to_json())\n",
    "\n",
    "encoded_train=tokenizer.texts_to_sequences([y_train])[0]\n",
    "encoded_val=tokenizer.texts_to_sequences([y_val])[0]\n",
    "encoded_test=tokenizer.texts_to_sequences([y_test])[0]\n",
    "\n",
    "y_train = to_categorical(encoded_train)\n",
    "y_val = to_categorical(encoded_val)\n",
    "y_test = to_categorical(encoded_test)\n",
    "\n",
    "print('Categories in OneHot anotation:')\n",
    "print(y_train)\n",
    "print('')\n",
    "# Making numpy arrays\n",
    "x_train=np.array(x_train)\n",
    "y_train=np.array(y_train)\n",
    "x_val=np.array(x_val)\n",
    "y_val=np.array(y_val)\n",
    "x_test=np.array(x_test)\n",
    "y_test=np.array(y_test)\n",
    "\n",
    "print('Dataset coordinate Values:')\n",
    "print(x_train)\n",
    "print('')\n",
    "\n",
    "import winsound\n",
    "def finished(num):\n",
    "    frequency = 2000  # Set Frequency To 2500 Hertz\n",
    "    duration = 500  # Set Duration To 1000 ms == 1 second\n",
    "    for i in range(0, num):\n",
    "        winsound.Beep(frequency, duration)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/michid41/first_test_run_SLR\" target=\"_blank\">https://app.wandb.ai/michid41/first_test_run_SLR</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/michid41/first_test_run_SLR/runs/37fb3nzl\" target=\"_blank\">https://app.wandb.ai/michid41/first_test_run_SLR/runs/37fb3nzl</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/michid41/first_test_run_SLR/runs/37fb3nzl"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"first_test_run_SLR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Stage\n",
    "Configure the model and train it.\n",
    "\n",
    "Metrics:\n",
    "<div float=\"right\">\n",
    "    <img src=\"assets/accuracy.png\" width=\"400\"> \n",
    "    <img src=\"assets/precision_recall_formula.png\" width=\"400\">\n",
    "</div>\n",
    "<img src=\"assets/precision_recall.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"color:blue\"> Hyperparametertuned LSTM </span>\n",
    "##### Here it is necessary to install the Keras-Tuner Module by executing:\n",
    "#####  <span style=\"color:green\"> via Conda:</span>\n",
    "conda install -c conda-forge keras-tuner\n",
    "#####  <span style=\"color:green\"> for pip:</span>\n",
    "pip install keras-tuner\n",
    "\n",
    "Right now there are three different builds we are testing:\n",
    "- classic LSTM\n",
    "- CuDNNLSTM\n",
    "- bidriectional LSTM\n",
    "\n",
    "#####  <span style=\"color:red\"> TODO: try to reduce learning rate or user tuner</span>\n",
    "#####  <span style=\"color:red\"> TODO: Crossfold</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.tuners import Hyperband\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from time import time, strftime\n",
    "\n",
    "\n",
    "starttime= strftime(\"%Y_%m_%d_%H%M%S\")\n",
    "LOG_DIR = \"C:\\ML\\Optimization_\"f\"{starttime}\" #<-In Windows below Log_dir Path will maybe be too long for Windows to handle, so use a shorter path like this here\n",
    "#LOG_DIR = \"./Optimization_\"f\"{starttime}\" # LOG_DIR holds json files with information and a model of each single trial\n",
    "\n",
    "def build_model_lstm(hp):\n",
    "    model = Sequential()\n",
    "#    model.add(tf.keras.layers.Masking(mask_value=-1.0, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    model.add(layers.LSTM(hp.Int(\"LSTM_input\", min_value =64, max_value=256,step=64, default=64), #kerastuner will randomly choose a value for nodes between 128 and 256 in steps of 64\n",
    "                            return_sequences=True,\n",
    "                            input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    \n",
    "    for i in range(hp.Int(\"n_layers\" , 1, 3)):    #number of layers ramdom between 1 an 3\n",
    "        model.add(layers.LSTM(hp.Int(f\"LSTM_{i}_units\", min_value =64, max_value=256,step=64, default=64),return_sequences=True))\n",
    "    \n",
    "    model.add(layers.LSTM(hp.Int(f\"LSTM_End\", min_value =32, max_value=128,step=32, default=32)))\n",
    "    model.add(layers.Dense(12, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  #optimizer=hp.Choice('optimizer',values=['Adam','RMSprop','SGD']),\n",
    "                  optimizer=hp.Choice('optimizer',values=['Adagrad','Adamax']),\n",
    "                  metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    model.summary()\n",
    "    print(model.optimizer.get_config()[\"name\"])\n",
    "    print('')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def build_model_CuDNNLSTM(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "\n",
    "    \n",
    "    model.add(tf.compat.v1.keras.layers.CuDNNLSTM(hp.Int(\"LSTM_input\", min_value =64, max_value=256,step=64, default=64), #kerastuner will randomly choose a value for nodes between 128 and 256 in steps of 64\n",
    "                            return_sequences=True,\n",
    "                            input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    \n",
    "    for i in range(hp.Int(\"n_layers\" , 1, 3)):    #number of layers ramdom between 1 an 3\n",
    "        model.add(tf.compat.v1.keras.layers.CuDNNLSTM(hp.Int(f\"LSTM_{i}_units\", min_value =64, max_value=256,step=64, default=64),return_sequences=True))\n",
    "    \n",
    "    model.add(tf.compat.v1.keras.layers.CuDNNLSTM(hp.Int(f\"LSTM_End\", min_value =32, max_value=128,step=32, default=32)))\n",
    "    model.add(layers.Dense(12, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  #optimizer=hp.Choice('optimizer',values=['Adam','RMSprop','SGD']),\n",
    "                  optimizer=hp.Choice('optimizer',values=['Adagrad','Adamax']),\n",
    "                  metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    model.summary()\n",
    "    print(model.optimizer.get_config()[\"name\"])\n",
    "    print('')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def build_model_bdlstm(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(layers.LSTM(hp.Int(\"LSTM_input\", min_value =64, max_value=256,step=64, default=64),\n",
    "                                        return_sequences=True),\n",
    "                                        input_shape=(100, 86)))\n",
    "    \n",
    "    for i in range(hp.Int(\"n_layers\" , 1, 3)):    #number of layers ramdom between 1 an 3\n",
    "        model.add(layers.Bidirectional(layers.LSTM(hp.Int(f\"LSTM_{i}_units\", min_value =64, max_value=256,step=64, default=64),return_sequences=True)))\n",
    "    \n",
    "    model.add(layers.Bidirectional(layers.LSTM(hp.Int(f\"LSTM_End\", min_value =32, max_value=128,step=32, default=32))))\n",
    "    model.add(layers.Dense(12, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=hp.Choice('optimizer',values=['Adagrad','Adamax','Adam','RMSprop']),\n",
    "                  metrics=['accuracy']) \n",
    "    model.summary()\n",
    "    print(model.optimizer.get_config()[\"name\"])\n",
    "    print('')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   <span style=\"color:red\">Necesarry only in case of using Nvidia GPU  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "print(\"Num GPUs:\", len(physical_devices)) \n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Keras-Tuner Approaches\n",
    "### 1 - RandomSearch\n",
    "Parameter of variables are ranomly used (number of layers, number of nodes) and \"best\" model is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project C:\\ML\\Optimization_2020_07_15_201918\\SignLagnuageModelOptimization\\oracle.json\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 64)           38656     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 64)           33024     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 84,492\n",
      "Trainable params: 84,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Adagrad\n",
      "\n",
      "INFO:tensorflow:Reloading Tuner from C:\\ML\\Optimization_2020_07_15_201918\\SignLagnuageModelOptimization\\tuner0.json\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 192)          214272    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 192)          295680    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 128)          164352    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 64)           49408     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1164      \n",
      "=================================================================\n",
      "Total params: 786,700\n",
      "Trainable params: 786,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Adamax\n",
      "\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/200\n",
      "426/426 - 10s - loss: 2.4364 - accuracy: 0.1197 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3693 - val_accuracy: 0.1127 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      "426/426 - 1s - loss: 2.2086 - accuracy: 0.2324 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0536 - val_accuracy: 0.2183 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/200\n",
      "426/426 - 1s - loss: 1.9432 - accuracy: 0.2559 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8502 - val_accuracy: 0.2324 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/200\n",
      "426/426 - 1s - loss: 1.9053 - accuracy: 0.2371 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9104 - val_accuracy: 0.2183 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/200\n",
      "426/426 - 1s - loss: 1.9508 - accuracy: 0.2700 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9047 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/200\n",
      "426/426 - 1s - loss: 1.8539 - accuracy: 0.2653 - precision: 0.8333 - recall: 0.0117 - val_loss: 1.8046 - val_accuracy: 0.2324 - val_precision: 1.0000 - val_recall: 0.0141\n",
      "Epoch 7/200\n",
      "426/426 - 1s - loss: 1.7999 - accuracy: 0.2817 - precision: 0.8182 - recall: 0.0211 - val_loss: 1.7633 - val_accuracy: 0.2817 - val_precision: 0.6250 - val_recall: 0.0352\n",
      "Epoch 8/200\n",
      "426/426 - 1s - loss: 1.7463 - accuracy: 0.3005 - precision: 0.7778 - recall: 0.0329 - val_loss: 1.7328 - val_accuracy: 0.2958 - val_precision: 0.7000 - val_recall: 0.0493\n",
      "Epoch 9/200\n",
      "426/426 - 1s - loss: 1.7317 - accuracy: 0.3005 - precision: 0.6944 - recall: 0.0587 - val_loss: 1.7215 - val_accuracy: 0.2817 - val_precision: 0.7500 - val_recall: 0.0634\n",
      "Epoch 10/200\n",
      "426/426 - 1s - loss: 1.7019 - accuracy: 0.3263 - precision: 0.6071 - recall: 0.0798 - val_loss: 1.7159 - val_accuracy: 0.2324 - val_precision: 0.7273 - val_recall: 0.0563\n",
      "Epoch 11/200\n",
      "426/426 - 1s - loss: 1.6825 - accuracy: 0.3333 - precision: 0.6471 - recall: 0.0775 - val_loss: 1.7270 - val_accuracy: 0.2817 - val_precision: 0.6000 - val_recall: 0.0423\n",
      "Epoch 12/200\n",
      "426/426 - 1s - loss: 1.6855 - accuracy: 0.3451 - precision: 0.6000 - recall: 0.0704 - val_loss: 1.7240 - val_accuracy: 0.3239 - val_precision: 0.5714 - val_recall: 0.0563\n",
      "Epoch 13/200\n",
      "426/426 - 1s - loss: 1.6868 - accuracy: 0.3380 - precision: 0.6585 - recall: 0.0634 - val_loss: 1.7017 - val_accuracy: 0.2958 - val_precision: 0.5833 - val_recall: 0.0493\n",
      "Epoch 14/200\n",
      "426/426 - 1s - loss: 1.6616 - accuracy: 0.3474 - precision: 0.7073 - recall: 0.0681 - val_loss: 1.6876 - val_accuracy: 0.2817 - val_precision: 0.6429 - val_recall: 0.0634\n",
      "Epoch 15/200\n",
      "426/426 - 1s - loss: 1.6367 - accuracy: 0.3545 - precision: 0.6056 - recall: 0.1009 - val_loss: 1.6599 - val_accuracy: 0.3169 - val_precision: 0.6471 - val_recall: 0.0775\n",
      "Epoch 16/200\n",
      "426/426 - 1s - loss: 1.6346 - accuracy: 0.3709 - precision: 0.6667 - recall: 0.1033 - val_loss: 1.6852 - val_accuracy: 0.3169 - val_precision: 0.7500 - val_recall: 0.1056\n",
      "Epoch 17/200\n",
      "426/426 - 1s - loss: 1.6205 - accuracy: 0.3545 - precision: 0.6667 - recall: 0.1315 - val_loss: 1.6559 - val_accuracy: 0.3239 - val_precision: 0.7619 - val_recall: 0.1127\n",
      "Epoch 18/200\n",
      "426/426 - 1s - loss: 1.6095 - accuracy: 0.3803 - precision: 0.7011 - recall: 0.1432 - val_loss: 1.6684 - val_accuracy: 0.2958 - val_precision: 0.7500 - val_recall: 0.1056\n",
      "Epoch 19/200\n",
      "426/426 - 1s - loss: 1.6245 - accuracy: 0.3451 - precision: 0.6186 - recall: 0.1408 - val_loss: 1.6200 - val_accuracy: 0.3169 - val_precision: 0.7826 - val_recall: 0.1268\n",
      "Epoch 20/200\n",
      "426/426 - 1s - loss: 1.6001 - accuracy: 0.4038 - precision: 0.7037 - recall: 0.1338 - val_loss: 1.6543 - val_accuracy: 0.3310 - val_precision: 0.7500 - val_recall: 0.1268\n",
      "Epoch 21/200\n",
      "426/426 - 1s - loss: 1.6263 - accuracy: 0.3568 - precision: 0.6824 - recall: 0.1362 - val_loss: 1.6950 - val_accuracy: 0.2676 - val_precision: 0.5882 - val_recall: 0.0704\n",
      "Epoch 22/200\n",
      "426/426 - 1s - loss: 1.6213 - accuracy: 0.3545 - precision: 0.6500 - recall: 0.1221 - val_loss: 1.6780 - val_accuracy: 0.3169 - val_precision: 0.6250 - val_recall: 0.1408\n",
      "Epoch 23/200\n",
      "426/426 - 1s - loss: 1.5981 - accuracy: 0.3991 - precision: 0.5957 - recall: 0.1315 - val_loss: 1.6645 - val_accuracy: 0.2746 - val_precision: 0.6667 - val_recall: 0.0845\n",
      "Epoch 24/200\n",
      "426/426 - 1s - loss: 1.5897 - accuracy: 0.3756 - precision: 0.6711 - recall: 0.1197 - val_loss: 1.6580 - val_accuracy: 0.3239 - val_precision: 0.8125 - val_recall: 0.0915\n",
      "Epoch 25/200\n",
      "426/426 - 1s - loss: 1.5752 - accuracy: 0.3967 - precision: 0.6860 - recall: 0.1385 - val_loss: 1.6812 - val_accuracy: 0.2746 - val_precision: 0.6429 - val_recall: 0.1268\n",
      "Epoch 26/200\n",
      "426/426 - 1s - loss: 1.5526 - accuracy: 0.3897 - precision: 0.7204 - recall: 0.1573 - val_loss: 1.5904 - val_accuracy: 0.3732 - val_precision: 0.7200 - val_recall: 0.1268\n",
      "Epoch 27/200\n",
      "426/426 - 1s - loss: 1.5480 - accuracy: 0.3779 - precision: 0.7019 - recall: 0.1714 - val_loss: 1.6298 - val_accuracy: 0.2887 - val_precision: 0.7308 - val_recall: 0.1338\n",
      "Epoch 28/200\n",
      "426/426 - 1s - loss: 1.5274 - accuracy: 0.4225 - precision: 0.7053 - recall: 0.1573 - val_loss: 1.6167 - val_accuracy: 0.3169 - val_precision: 0.6429 - val_recall: 0.1268\n",
      "Epoch 29/200\n",
      "426/426 - 1s - loss: 1.4936 - accuracy: 0.4108 - precision: 0.7156 - recall: 0.1831 - val_loss: 1.6598 - val_accuracy: 0.2958 - val_precision: 0.6286 - val_recall: 0.1549\n",
      "Epoch 30/200\n",
      "426/426 - 1s - loss: 1.4819 - accuracy: 0.4225 - precision: 0.6961 - recall: 0.1667 - val_loss: 1.6115 - val_accuracy: 0.3239 - val_precision: 0.7143 - val_recall: 0.1408\n",
      "Epoch 31/200\n",
      "426/426 - 1s - loss: 1.4753 - accuracy: 0.4296 - precision: 0.7570 - recall: 0.1901 - val_loss: 1.5979 - val_accuracy: 0.3521 - val_precision: 0.6875 - val_recall: 0.1549\n",
      "Epoch 32/200\n",
      "426/426 - 1s - loss: 1.4454 - accuracy: 0.4413 - precision: 0.7411 - recall: 0.1948 - val_loss: 1.5493 - val_accuracy: 0.3521 - val_precision: 0.5588 - val_recall: 0.1338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200\n",
      "426/426 - 1s - loss: 1.3850 - accuracy: 0.4624 - precision: 0.7719 - recall: 0.2066 - val_loss: 1.4748 - val_accuracy: 0.4014 - val_precision: 0.6600 - val_recall: 0.2324\n",
      "Epoch 34/200\n",
      "426/426 - 1s - loss: 1.3348 - accuracy: 0.4930 - precision: 0.7682 - recall: 0.2723 - val_loss: 1.4313 - val_accuracy: 0.4437 - val_precision: 0.7547 - val_recall: 0.2817\n",
      "Epoch 35/200\n",
      "426/426 - 1s - loss: 1.3577 - accuracy: 0.4718 - precision: 0.6614 - recall: 0.2934 - val_loss: 1.6190 - val_accuracy: 0.3662 - val_precision: 0.6667 - val_recall: 0.2254\n",
      "Epoch 36/200\n",
      "426/426 - 1s - loss: 1.4989 - accuracy: 0.4108 - precision: 0.6645 - recall: 0.2371 - val_loss: 1.4719 - val_accuracy: 0.4155 - val_precision: 0.6290 - val_recall: 0.2746\n",
      "Epoch 37/200\n",
      "426/426 - 1s - loss: 1.3575 - accuracy: 0.4648 - precision: 0.7564 - recall: 0.2770 - val_loss: 1.5446 - val_accuracy: 0.3944 - val_precision: 0.7447 - val_recall: 0.2465\n",
      "Epoch 38/200\n",
      "426/426 - 1s - loss: 1.4180 - accuracy: 0.4390 - precision: 0.7500 - recall: 0.2606 - val_loss: 1.4287 - val_accuracy: 0.3873 - val_precision: 0.7609 - val_recall: 0.2465\n",
      "Epoch 39/200\n",
      "426/426 - 1s - loss: 1.3312 - accuracy: 0.4695 - precision: 0.7603 - recall: 0.2606 - val_loss: 1.3819 - val_accuracy: 0.4155 - val_precision: 0.7826 - val_recall: 0.2535\n",
      "Epoch 40/200\n",
      "426/426 - 1s - loss: 1.3295 - accuracy: 0.4671 - precision: 0.7267 - recall: 0.2559 - val_loss: 1.4556 - val_accuracy: 0.3380 - val_precision: 0.8250 - val_recall: 0.2324\n",
      "Epoch 41/200\n",
      "426/426 - 1s - loss: 1.2826 - accuracy: 0.4953 - precision: 0.7961 - recall: 0.2840 - val_loss: 1.3953 - val_accuracy: 0.4225 - val_precision: 0.7500 - val_recall: 0.2746\n",
      "Epoch 42/200\n",
      "426/426 - 1s - loss: 1.2844 - accuracy: 0.4859 - precision: 0.7875 - recall: 0.2958 - val_loss: 1.4175 - val_accuracy: 0.4225 - val_precision: 0.7083 - val_recall: 0.2394\n",
      "Epoch 43/200\n",
      "426/426 - 1s - loss: 1.2830 - accuracy: 0.4859 - precision: 0.7947 - recall: 0.2817 - val_loss: 1.3903 - val_accuracy: 0.4155 - val_precision: 0.7609 - val_recall: 0.2465\n",
      "Epoch 44/200\n",
      "426/426 - 1s - loss: 1.2201 - accuracy: 0.5188 - precision: 0.8012 - recall: 0.3122 - val_loss: 1.3619 - val_accuracy: 0.4296 - val_precision: 0.7692 - val_recall: 0.2817\n",
      "Epoch 45/200\n",
      "426/426 - 1s - loss: 1.2503 - accuracy: 0.4789 - precision: 0.7418 - recall: 0.3169 - val_loss: 1.3674 - val_accuracy: 0.4014 - val_precision: 0.7368 - val_recall: 0.2958\n",
      "Epoch 46/200\n",
      "426/426 - 1s - loss: 1.2830 - accuracy: 0.5070 - precision: 0.7485 - recall: 0.2864 - val_loss: 1.4285 - val_accuracy: 0.4225 - val_precision: 0.7083 - val_recall: 0.2394\n",
      "Epoch 47/200\n",
      "426/426 - 1s - loss: 1.2721 - accuracy: 0.5000 - precision: 0.7987 - recall: 0.2887 - val_loss: 1.5139 - val_accuracy: 0.3521 - val_precision: 0.6800 - val_recall: 0.2394\n",
      "Epoch 48/200\n",
      "426/426 - 1s - loss: 1.3238 - accuracy: 0.4765 - precision: 0.7771 - recall: 0.2864 - val_loss: 1.3183 - val_accuracy: 0.4648 - val_precision: 0.7636 - val_recall: 0.2958\n",
      "Epoch 49/200\n",
      "426/426 - 1s - loss: 1.2406 - accuracy: 0.4977 - precision: 0.7614 - recall: 0.3146 - val_loss: 1.2757 - val_accuracy: 0.4507 - val_precision: 0.7895 - val_recall: 0.3169\n",
      "Epoch 50/200\n",
      "426/426 - 1s - loss: 1.3259 - accuracy: 0.5117 - precision: 0.7158 - recall: 0.3192 - val_loss: 1.6167 - val_accuracy: 0.3451 - val_precision: 0.6744 - val_recall: 0.2042\n",
      "Epoch 51/200\n",
      "426/426 - 1s - loss: 1.2837 - accuracy: 0.5000 - precision: 0.7784 - recall: 0.3052 - val_loss: 1.3858 - val_accuracy: 0.4507 - val_precision: 0.7167 - val_recall: 0.3028\n",
      "Epoch 52/200\n",
      "426/426 - 1s - loss: 1.2191 - accuracy: 0.5070 - precision: 0.8011 - recall: 0.3404 - val_loss: 1.4657 - val_accuracy: 0.4085 - val_precision: 0.7547 - val_recall: 0.2817\n",
      "Epoch 53/200\n",
      "426/426 - 1s - loss: 1.1976 - accuracy: 0.5258 - precision: 0.8043 - recall: 0.3474 - val_loss: 1.3067 - val_accuracy: 0.4648 - val_precision: 0.7500 - val_recall: 0.3169\n",
      "Epoch 54/200\n",
      "426/426 - 1s - loss: 1.2158 - accuracy: 0.5023 - precision: 0.7650 - recall: 0.3286 - val_loss: 1.3198 - val_accuracy: 0.4437 - val_precision: 0.7742 - val_recall: 0.3380\n",
      "Epoch 55/200\n",
      "426/426 - 1s - loss: 1.2048 - accuracy: 0.5164 - precision: 0.7565 - recall: 0.3427 - val_loss: 1.4944 - val_accuracy: 0.3592 - val_precision: 0.6207 - val_recall: 0.2535\n",
      "Epoch 56/200\n",
      "426/426 - 1s - loss: 1.2354 - accuracy: 0.4883 - precision: 0.7814 - recall: 0.3357 - val_loss: 1.2869 - val_accuracy: 0.4507 - val_precision: 0.7818 - val_recall: 0.3028\n",
      "Epoch 57/200\n",
      "426/426 - 1s - loss: 1.1439 - accuracy: 0.5493 - precision: 0.8177 - recall: 0.3474 - val_loss: 1.2941 - val_accuracy: 0.4789 - val_precision: 0.7705 - val_recall: 0.3310\n",
      "Epoch 58/200\n",
      "426/426 - 1s - loss: 1.1558 - accuracy: 0.5845 - precision: 0.7824 - recall: 0.3545 - val_loss: 1.4057 - val_accuracy: 0.3944 - val_precision: 0.6721 - val_recall: 0.2887\n",
      "Epoch 59/200\n",
      "426/426 - 1s - loss: 1.1597 - accuracy: 0.5681 - precision: 0.7978 - recall: 0.3427 - val_loss: 1.3681 - val_accuracy: 0.4366 - val_precision: 0.7333 - val_recall: 0.3099\n",
      "Epoch 60/200\n",
      "426/426 - 1s - loss: 1.1289 - accuracy: 0.5540 - precision: 0.8111 - recall: 0.3427 - val_loss: 1.3150 - val_accuracy: 0.4648 - val_precision: 0.7719 - val_recall: 0.3099\n",
      "Epoch 61/200\n",
      "426/426 - 1s - loss: 1.0856 - accuracy: 0.5775 - precision: 0.8000 - recall: 0.3662 - val_loss: 1.3113 - val_accuracy: 0.4437 - val_precision: 0.7541 - val_recall: 0.3239\n",
      "Epoch 62/200\n",
      "426/426 - 1s - loss: 1.0393 - accuracy: 0.5892 - precision: 0.8250 - recall: 0.3873 - val_loss: 1.3063 - val_accuracy: 0.4648 - val_precision: 0.7692 - val_recall: 0.3521\n",
      "Epoch 63/200\n",
      "426/426 - 1s - loss: 1.0261 - accuracy: 0.5915 - precision: 0.8778 - recall: 0.3709 - val_loss: 1.2553 - val_accuracy: 0.4718 - val_precision: 0.8333 - val_recall: 0.3521\n",
      "Epoch 64/200\n",
      "426/426 - 1s - loss: 1.1193 - accuracy: 0.5516 - precision: 0.7628 - recall: 0.3850 - val_loss: 1.4086 - val_accuracy: 0.3873 - val_precision: 0.6027 - val_recall: 0.3099\n",
      "Epoch 65/200\n",
      "426/426 - 1s - loss: 1.1844 - accuracy: 0.5446 - precision: 0.7462 - recall: 0.3451 - val_loss: 1.4623 - val_accuracy: 0.3732 - val_precision: 0.7115 - val_recall: 0.2606\n",
      "Epoch 66/200\n",
      "426/426 - 1s - loss: 1.1478 - accuracy: 0.5610 - precision: 0.8588 - recall: 0.3427 - val_loss: 1.2564 - val_accuracy: 0.4859 - val_precision: 0.7627 - val_recall: 0.3169\n",
      "Epoch 67/200\n",
      "426/426 - 1s - loss: 1.0955 - accuracy: 0.5962 - precision: 0.8191 - recall: 0.3615 - val_loss: 1.2163 - val_accuracy: 0.5070 - val_precision: 0.7656 - val_recall: 0.3451\n",
      "Epoch 68/200\n",
      "426/426 - 1s - loss: 1.0703 - accuracy: 0.5775 - precision: 0.7696 - recall: 0.3920 - val_loss: 1.3263 - val_accuracy: 0.4648 - val_precision: 0.6765 - val_recall: 0.3239\n",
      "Epoch 69/200\n",
      "426/426 - 1s - loss: 1.0558 - accuracy: 0.5939 - precision: 0.8048 - recall: 0.3967 - val_loss: 1.2818 - val_accuracy: 0.4718 - val_precision: 0.7576 - val_recall: 0.3521\n",
      "Epoch 70/200\n",
      "426/426 - 1s - loss: 1.3190 - accuracy: 0.4977 - precision: 0.7292 - recall: 0.3286 - val_loss: 1.4718 - val_accuracy: 0.3662 - val_precision: 0.6491 - val_recall: 0.2606\n",
      "Epoch 71/200\n",
      "426/426 - 1s - loss: 1.1961 - accuracy: 0.5399 - precision: 0.7079 - recall: 0.3357 - val_loss: 1.2599 - val_accuracy: 0.4930 - val_precision: 0.7719 - val_recall: 0.3099\n",
      "Epoch 72/200\n",
      "426/426 - 1s - loss: 1.0325 - accuracy: 0.5915 - precision: 0.8241 - recall: 0.3850 - val_loss: 1.2679 - val_accuracy: 0.4789 - val_precision: 0.7302 - val_recall: 0.3239\n",
      "Epoch 73/200\n",
      "426/426 - 1s - loss: 0.9530 - accuracy: 0.6315 - precision: 0.8654 - recall: 0.4225 - val_loss: 1.2336 - val_accuracy: 0.5211 - val_precision: 0.7101 - val_recall: 0.3451\n",
      "Epoch 74/200\n",
      "426/426 - 1s - loss: 0.9031 - accuracy: 0.6620 - precision: 0.8292 - recall: 0.4671 - val_loss: 1.1631 - val_accuracy: 0.5704 - val_precision: 0.7200 - val_recall: 0.3803\n",
      "Epoch 75/200\n",
      "426/426 - 1s - loss: 0.8755 - accuracy: 0.6925 - precision: 0.8618 - recall: 0.4977 - val_loss: 1.2341 - val_accuracy: 0.5282 - val_precision: 0.6712 - val_recall: 0.3451\n",
      "Epoch 76/200\n",
      "426/426 - 1s - loss: 0.8638 - accuracy: 0.7136 - precision: 0.8600 - recall: 0.5047 - val_loss: 1.0871 - val_accuracy: 0.6056 - val_precision: 0.7160 - val_recall: 0.4085\n",
      "Epoch 77/200\n",
      "426/426 - 1s - loss: 0.8594 - accuracy: 0.6854 - precision: 0.8218 - recall: 0.5305 - val_loss: 1.0720 - val_accuracy: 0.6268 - val_precision: 0.7531 - val_recall: 0.4296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/200\n",
      "426/426 - 1s - loss: 1.0501 - accuracy: 0.6362 - precision: 0.7500 - recall: 0.4718 - val_loss: 1.1077 - val_accuracy: 0.5986 - val_precision: 0.7126 - val_recall: 0.4366\n",
      "Epoch 79/200\n",
      "426/426 - 1s - loss: 0.9230 - accuracy: 0.6690 - precision: 0.7810 - recall: 0.5023 - val_loss: 1.1327 - val_accuracy: 0.5563 - val_precision: 0.6782 - val_recall: 0.4155\n",
      "Epoch 80/200\n",
      "426/426 - 1s - loss: 0.8245 - accuracy: 0.6714 - precision: 0.8109 - recall: 0.5235 - val_loss: 0.9620 - val_accuracy: 0.5986 - val_precision: 0.7595 - val_recall: 0.4225\n",
      "Epoch 81/200\n",
      "426/426 - 1s - loss: 0.7405 - accuracy: 0.7042 - precision: 0.8316 - recall: 0.5563 - val_loss: 1.0711 - val_accuracy: 0.5775 - val_precision: 0.7619 - val_recall: 0.4507\n",
      "Epoch 82/200\n",
      "426/426 - 1s - loss: 0.8685 - accuracy: 0.6643 - precision: 0.8237 - recall: 0.5376 - val_loss: 1.1316 - val_accuracy: 0.5986 - val_precision: 0.7229 - val_recall: 0.4225\n",
      "Epoch 83/200\n",
      "426/426 - 1s - loss: 0.8674 - accuracy: 0.6784 - precision: 0.7957 - recall: 0.5211 - val_loss: 1.0891 - val_accuracy: 0.5634 - val_precision: 0.7531 - val_recall: 0.4296\n",
      "Epoch 84/200\n",
      "426/426 - 1s - loss: 0.8023 - accuracy: 0.6784 - precision: 0.8298 - recall: 0.5493 - val_loss: 1.0377 - val_accuracy: 0.6056 - val_precision: 0.7556 - val_recall: 0.4789\n",
      "Epoch 85/200\n",
      "426/426 - 1s - loss: 0.7861 - accuracy: 0.6948 - precision: 0.8453 - recall: 0.5516 - val_loss: 1.1893 - val_accuracy: 0.5986 - val_precision: 0.6667 - val_recall: 0.3944\n",
      "Epoch 86/200\n",
      "426/426 - 1s - loss: 0.8963 - accuracy: 0.6620 - precision: 0.8147 - recall: 0.4953 - val_loss: 1.0404 - val_accuracy: 0.5915 - val_precision: 0.7065 - val_recall: 0.4577\n",
      "Epoch 87/200\n",
      "426/426 - 1s - loss: 0.6747 - accuracy: 0.7418 - precision: 0.8482 - recall: 0.6033 - val_loss: 1.0069 - val_accuracy: 0.6127 - val_precision: 0.6900 - val_recall: 0.4859\n",
      "Epoch 88/200\n",
      "426/426 - 1s - loss: 0.6350 - accuracy: 0.7746 - precision: 0.8478 - recall: 0.6408 - val_loss: 0.9414 - val_accuracy: 0.6620 - val_precision: 0.7451 - val_recall: 0.5352\n",
      "Epoch 89/200\n",
      "426/426 - 1s - loss: 0.6111 - accuracy: 0.7723 - precision: 0.8818 - recall: 0.6479 - val_loss: 0.9776 - val_accuracy: 0.6127 - val_precision: 0.7238 - val_recall: 0.5352\n",
      "Epoch 90/200\n",
      "426/426 - 1s - loss: 0.5878 - accuracy: 0.7911 - precision: 0.8679 - recall: 0.6784 - val_loss: 0.9251 - val_accuracy: 0.6338 - val_precision: 0.7228 - val_recall: 0.5141\n",
      "Epoch 91/200\n",
      "426/426 - 1s - loss: 0.5943 - accuracy: 0.7770 - precision: 0.8550 - recall: 0.6784 - val_loss: 0.8839 - val_accuracy: 0.6479 - val_precision: 0.7232 - val_recall: 0.5704\n",
      "Epoch 92/200\n",
      "426/426 - 1s - loss: 0.5502 - accuracy: 0.7840 - precision: 0.8592 - recall: 0.7160 - val_loss: 0.9548 - val_accuracy: 0.6408 - val_precision: 0.7048 - val_recall: 0.5211\n",
      "Epoch 93/200\n",
      "426/426 - 1s - loss: 0.5867 - accuracy: 0.7746 - precision: 0.8685 - recall: 0.6667 - val_loss: 1.2704 - val_accuracy: 0.5423 - val_precision: 0.6121 - val_recall: 0.5000\n",
      "Epoch 94/200\n",
      "426/426 - 1s - loss: 0.8288 - accuracy: 0.6878 - precision: 0.7844 - recall: 0.6150 - val_loss: 0.9076 - val_accuracy: 0.6549 - val_precision: 0.7835 - val_recall: 0.5352\n",
      "Epoch 95/200\n",
      "426/426 - 1s - loss: 0.5466 - accuracy: 0.7887 - precision: 0.8886 - recall: 0.6925 - val_loss: 0.9068 - val_accuracy: 0.6268 - val_precision: 0.7193 - val_recall: 0.5775\n",
      "Epoch 96/200\n",
      "426/426 - 1s - loss: 0.5219 - accuracy: 0.7958 - precision: 0.8802 - recall: 0.7418 - val_loss: 0.8852 - val_accuracy: 0.6549 - val_precision: 0.7155 - val_recall: 0.5845\n",
      "Epoch 97/200\n",
      "426/426 - 1s - loss: 0.5187 - accuracy: 0.8169 - precision: 0.8659 - recall: 0.7277 - val_loss: 0.8541 - val_accuracy: 0.6620 - val_precision: 0.7257 - val_recall: 0.5775\n",
      "Epoch 98/200\n",
      "426/426 - 1s - loss: 0.5009 - accuracy: 0.8146 - precision: 0.8736 - recall: 0.7300 - val_loss: 0.8632 - val_accuracy: 0.6901 - val_precision: 0.7203 - val_recall: 0.5986\n",
      "Epoch 99/200\n",
      "426/426 - 1s - loss: 0.5041 - accuracy: 0.8099 - precision: 0.8873 - recall: 0.7207 - val_loss: 0.8860 - val_accuracy: 0.6479 - val_precision: 0.7297 - val_recall: 0.5704\n",
      "Epoch 100/200\n",
      "426/426 - 1s - loss: 0.5299 - accuracy: 0.8169 - precision: 0.8698 - recall: 0.7371 - val_loss: 1.0228 - val_accuracy: 0.6268 - val_precision: 0.7105 - val_recall: 0.5704\n",
      "Epoch 101/200\n",
      "426/426 - 0s - loss: 0.5960 - accuracy: 0.7817 - precision: 0.8421 - recall: 0.7136 - val_loss: 0.9493 - val_accuracy: 0.6690 - val_precision: 0.7043 - val_recall: 0.5704\n",
      "Epoch 102/200\n",
      "426/426 - 1s - loss: 0.5586 - accuracy: 0.7817 - precision: 0.8315 - recall: 0.7066 - val_loss: 1.0204 - val_accuracy: 0.5986 - val_precision: 0.6371 - val_recall: 0.5563\n",
      "Epoch 103/200\n",
      "426/426 - 1s - loss: 0.5039 - accuracy: 0.8028 - precision: 0.8839 - recall: 0.7324 - val_loss: 0.8528 - val_accuracy: 0.6972 - val_precision: 0.7258 - val_recall: 0.6338\n",
      "Epoch 104/200\n",
      "426/426 - 1s - loss: 0.5436 - accuracy: 0.7958 - precision: 0.8408 - recall: 0.7441 - val_loss: 0.9991 - val_accuracy: 0.6408 - val_precision: 0.6720 - val_recall: 0.5915\n",
      "Epoch 105/200\n",
      "426/426 - 1s - loss: 0.5264 - accuracy: 0.8099 - precision: 0.8591 - recall: 0.7441 - val_loss: 0.9541 - val_accuracy: 0.6408 - val_precision: 0.6860 - val_recall: 0.5845\n",
      "Epoch 106/200\n",
      "426/426 - 1s - loss: 0.4657 - accuracy: 0.8310 - precision: 0.8871 - recall: 0.7559 - val_loss: 0.8793 - val_accuracy: 0.7042 - val_precision: 0.7203 - val_recall: 0.5986\n",
      "Epoch 107/200\n",
      "426/426 - 1s - loss: 0.4776 - accuracy: 0.8099 - precision: 0.8605 - recall: 0.7676 - val_loss: 0.9328 - val_accuracy: 0.6408 - val_precision: 0.6911 - val_recall: 0.5986\n",
      "Epoch 108/200\n",
      "426/426 - 1s - loss: 0.5744 - accuracy: 0.8099 - precision: 0.8429 - recall: 0.7559 - val_loss: 0.8717 - val_accuracy: 0.6831 - val_precision: 0.7097 - val_recall: 0.6197\n",
      "Epoch 109/200\n",
      "426/426 - 1s - loss: 0.6283 - accuracy: 0.7582 - precision: 0.8043 - recall: 0.6948 - val_loss: 0.8617 - val_accuracy: 0.6831 - val_precision: 0.7188 - val_recall: 0.6479\n",
      "Epoch 110/200\n",
      "426/426 - 1s - loss: 0.4426 - accuracy: 0.8451 - precision: 0.8907 - recall: 0.7840 - val_loss: 0.9052 - val_accuracy: 0.6761 - val_precision: 0.7258 - val_recall: 0.6338\n",
      "Epoch 111/200\n",
      "426/426 - 1s - loss: 0.4639 - accuracy: 0.8286 - precision: 0.8538 - recall: 0.7817 - val_loss: 0.9237 - val_accuracy: 0.6761 - val_precision: 0.7222 - val_recall: 0.6408\n",
      "Epoch 112/200\n",
      "426/426 - 1s - loss: 0.4992 - accuracy: 0.7911 - precision: 0.8264 - recall: 0.7488 - val_loss: 1.0367 - val_accuracy: 0.5704 - val_precision: 0.6496 - val_recall: 0.5352\n",
      "Epoch 113/200\n",
      "426/426 - 1s - loss: 0.5378 - accuracy: 0.7840 - precision: 0.8338 - recall: 0.7300 - val_loss: 0.8350 - val_accuracy: 0.6761 - val_precision: 0.7167 - val_recall: 0.6056\n",
      "Epoch 114/200\n",
      "426/426 - 1s - loss: 0.4703 - accuracy: 0.8310 - precision: 0.8670 - recall: 0.7653 - val_loss: 0.8619 - val_accuracy: 0.6831 - val_precision: 0.7063 - val_recall: 0.6268\n",
      "Epoch 115/200\n",
      "426/426 - 1s - loss: 0.4322 - accuracy: 0.8427 - precision: 0.8851 - recall: 0.7958 - val_loss: 0.9109 - val_accuracy: 0.6831 - val_precision: 0.7188 - val_recall: 0.6479\n",
      "Epoch 116/200\n",
      "426/426 - 1s - loss: 0.4050 - accuracy: 0.8545 - precision: 0.8759 - recall: 0.8286 - val_loss: 0.8933 - val_accuracy: 0.6761 - val_precision: 0.7231 - val_recall: 0.6620\n",
      "Epoch 117/200\n",
      "426/426 - 1s - loss: 0.5533 - accuracy: 0.7840 - precision: 0.8205 - recall: 0.7512 - val_loss: 1.1303 - val_accuracy: 0.6549 - val_precision: 0.6960 - val_recall: 0.6127\n",
      "Epoch 118/200\n",
      "426/426 - 1s - loss: 0.4835 - accuracy: 0.8427 - precision: 0.8793 - recall: 0.7864 - val_loss: 0.8448 - val_accuracy: 0.6831 - val_precision: 0.7200 - val_recall: 0.6338\n",
      "Epoch 119/200\n",
      "426/426 - 1s - loss: 0.4322 - accuracy: 0.8521 - precision: 0.8883 - recall: 0.8028 - val_loss: 0.8982 - val_accuracy: 0.7042 - val_precision: 0.7143 - val_recall: 0.6690\n",
      "Epoch 120/200\n",
      "426/426 - 1s - loss: 0.4021 - accuracy: 0.8638 - precision: 0.9093 - recall: 0.8239 - val_loss: 0.8641 - val_accuracy: 0.6901 - val_precision: 0.7302 - val_recall: 0.6479\n",
      "Epoch 121/200\n",
      "426/426 - 1s - loss: 0.3078 - accuracy: 0.9038 - precision: 0.9332 - recall: 0.8850 - val_loss: 0.9154 - val_accuracy: 0.6831 - val_precision: 0.7120 - val_recall: 0.6268\n",
      "Epoch 122/200\n",
      "426/426 - 1s - loss: 0.3199 - accuracy: 0.9014 - precision: 0.9158 - recall: 0.8685 - val_loss: 0.7866 - val_accuracy: 0.7465 - val_precision: 0.7760 - val_recall: 0.6831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "426/426 - 1s - loss: 0.3440 - accuracy: 0.8732 - precision: 0.9128 - recall: 0.8357 - val_loss: 0.8317 - val_accuracy: 0.7113 - val_precision: 0.7405 - val_recall: 0.6831\n",
      "Epoch 124/200\n",
      "426/426 - 1s - loss: 0.3158 - accuracy: 0.9038 - precision: 0.9153 - recall: 0.8873 - val_loss: 0.8668 - val_accuracy: 0.7183 - val_precision: 0.7154 - val_recall: 0.6549\n",
      "Epoch 125/200\n",
      "426/426 - 1s - loss: 0.3054 - accuracy: 0.8920 - precision: 0.9193 - recall: 0.8826 - val_loss: 0.8689 - val_accuracy: 0.7113 - val_precision: 0.7176 - val_recall: 0.6620\n",
      "Epoch 126/200\n",
      "426/426 - 1s - loss: 0.3257 - accuracy: 0.8638 - precision: 0.8881 - recall: 0.8568 - val_loss: 0.8582 - val_accuracy: 0.6972 - val_precision: 0.7164 - val_recall: 0.6761\n",
      "Epoch 127/200\n",
      "426/426 - 1s - loss: 0.3595 - accuracy: 0.8803 - precision: 0.9132 - recall: 0.8638 - val_loss: 0.8353 - val_accuracy: 0.7254 - val_precision: 0.7557 - val_recall: 0.6972\n",
      "Epoch 128/200\n",
      "426/426 - 1s - loss: 0.3728 - accuracy: 0.8756 - precision: 0.8886 - recall: 0.8615 - val_loss: 1.0281 - val_accuracy: 0.6690 - val_precision: 0.6963 - val_recall: 0.6620\n",
      "Epoch 129/200\n",
      "426/426 - 1s - loss: 0.3466 - accuracy: 0.8756 - precision: 0.8859 - recall: 0.8568 - val_loss: 0.8522 - val_accuracy: 0.7324 - val_precision: 0.7656 - val_recall: 0.6901\n",
      "Epoch 130/200\n",
      "426/426 - 1s - loss: 0.3198 - accuracy: 0.8873 - precision: 0.9320 - recall: 0.8685 - val_loss: 1.1100 - val_accuracy: 0.6620 - val_precision: 0.6815 - val_recall: 0.6479\n",
      "Epoch 131/200\n",
      "426/426 - 1s - loss: 0.3548 - accuracy: 0.8709 - precision: 0.9035 - recall: 0.8568 - val_loss: 0.8156 - val_accuracy: 0.7394 - val_precision: 0.7674 - val_recall: 0.6972\n",
      "Epoch 132/200\n",
      "426/426 - 1s - loss: 0.2741 - accuracy: 0.9108 - precision: 0.9401 - recall: 0.8850 - val_loss: 0.9728 - val_accuracy: 0.6761 - val_precision: 0.6977 - val_recall: 0.6338\n",
      "Epoch 133/200\n",
      "426/426 - 1s - loss: 0.3086 - accuracy: 0.8920 - precision: 0.9183 - recall: 0.8709 - val_loss: 0.8565 - val_accuracy: 0.7535 - val_precision: 0.7761 - val_recall: 0.7324\n",
      "Epoch 134/200\n",
      "426/426 - 1s - loss: 0.2658 - accuracy: 0.9108 - precision: 0.9251 - recall: 0.8991 - val_loss: 0.8528 - val_accuracy: 0.7465 - val_precision: 0.7786 - val_recall: 0.7183\n",
      "Epoch 135/200\n",
      "426/426 - 1s - loss: 0.2690 - accuracy: 0.8991 - precision: 0.9223 - recall: 0.8920 - val_loss: 0.8772 - val_accuracy: 0.7183 - val_precision: 0.7519 - val_recall: 0.7042\n",
      "Epoch 136/200\n",
      "426/426 - 1s - loss: 0.3831 - accuracy: 0.8756 - precision: 0.8946 - recall: 0.8568 - val_loss: 1.0816 - val_accuracy: 0.6901 - val_precision: 0.7231 - val_recall: 0.6620\n",
      "Epoch 137/200\n",
      "426/426 - 1s - loss: 0.4926 - accuracy: 0.8521 - precision: 0.8639 - recall: 0.8192 - val_loss: 0.9125 - val_accuracy: 0.7183 - val_precision: 0.7308 - val_recall: 0.6690\n",
      "Epoch 138/200\n",
      "426/426 - 1s - loss: 0.4129 - accuracy: 0.8521 - precision: 0.8617 - recall: 0.8192 - val_loss: 0.9692 - val_accuracy: 0.6972 - val_precision: 0.7308 - val_recall: 0.6690\n",
      "Epoch 139/200\n",
      "426/426 - 1s - loss: 0.3705 - accuracy: 0.8826 - precision: 0.9042 - recall: 0.8638 - val_loss: 0.9042 - val_accuracy: 0.6901 - val_precision: 0.7308 - val_recall: 0.6690\n",
      "Epoch 140/200\n",
      "426/426 - 1s - loss: 0.3513 - accuracy: 0.8803 - precision: 0.9005 - recall: 0.8498 - val_loss: 0.9868 - val_accuracy: 0.6831 - val_precision: 0.7007 - val_recall: 0.6761\n",
      "Epoch 141/200\n",
      "426/426 - 1s - loss: 0.3910 - accuracy: 0.8756 - precision: 0.8960 - recall: 0.8498 - val_loss: 0.9639 - val_accuracy: 0.6549 - val_precision: 0.7200 - val_recall: 0.6338\n",
      "Epoch 142/200\n",
      "426/426 - 1s - loss: 0.3655 - accuracy: 0.8897 - precision: 0.9135 - recall: 0.8427 - val_loss: 1.0052 - val_accuracy: 0.6831 - val_precision: 0.7209 - val_recall: 0.6549\n",
      "Epoch 143/200\n",
      "426/426 - 1s - loss: 0.3004 - accuracy: 0.9108 - precision: 0.9319 - recall: 0.8991 - val_loss: 1.1170 - val_accuracy: 0.6268 - val_precision: 0.6567 - val_recall: 0.6197\n",
      "Epoch 144/200\n",
      "426/426 - 1s - loss: 0.3083 - accuracy: 0.8967 - precision: 0.9173 - recall: 0.8850 - val_loss: 0.8599 - val_accuracy: 0.7254 - val_precision: 0.7594 - val_recall: 0.7113\n",
      "Epoch 145/200\n",
      "426/426 - 1s - loss: 0.2637 - accuracy: 0.9085 - precision: 0.9358 - recall: 0.8897 - val_loss: 0.9663 - val_accuracy: 0.7113 - val_precision: 0.7405 - val_recall: 0.6831\n",
      "Epoch 146/200\n",
      "426/426 - 1s - loss: 0.3227 - accuracy: 0.8897 - precision: 0.9111 - recall: 0.8662 - val_loss: 1.0997 - val_accuracy: 0.6901 - val_precision: 0.7101 - val_recall: 0.6901\n",
      "Epoch 147/200\n",
      "426/426 - 1s - loss: 0.3858 - accuracy: 0.8685 - precision: 0.8741 - recall: 0.8638 - val_loss: 1.0972 - val_accuracy: 0.6549 - val_precision: 0.6692 - val_recall: 0.6268\n",
      "Epoch 148/200\n",
      "426/426 - 1s - loss: 0.3047 - accuracy: 0.8991 - precision: 0.9128 - recall: 0.8850 - val_loss: 0.9757 - val_accuracy: 0.6831 - val_precision: 0.7090 - val_recall: 0.6690\n",
      "Epoch 149/200\n",
      "426/426 - 1s - loss: 0.3624 - accuracy: 0.8732 - precision: 0.8814 - recall: 0.8545 - val_loss: 0.8724 - val_accuracy: 0.7183 - val_precision: 0.7519 - val_recall: 0.7042\n",
      "Epoch 150/200\n",
      "426/426 - 1s - loss: 0.3056 - accuracy: 0.8803 - precision: 0.8998 - recall: 0.8638 - val_loss: 0.8863 - val_accuracy: 0.7324 - val_precision: 0.7634 - val_recall: 0.7042\n",
      "Epoch 151/200\n",
      "426/426 - 1s - loss: 0.2274 - accuracy: 0.9272 - precision: 0.9440 - recall: 0.9108 - val_loss: 1.0011 - val_accuracy: 0.6831 - val_precision: 0.7111 - val_recall: 0.6761\n",
      "Epoch 152/200\n",
      "426/426 - 1s - loss: 0.4296 - accuracy: 0.8545 - precision: 0.8644 - recall: 0.8380 - val_loss: 0.9311 - val_accuracy: 0.7042 - val_precision: 0.7206 - val_recall: 0.6901\n",
      "Epoch 153/200\n",
      "426/426 - 1s - loss: 0.3552 - accuracy: 0.8779 - precision: 0.8929 - recall: 0.8615 - val_loss: 0.8947 - val_accuracy: 0.7042 - val_precision: 0.7308 - val_recall: 0.6690\n",
      "Epoch 154/200\n",
      "426/426 - 1s - loss: 0.3070 - accuracy: 0.8967 - precision: 0.9206 - recall: 0.8709 - val_loss: 0.8510 - val_accuracy: 0.7465 - val_precision: 0.7594 - val_recall: 0.7113\n",
      "Epoch 155/200\n",
      "426/426 - 1s - loss: 0.3471 - accuracy: 0.8685 - precision: 0.8811 - recall: 0.8521 - val_loss: 1.0035 - val_accuracy: 0.6761 - val_precision: 0.7090 - val_recall: 0.6690\n",
      "Epoch 156/200\n",
      "426/426 - 1s - loss: 0.3115 - accuracy: 0.8897 - precision: 0.8993 - recall: 0.8803 - val_loss: 0.9303 - val_accuracy: 0.7394 - val_precision: 0.7536 - val_recall: 0.7324\n",
      "Epoch 157/200\n",
      "426/426 - 1s - loss: 0.2750 - accuracy: 0.9061 - precision: 0.9189 - recall: 0.9038 - val_loss: 0.9807 - val_accuracy: 0.6972 - val_precision: 0.7313 - val_recall: 0.6901\n",
      "Epoch 158/200\n",
      "426/426 - 1s - loss: 0.2210 - accuracy: 0.9343 - precision: 0.9381 - recall: 0.9249 - val_loss: 0.9739 - val_accuracy: 0.6972 - val_precision: 0.7313 - val_recall: 0.6901\n",
      "Epoch 159/200\n",
      "426/426 - 1s - loss: 0.2182 - accuracy: 0.9249 - precision: 0.9415 - recall: 0.9061 - val_loss: 0.9319 - val_accuracy: 0.7183 - val_precision: 0.7500 - val_recall: 0.6972\n",
      "Epoch 160/200\n",
      "426/426 - 1s - loss: 0.2871 - accuracy: 0.9108 - precision: 0.9201 - recall: 0.8920 - val_loss: 0.9401 - val_accuracy: 0.7113 - val_precision: 0.7481 - val_recall: 0.6901\n",
      "Epoch 161/200\n",
      "426/426 - 1s - loss: 0.2350 - accuracy: 0.9272 - precision: 0.9392 - recall: 0.9061 - val_loss: 1.0508 - val_accuracy: 0.6972 - val_precision: 0.7153 - val_recall: 0.6901\n",
      "Epoch 162/200\n",
      "426/426 - 1s - loss: 0.2685 - accuracy: 0.9202 - precision: 0.9320 - recall: 0.9014 - val_loss: 0.8887 - val_accuracy: 0.7042 - val_precision: 0.7388 - val_recall: 0.6972\n",
      "Epoch 163/200\n",
      "426/426 - 1s - loss: 0.2296 - accuracy: 0.9225 - precision: 0.9415 - recall: 0.9061 - val_loss: 0.9055 - val_accuracy: 0.7254 - val_precision: 0.7391 - val_recall: 0.7183\n",
      "Epoch 164/200\n",
      "426/426 - 1s - loss: 0.1881 - accuracy: 0.9437 - precision: 0.9588 - recall: 0.9296 - val_loss: 0.9953 - val_accuracy: 0.6972 - val_precision: 0.7153 - val_recall: 0.6901\n",
      "Epoch 165/200\n",
      "426/426 - 1s - loss: 0.1627 - accuracy: 0.9484 - precision: 0.9639 - recall: 0.9390 - val_loss: 0.9330 - val_accuracy: 0.7254 - val_precision: 0.7537 - val_recall: 0.7113\n",
      "Epoch 166/200\n",
      "426/426 - 1s - loss: 0.1769 - accuracy: 0.9413 - precision: 0.9452 - recall: 0.9319 - val_loss: 0.9086 - val_accuracy: 0.7394 - val_precision: 0.7391 - val_recall: 0.7183\n",
      "Epoch 167/200\n",
      "426/426 - 1s - loss: 0.1948 - accuracy: 0.9390 - precision: 0.9474 - recall: 0.9296 - val_loss: 0.8928 - val_accuracy: 0.7465 - val_precision: 0.7482 - val_recall: 0.7324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/200\n",
      "426/426 - 1s - loss: 0.1453 - accuracy: 0.9577 - precision: 0.9643 - recall: 0.9507 - val_loss: 0.9043 - val_accuracy: 0.7535 - val_precision: 0.7647 - val_recall: 0.7324\n",
      "Epoch 169/200\n",
      "426/426 - 1s - loss: 0.2212 - accuracy: 0.9131 - precision: 0.9211 - recall: 0.9038 - val_loss: 1.3387 - val_accuracy: 0.6549 - val_precision: 0.6544 - val_recall: 0.6268\n",
      "Epoch 170/200\n",
      "426/426 - 1s - loss: 0.3348 - accuracy: 0.8944 - precision: 0.9122 - recall: 0.8779 - val_loss: 1.0391 - val_accuracy: 0.6972 - val_precision: 0.7111 - val_recall: 0.6761\n",
      "Epoch 171/200\n",
      "426/426 - 1s - loss: 0.2918 - accuracy: 0.8991 - precision: 0.9069 - recall: 0.8920 - val_loss: 0.9187 - val_accuracy: 0.7676 - val_precision: 0.7754 - val_recall: 0.7535\n",
      "Epoch 172/200\n",
      "426/426 - 1s - loss: 0.2169 - accuracy: 0.9249 - precision: 0.9396 - recall: 0.9131 - val_loss: 0.9802 - val_accuracy: 0.7042 - val_precision: 0.7206 - val_recall: 0.6901\n",
      "Epoch 173/200\n",
      "426/426 - 1s - loss: 0.1757 - accuracy: 0.9390 - precision: 0.9498 - recall: 0.9319 - val_loss: 0.9906 - val_accuracy: 0.6901 - val_precision: 0.6985 - val_recall: 0.6690\n",
      "Epoch 174/200\n",
      "426/426 - 1s - loss: 0.1805 - accuracy: 0.9460 - precision: 0.9594 - recall: 0.9437 - val_loss: 0.9773 - val_accuracy: 0.6901 - val_precision: 0.7259 - val_recall: 0.6901\n",
      "Epoch 175/200\n",
      "426/426 - 1s - loss: 0.1480 - accuracy: 0.9577 - precision: 0.9620 - recall: 0.9507 - val_loss: 0.9177 - val_accuracy: 0.7254 - val_precision: 0.7391 - val_recall: 0.7183\n",
      "Epoch 176/200\n",
      "426/426 - 1s - loss: 0.1262 - accuracy: 0.9671 - precision: 0.9716 - recall: 0.9648 - val_loss: 0.9062 - val_accuracy: 0.7394 - val_precision: 0.7574 - val_recall: 0.7254\n",
      "Epoch 177/200\n",
      "426/426 - 1s - loss: 0.1133 - accuracy: 0.9718 - precision: 0.9763 - recall: 0.9671 - val_loss: 0.9130 - val_accuracy: 0.7465 - val_precision: 0.7571 - val_recall: 0.7465\n",
      "Epoch 178/200\n",
      "426/426 - 1s - loss: 0.1056 - accuracy: 0.9742 - precision: 0.9810 - recall: 0.9718 - val_loss: 0.8887 - val_accuracy: 0.7465 - val_precision: 0.7778 - val_recall: 0.7394\n",
      "Epoch 179/200\n",
      "426/426 - 1s - loss: 0.1036 - accuracy: 0.9765 - precision: 0.9764 - recall: 0.9718 - val_loss: 0.9714 - val_accuracy: 0.7254 - val_precision: 0.7391 - val_recall: 0.7183\n",
      "Epoch 180/200\n",
      "426/426 - 1s - loss: 0.1654 - accuracy: 0.9437 - precision: 0.9455 - recall: 0.9366 - val_loss: 0.9368 - val_accuracy: 0.7465 - val_precision: 0.7609 - val_recall: 0.7394\n",
      "Epoch 181/200\n",
      "426/426 - 1s - loss: 0.1522 - accuracy: 0.9531 - precision: 0.9595 - recall: 0.9460 - val_loss: 1.0365 - val_accuracy: 0.7254 - val_precision: 0.7500 - val_recall: 0.7183\n",
      "Epoch 182/200\n",
      "426/426 - 1s - loss: 0.2103 - accuracy: 0.9272 - precision: 0.9382 - recall: 0.9272 - val_loss: 0.8276 - val_accuracy: 0.7676 - val_precision: 0.7810 - val_recall: 0.7535\n",
      "Epoch 183/200\n",
      "426/426 - 1s - loss: 0.1423 - accuracy: 0.9413 - precision: 0.9480 - recall: 0.9413 - val_loss: 0.8725 - val_accuracy: 0.7535 - val_precision: 0.7647 - val_recall: 0.7324\n",
      "Epoch 184/200\n",
      "426/426 - 1s - loss: 0.1179 - accuracy: 0.9671 - precision: 0.9717 - recall: 0.9671 - val_loss: 0.8849 - val_accuracy: 0.7535 - val_precision: 0.7778 - val_recall: 0.7394\n",
      "Epoch 185/200\n",
      "426/426 - 1s - loss: 0.1383 - accuracy: 0.9601 - precision: 0.9646 - recall: 0.9601 - val_loss: 0.8499 - val_accuracy: 0.7746 - val_precision: 0.7883 - val_recall: 0.7606\n",
      "Epoch 186/200\n",
      "426/426 - 1s - loss: 0.1115 - accuracy: 0.9718 - precision: 0.9741 - recall: 0.9718 - val_loss: 1.0083 - val_accuracy: 0.7183 - val_precision: 0.7194 - val_recall: 0.7042\n",
      "Epoch 187/200\n",
      "426/426 - 1s - loss: 0.3905 - accuracy: 0.8615 - precision: 0.8753 - recall: 0.8568 - val_loss: 0.9991 - val_accuracy: 0.6761 - val_precision: 0.7045 - val_recall: 0.6549\n",
      "Epoch 188/200\n",
      "426/426 - 1s - loss: 0.3099 - accuracy: 0.8803 - precision: 0.8935 - recall: 0.8662 - val_loss: 0.8688 - val_accuracy: 0.7183 - val_precision: 0.7537 - val_recall: 0.7113\n",
      "Epoch 189/200\n",
      "426/426 - 1s - loss: 0.2572 - accuracy: 0.9061 - precision: 0.9227 - recall: 0.8967 - val_loss: 0.9629 - val_accuracy: 0.7394 - val_precision: 0.7664 - val_recall: 0.7394\n",
      "Epoch 190/200\n",
      "426/426 - 1s - loss: 0.2982 - accuracy: 0.8897 - precision: 0.9118 - recall: 0.8732 - val_loss: 1.0210 - val_accuracy: 0.6901 - val_precision: 0.7164 - val_recall: 0.6761\n",
      "Epoch 191/200\n",
      "426/426 - 1s - loss: 0.2362 - accuracy: 0.9296 - precision: 0.9354 - recall: 0.9178 - val_loss: 0.8731 - val_accuracy: 0.7254 - val_precision: 0.7444 - val_recall: 0.6972\n",
      "Epoch 192/200\n",
      "426/426 - 1s - loss: 0.3436 - accuracy: 0.8803 - precision: 0.8892 - recall: 0.8662 - val_loss: 1.0951 - val_accuracy: 0.7042 - val_precision: 0.7226 - val_recall: 0.6972\n",
      "Epoch 193/200\n",
      "426/426 - 1s - loss: 0.3445 - accuracy: 0.8779 - precision: 0.8918 - recall: 0.8709 - val_loss: 1.3372 - val_accuracy: 0.6268 - val_precision: 0.6449 - val_recall: 0.6268\n",
      "Epoch 194/200\n",
      "426/426 - 1s - loss: 0.5288 - accuracy: 0.8146 - precision: 0.8252 - recall: 0.7981 - val_loss: 1.0377 - val_accuracy: 0.7042 - val_precision: 0.7143 - val_recall: 0.6690\n",
      "Epoch 195/200\n",
      "426/426 - 1s - loss: 0.4547 - accuracy: 0.8709 - precision: 0.8862 - recall: 0.8592 - val_loss: 0.8947 - val_accuracy: 0.6901 - val_precision: 0.7037 - val_recall: 0.6690\n",
      "Epoch 196/200\n",
      "426/426 - 1s - loss: 0.3233 - accuracy: 0.9014 - precision: 0.9157 - recall: 0.8920 - val_loss: 0.8925 - val_accuracy: 0.6972 - val_precision: 0.7308 - val_recall: 0.6690\n",
      "Epoch 197/200\n",
      "426/426 - 1s - loss: 0.2724 - accuracy: 0.9038 - precision: 0.9212 - recall: 0.8779 - val_loss: 0.9325 - val_accuracy: 0.7042 - val_precision: 0.7273 - val_recall: 0.6761\n",
      "Epoch 198/200\n",
      "426/426 - 1s - loss: 0.1852 - accuracy: 0.9507 - precision: 0.9547 - recall: 0.9390 - val_loss: 0.8818 - val_accuracy: 0.7394 - val_precision: 0.7612 - val_recall: 0.7183\n",
      "Epoch 199/200\n",
      "426/426 - 1s - loss: 0.1590 - accuracy: 0.9531 - precision: 0.9545 - recall: 0.9366 - val_loss: 0.9023 - val_accuracy: 0.7394 - val_precision: 0.7536 - val_recall: 0.7324\n",
      "Epoch 200/200\n",
      "426/426 - 1s - loss: 0.1683 - accuracy: 0.9366 - precision: 0.9429 - recall: 0.9296 - val_loss: 0.8824 - val_accuracy: 0.7535 - val_precision: 0.7591 - val_recall: 0.7324\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 192)          214272    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 192)          295680    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 128)          164352    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 64)           49408     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1164      \n",
      "=================================================================\n",
      "Total params: 786,700\n",
      "Trainable params: 786,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Adamax\n",
      "\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/200\n",
      "426/426 - 11s - loss: 2.4346 - accuracy: 0.1127 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3818 - val_accuracy: 0.1197 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      "426/426 - 1s - loss: 2.2894 - accuracy: 0.1995 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.2496 - val_accuracy: 0.1761 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/200\n",
      "426/426 - 1s - loss: 2.1150 - accuracy: 0.2300 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0557 - val_accuracy: 0.2324 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/200\n",
      "426/426 - 1s - loss: 1.9680 - accuracy: 0.2277 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9435 - val_accuracy: 0.1972 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/200\n",
      "426/426 - 1s - loss: 1.8892 - accuracy: 0.2629 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8192 - val_accuracy: 0.2676 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200\n",
      "426/426 - 1s - loss: 1.8310 - accuracy: 0.2840 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8041 - val_accuracy: 0.2113 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/200\n",
      "426/426 - 1s - loss: 1.7935 - accuracy: 0.2934 - precision: 0.5000 - recall: 0.0023 - val_loss: 1.7923 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/200\n",
      "426/426 - 1s - loss: 1.7866 - accuracy: 0.2934 - precision: 1.0000 - recall: 0.0023 - val_loss: 1.7659 - val_accuracy: 0.2465 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 9/200\n",
      "426/426 - 1s - loss: 1.7475 - accuracy: 0.3005 - precision: 0.5000 - recall: 0.0282 - val_loss: 1.7170 - val_accuracy: 0.2958 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 10/200\n",
      "426/426 - 1s - loss: 1.7273 - accuracy: 0.3099 - precision: 0.6667 - recall: 0.0141 - val_loss: 1.7379 - val_accuracy: 0.2606 - val_precision: 0.7500 - val_recall: 0.0211\n",
      "Epoch 11/200\n",
      "426/426 - 1s - loss: 1.6986 - accuracy: 0.3216 - precision: 0.5000 - recall: 0.0211 - val_loss: 1.7692 - val_accuracy: 0.2887 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 12/200\n",
      "426/426 - 1s - loss: 1.7180 - accuracy: 0.3474 - precision: 0.5652 - recall: 0.0305 - val_loss: 1.7731 - val_accuracy: 0.2394 - val_precision: 1.0000 - val_recall: 0.0141\n",
      "Epoch 13/200\n",
      "426/426 - 1s - loss: 1.7086 - accuracy: 0.3427 - precision: 0.7000 - recall: 0.0164 - val_loss: 1.5742 - val_accuracy: 0.3803 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 14/200\n",
      "426/426 - 1s - loss: 1.6144 - accuracy: 0.3498 - precision: 0.6667 - recall: 0.0235 - val_loss: 1.5855 - val_accuracy: 0.3099 - val_precision: 1.0000 - val_recall: 0.0845\n",
      "Epoch 15/200\n",
      "426/426 - 1s - loss: 1.6698 - accuracy: 0.3333 - precision: 0.6129 - recall: 0.0446 - val_loss: 1.5583 - val_accuracy: 0.3732 - val_precision: 0.7727 - val_recall: 0.1197\n",
      "Epoch 16/200\n",
      "426/426 - 1s - loss: 1.5731 - accuracy: 0.3685 - precision: 0.7091 - recall: 0.0915 - val_loss: 1.5215 - val_accuracy: 0.3380 - val_precision: 0.8889 - val_recall: 0.1127\n",
      "Epoch 17/200\n",
      "426/426 - 1s - loss: 1.5277 - accuracy: 0.3826 - precision: 0.7391 - recall: 0.0798 - val_loss: 1.5247 - val_accuracy: 0.3310 - val_precision: 1.0000 - val_recall: 0.1056\n",
      "Epoch 18/200\n",
      "426/426 - 1s - loss: 1.5301 - accuracy: 0.3803 - precision: 0.8000 - recall: 0.0845 - val_loss: 1.4777 - val_accuracy: 0.3662 - val_precision: 0.9412 - val_recall: 0.1127\n",
      "Epoch 19/200\n",
      "426/426 - 1s - loss: 1.5078 - accuracy: 0.4085 - precision: 0.6719 - recall: 0.1009 - val_loss: 1.4928 - val_accuracy: 0.3944 - val_precision: 0.8889 - val_recall: 0.1127\n",
      "Epoch 20/200\n",
      "426/426 - 1s - loss: 1.5236 - accuracy: 0.3850 - precision: 0.7273 - recall: 0.0939 - val_loss: 1.5125 - val_accuracy: 0.3662 - val_precision: 0.9444 - val_recall: 0.1197\n",
      "Epoch 21/200\n",
      "426/426 - 1s - loss: 1.5249 - accuracy: 0.3826 - precision: 0.6724 - recall: 0.0915 - val_loss: 1.4648 - val_accuracy: 0.3310 - val_precision: 0.8889 - val_recall: 0.1127\n",
      "Epoch 22/200\n",
      "426/426 - 1s - loss: 1.4692 - accuracy: 0.4178 - precision: 0.7719 - recall: 0.1033 - val_loss: 1.4599 - val_accuracy: 0.3873 - val_precision: 0.8947 - val_recall: 0.1197\n",
      "Epoch 23/200\n",
      "426/426 - 1s - loss: 1.5045 - accuracy: 0.3967 - precision: 0.7241 - recall: 0.0986 - val_loss: 1.5577 - val_accuracy: 0.3732 - val_precision: 0.8421 - val_recall: 0.1127\n",
      "Epoch 24/200\n",
      "426/426 - 1s - loss: 1.5814 - accuracy: 0.3803 - precision: 0.5854 - recall: 0.1127 - val_loss: 1.5633 - val_accuracy: 0.3521 - val_precision: 0.8889 - val_recall: 0.1127\n",
      "Epoch 25/200\n",
      "426/426 - 1s - loss: 1.4710 - accuracy: 0.4131 - precision: 0.7872 - recall: 0.0869 - val_loss: 1.4274 - val_accuracy: 0.3944 - val_precision: 0.8571 - val_recall: 0.1268\n",
      "Epoch 26/200\n",
      "426/426 - 1s - loss: 1.4560 - accuracy: 0.4108 - precision: 0.7581 - recall: 0.1103 - val_loss: 1.3911 - val_accuracy: 0.4366 - val_precision: 0.7407 - val_recall: 0.1408\n",
      "Epoch 27/200\n",
      "426/426 - 1s - loss: 1.4620 - accuracy: 0.3967 - precision: 0.7467 - recall: 0.1315 - val_loss: 1.4531 - val_accuracy: 0.3873 - val_precision: 0.7619 - val_recall: 0.1127\n",
      "Epoch 28/200\n",
      "426/426 - 1s - loss: 1.4698 - accuracy: 0.4014 - precision: 0.7419 - recall: 0.1080 - val_loss: 1.5821 - val_accuracy: 0.3310 - val_precision: 0.7619 - val_recall: 0.1127\n",
      "Epoch 29/200\n",
      "426/426 - 1s - loss: 1.5086 - accuracy: 0.4014 - precision: 0.6471 - recall: 0.1291 - val_loss: 1.5584 - val_accuracy: 0.3592 - val_precision: 0.7308 - val_recall: 0.1338\n",
      "Epoch 30/200\n",
      "426/426 - 1s - loss: 1.4786 - accuracy: 0.3944 - precision: 0.7612 - recall: 0.1197 - val_loss: 1.5231 - val_accuracy: 0.3380 - val_precision: 0.8421 - val_recall: 0.1127\n",
      "Epoch 31/200\n",
      "426/426 - 1s - loss: 1.4472 - accuracy: 0.4225 - precision: 0.7368 - recall: 0.1315 - val_loss: 1.4456 - val_accuracy: 0.4085 - val_precision: 0.8462 - val_recall: 0.1549\n",
      "Epoch 32/200\n",
      "426/426 - 1s - loss: 1.4233 - accuracy: 0.4296 - precision: 0.7209 - recall: 0.1455 - val_loss: 1.3873 - val_accuracy: 0.4366 - val_precision: 0.6944 - val_recall: 0.1761\n",
      "Epoch 33/200\n",
      "426/426 - 1s - loss: 1.4081 - accuracy: 0.4202 - precision: 0.7333 - recall: 0.1549 - val_loss: 1.4185 - val_accuracy: 0.3873 - val_precision: 0.7667 - val_recall: 0.1620\n",
      "Epoch 34/200\n",
      "426/426 - 1s - loss: 1.3927 - accuracy: 0.4531 - precision: 0.7172 - recall: 0.1667 - val_loss: 1.5107 - val_accuracy: 0.3592 - val_precision: 0.7143 - val_recall: 0.1761\n",
      "Epoch 35/200\n",
      "426/426 - 1s - loss: 1.4321 - accuracy: 0.4131 - precision: 0.7030 - recall: 0.1667 - val_loss: 1.4218 - val_accuracy: 0.3732 - val_precision: 0.7027 - val_recall: 0.1831\n",
      "Epoch 36/200\n",
      "426/426 - 1s - loss: 1.4012 - accuracy: 0.4507 - precision: 0.6719 - recall: 0.2019 - val_loss: 1.3489 - val_accuracy: 0.4366 - val_precision: 0.6444 - val_recall: 0.2042\n",
      "Epoch 37/200\n",
      "426/426 - 1s - loss: 1.3890 - accuracy: 0.4296 - precision: 0.6718 - recall: 0.2066 - val_loss: 1.4465 - val_accuracy: 0.3380 - val_precision: 0.6667 - val_recall: 0.1690\n",
      "Epoch 38/200\n",
      "426/426 - 1s - loss: 1.3565 - accuracy: 0.4554 - precision: 0.7232 - recall: 0.1901 - val_loss: 1.4216 - val_accuracy: 0.4085 - val_precision: 0.6444 - val_recall: 0.2042\n",
      "Epoch 39/200\n",
      "426/426 - 1s - loss: 1.3472 - accuracy: 0.4554 - precision: 0.6835 - recall: 0.2230 - val_loss: 1.3503 - val_accuracy: 0.4225 - val_precision: 0.6471 - val_recall: 0.2324\n",
      "Epoch 40/200\n",
      "426/426 - 1s - loss: 1.3356 - accuracy: 0.4695 - precision: 0.6815 - recall: 0.2160 - val_loss: 1.3695 - val_accuracy: 0.3803 - val_precision: 0.7692 - val_recall: 0.2113\n",
      "Epoch 41/200\n",
      "426/426 - 1s - loss: 1.3004 - accuracy: 0.5094 - precision: 0.7612 - recall: 0.2394 - val_loss: 1.3493 - val_accuracy: 0.4437 - val_precision: 0.6923 - val_recall: 0.2535\n",
      "Epoch 42/200\n",
      "426/426 - 1s - loss: 1.2877 - accuracy: 0.5070 - precision: 0.7550 - recall: 0.2676 - val_loss: 1.4320 - val_accuracy: 0.3873 - val_precision: 0.6275 - val_recall: 0.2254\n",
      "Epoch 43/200\n",
      "426/426 - 1s - loss: 1.3010 - accuracy: 0.4812 - precision: 0.7326 - recall: 0.2958 - val_loss: 1.5182 - val_accuracy: 0.3592 - val_precision: 0.5614 - val_recall: 0.2254\n",
      "Epoch 44/200\n",
      "426/426 - 1s - loss: 1.3474 - accuracy: 0.4624 - precision: 0.7303 - recall: 0.2606 - val_loss: 1.3900 - val_accuracy: 0.4366 - val_precision: 0.6400 - val_recall: 0.2254\n",
      "Epoch 45/200\n",
      "426/426 - 1s - loss: 1.3278 - accuracy: 0.4883 - precision: 0.7152 - recall: 0.2535 - val_loss: 1.4170 - val_accuracy: 0.4225 - val_precision: 0.6545 - val_recall: 0.2535\n",
      "Epoch 46/200\n",
      "426/426 - 1s - loss: 1.2865 - accuracy: 0.4953 - precision: 0.7125 - recall: 0.2676 - val_loss: 1.5111 - val_accuracy: 0.3451 - val_precision: 0.5870 - val_recall: 0.1901\n",
      "Epoch 47/200\n",
      "426/426 - 1s - loss: 1.3712 - accuracy: 0.4624 - precision: 0.7293 - recall: 0.2277 - val_loss: 1.2901 - val_accuracy: 0.4718 - val_precision: 0.6897 - val_recall: 0.2817\n",
      "Epoch 48/200\n",
      "426/426 - 1s - loss: 1.2832 - accuracy: 0.5047 - precision: 0.7081 - recall: 0.3075 - val_loss: 1.2960 - val_accuracy: 0.4225 - val_precision: 0.7826 - val_recall: 0.2535\n",
      "Epoch 49/200\n",
      "426/426 - 1s - loss: 1.3350 - accuracy: 0.4648 - precision: 0.6948 - recall: 0.2512 - val_loss: 1.4047 - val_accuracy: 0.4155 - val_precision: 0.6538 - val_recall: 0.2394\n",
      "Epoch 50/200\n",
      "426/426 - 1s - loss: 1.3258 - accuracy: 0.4718 - precision: 0.6982 - recall: 0.2770 - val_loss: 1.4450 - val_accuracy: 0.3732 - val_precision: 0.6429 - val_recall: 0.2535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200\n",
      "426/426 - 1s - loss: 1.2371 - accuracy: 0.5235 - precision: 0.7630 - recall: 0.3099 - val_loss: 1.3497 - val_accuracy: 0.4366 - val_precision: 0.7273 - val_recall: 0.2817\n",
      "Epoch 52/200\n",
      "426/426 - 1s - loss: 1.2069 - accuracy: 0.5211 - precision: 0.7706 - recall: 0.3075 - val_loss: 1.3095 - val_accuracy: 0.4507 - val_precision: 0.7636 - val_recall: 0.2958\n",
      "Epoch 53/200\n",
      "426/426 - 1s - loss: 1.1702 - accuracy: 0.5282 - precision: 0.7500 - recall: 0.3380 - val_loss: 1.3219 - val_accuracy: 0.4507 - val_precision: 0.6667 - val_recall: 0.2676\n",
      "Epoch 54/200\n",
      "426/426 - 1s - loss: 1.1531 - accuracy: 0.5493 - precision: 0.7594 - recall: 0.3333 - val_loss: 1.3337 - val_accuracy: 0.4225 - val_precision: 0.7547 - val_recall: 0.2817\n",
      "Epoch 55/200\n",
      "426/426 - 1s - loss: 1.1764 - accuracy: 0.5352 - precision: 0.7738 - recall: 0.3052 - val_loss: 1.3554 - val_accuracy: 0.4085 - val_precision: 0.7692 - val_recall: 0.2817\n",
      "Epoch 56/200\n",
      "426/426 - 1s - loss: 1.1730 - accuracy: 0.5258 - precision: 0.7543 - recall: 0.3099 - val_loss: 1.4251 - val_accuracy: 0.3662 - val_precision: 0.5818 - val_recall: 0.2254\n",
      "Epoch 57/200\n",
      "426/426 - 1s - loss: 1.2396 - accuracy: 0.5000 - precision: 0.7169 - recall: 0.2793 - val_loss: 1.4788 - val_accuracy: 0.3451 - val_precision: 0.6400 - val_recall: 0.2254\n",
      "Epoch 58/200\n",
      "426/426 - 1s - loss: 1.3613 - accuracy: 0.4460 - precision: 0.6162 - recall: 0.2676 - val_loss: 1.3897 - val_accuracy: 0.3732 - val_precision: 0.7083 - val_recall: 0.2394\n",
      "Epoch 59/200\n",
      "426/426 - 1s - loss: 1.2114 - accuracy: 0.5117 - precision: 0.7931 - recall: 0.2700 - val_loss: 1.4632 - val_accuracy: 0.3592 - val_precision: 0.6444 - val_recall: 0.2042\n",
      "Epoch 60/200\n",
      "426/426 - 1s - loss: 1.2563 - accuracy: 0.5070 - precision: 0.7233 - recall: 0.2700 - val_loss: 1.3748 - val_accuracy: 0.3803 - val_precision: 0.7170 - val_recall: 0.2676\n",
      "Epoch 61/200\n",
      "426/426 - 1s - loss: 1.1973 - accuracy: 0.5188 - precision: 0.7687 - recall: 0.2653 - val_loss: 1.3448 - val_accuracy: 0.4366 - val_precision: 0.6923 - val_recall: 0.2535\n",
      "Epoch 62/200\n",
      "426/426 - 1s - loss: 1.1542 - accuracy: 0.5516 - precision: 0.7500 - recall: 0.3099 - val_loss: 1.3751 - val_accuracy: 0.4225 - val_precision: 0.6935 - val_recall: 0.3028\n",
      "Epoch 63/200\n",
      "426/426 - 1s - loss: 1.1331 - accuracy: 0.5469 - precision: 0.8150 - recall: 0.3310 - val_loss: 1.2928 - val_accuracy: 0.4437 - val_precision: 0.6774 - val_recall: 0.2958\n",
      "Epoch 64/200\n",
      "426/426 - 1s - loss: 1.0929 - accuracy: 0.5657 - precision: 0.7989 - recall: 0.3263 - val_loss: 1.3746 - val_accuracy: 0.4085 - val_precision: 0.7167 - val_recall: 0.3028\n",
      "Epoch 65/200\n",
      "426/426 - 1s - loss: 1.1048 - accuracy: 0.5751 - precision: 0.7737 - recall: 0.3451 - val_loss: 1.3420 - val_accuracy: 0.3944 - val_precision: 0.6290 - val_recall: 0.2746\n",
      "Epoch 66/200\n",
      "426/426 - 1s - loss: 1.1155 - accuracy: 0.5516 - precision: 0.7833 - recall: 0.3310 - val_loss: 1.2862 - val_accuracy: 0.4366 - val_precision: 0.6769 - val_recall: 0.3099\n",
      "Epoch 67/200\n",
      "426/426 - 1s - loss: 1.1327 - accuracy: 0.5399 - precision: 0.7577 - recall: 0.3451 - val_loss: 1.4723 - val_accuracy: 0.3873 - val_precision: 0.5156 - val_recall: 0.2324\n",
      "Epoch 68/200\n",
      "426/426 - 1s - loss: 1.2342 - accuracy: 0.5094 - precision: 0.7193 - recall: 0.2887 - val_loss: 1.4246 - val_accuracy: 0.3803 - val_precision: 0.7083 - val_recall: 0.2394\n",
      "Epoch 69/200\n",
      "426/426 - 1s - loss: 1.1978 - accuracy: 0.5094 - precision: 0.7582 - recall: 0.2723 - val_loss: 1.3560 - val_accuracy: 0.4014 - val_precision: 0.6981 - val_recall: 0.2606\n",
      "Epoch 70/200\n",
      "426/426 - 1s - loss: 1.1136 - accuracy: 0.5352 - precision: 0.8431 - recall: 0.3028 - val_loss: 1.2602 - val_accuracy: 0.4577 - val_precision: 0.7460 - val_recall: 0.3310\n",
      "Epoch 71/200\n",
      "426/426 - 1s - loss: 1.0831 - accuracy: 0.5798 - precision: 0.8351 - recall: 0.3685 - val_loss: 1.2677 - val_accuracy: 0.4437 - val_precision: 0.7273 - val_recall: 0.3380\n",
      "Epoch 72/200\n",
      "426/426 - 1s - loss: 1.0531 - accuracy: 0.5915 - precision: 0.7833 - recall: 0.3732 - val_loss: 1.2787 - val_accuracy: 0.4577 - val_precision: 0.7164 - val_recall: 0.3380\n",
      "Epoch 73/200\n",
      "426/426 - 1s - loss: 1.0057 - accuracy: 0.5892 - precision: 0.7860 - recall: 0.3967 - val_loss: 1.2383 - val_accuracy: 0.4718 - val_precision: 0.6667 - val_recall: 0.3803\n",
      "Epoch 74/200\n",
      "426/426 - 1s - loss: 0.9810 - accuracy: 0.6315 - precision: 0.8219 - recall: 0.4225 - val_loss: 1.2886 - val_accuracy: 0.4296 - val_precision: 0.6486 - val_recall: 0.3380\n",
      "Epoch 75/200\n",
      "426/426 - 1s - loss: 1.1161 - accuracy: 0.5657 - precision: 0.7181 - recall: 0.3826 - val_loss: 1.2210 - val_accuracy: 0.4930 - val_precision: 0.6957 - val_recall: 0.3380\n",
      "Epoch 76/200\n",
      "426/426 - 1s - loss: 1.0496 - accuracy: 0.6056 - precision: 0.7783 - recall: 0.4038 - val_loss: 1.1694 - val_accuracy: 0.5352 - val_precision: 0.7571 - val_recall: 0.3732\n",
      "Epoch 77/200\n",
      "426/426 - 1s - loss: 0.9317 - accuracy: 0.6643 - precision: 0.8216 - recall: 0.4648 - val_loss: 1.2159 - val_accuracy: 0.5141 - val_precision: 0.6889 - val_recall: 0.4366\n",
      "Epoch 78/200\n",
      "426/426 - 1s - loss: 0.9178 - accuracy: 0.6432 - precision: 0.7930 - recall: 0.4765 - val_loss: 1.0740 - val_accuracy: 0.5704 - val_precision: 0.7051 - val_recall: 0.3873\n",
      "Epoch 79/200\n",
      "426/426 - 1s - loss: 0.8829 - accuracy: 0.6761 - precision: 0.8353 - recall: 0.4883 - val_loss: 1.2138 - val_accuracy: 0.5704 - val_precision: 0.6800 - val_recall: 0.3592\n",
      "Epoch 80/200\n",
      "426/426 - 1s - loss: 0.8571 - accuracy: 0.6549 - precision: 0.8134 - recall: 0.5117 - val_loss: 1.0732 - val_accuracy: 0.5775 - val_precision: 0.7750 - val_recall: 0.4366\n",
      "Epoch 81/200\n",
      "426/426 - 1s - loss: 0.8078 - accuracy: 0.7042 - precision: 0.8275 - recall: 0.5516 - val_loss: 1.1034 - val_accuracy: 0.5775 - val_precision: 0.7436 - val_recall: 0.4085\n",
      "Epoch 82/200\n",
      "426/426 - 1s - loss: 0.7976 - accuracy: 0.6901 - precision: 0.8182 - recall: 0.5493 - val_loss: 1.0164 - val_accuracy: 0.6197 - val_precision: 0.7586 - val_recall: 0.4648\n",
      "Epoch 83/200\n",
      "426/426 - 1s - loss: 0.7923 - accuracy: 0.7042 - precision: 0.8322 - recall: 0.5822 - val_loss: 1.0272 - val_accuracy: 0.6197 - val_precision: 0.8214 - val_recall: 0.4859\n",
      "Epoch 84/200\n",
      "426/426 - 1s - loss: 0.7187 - accuracy: 0.7300 - precision: 0.8567 - recall: 0.6033 - val_loss: 0.9638 - val_accuracy: 0.6620 - val_precision: 0.7423 - val_recall: 0.5070\n",
      "Epoch 85/200\n",
      "426/426 - 1s - loss: 0.6557 - accuracy: 0.7700 - precision: 0.8502 - recall: 0.6526 - val_loss: 1.0518 - val_accuracy: 0.5775 - val_precision: 0.6509 - val_recall: 0.4859\n",
      "Epoch 86/200\n",
      "426/426 - 1s - loss: 0.7509 - accuracy: 0.6995 - precision: 0.8115 - recall: 0.5962 - val_loss: 1.0527 - val_accuracy: 0.5986 - val_precision: 0.6600 - val_recall: 0.4648\n",
      "Epoch 87/200\n",
      "426/426 - 1s - loss: 0.7255 - accuracy: 0.6948 - precision: 0.8212 - recall: 0.5822 - val_loss: 0.9913 - val_accuracy: 0.6338 - val_precision: 0.7143 - val_recall: 0.4930\n",
      "Epoch 88/200\n",
      "426/426 - 1s - loss: 0.6874 - accuracy: 0.7465 - precision: 0.8108 - recall: 0.6338 - val_loss: 1.1020 - val_accuracy: 0.5704 - val_precision: 0.6372 - val_recall: 0.5070\n",
      "Epoch 89/200\n",
      "426/426 - 1s - loss: 0.7991 - accuracy: 0.6925 - precision: 0.7741 - recall: 0.6033 - val_loss: 1.2685 - val_accuracy: 0.5704 - val_precision: 0.5966 - val_recall: 0.5000\n",
      "Epoch 90/200\n",
      "426/426 - 1s - loss: 0.8566 - accuracy: 0.6667 - precision: 0.7625 - recall: 0.5728 - val_loss: 1.0884 - val_accuracy: 0.6268 - val_precision: 0.7037 - val_recall: 0.5352\n",
      "Epoch 91/200\n",
      "426/426 - 1s - loss: 0.6734 - accuracy: 0.7535 - precision: 0.8323 - recall: 0.6526 - val_loss: 0.9483 - val_accuracy: 0.6479 - val_precision: 0.7500 - val_recall: 0.5704\n",
      "Epoch 92/200\n",
      "426/426 - 1s - loss: 0.7218 - accuracy: 0.7254 - precision: 0.7994 - recall: 0.6268 - val_loss: 0.8925 - val_accuracy: 0.6761 - val_precision: 0.7830 - val_recall: 0.5845\n",
      "Epoch 93/200\n",
      "426/426 - 1s - loss: 0.6595 - accuracy: 0.7512 - precision: 0.8478 - recall: 0.6667 - val_loss: 0.9608 - val_accuracy: 0.6549 - val_precision: 0.6991 - val_recall: 0.5563\n",
      "Epoch 94/200\n",
      "426/426 - 1s - loss: 0.6348 - accuracy: 0.7488 - precision: 0.8111 - recall: 0.6854 - val_loss: 0.9721 - val_accuracy: 0.6479 - val_precision: 0.7207 - val_recall: 0.5634\n",
      "Epoch 95/200\n",
      "426/426 - 1s - loss: 0.6667 - accuracy: 0.7394 - precision: 0.8240 - recall: 0.6596 - val_loss: 1.0758 - val_accuracy: 0.6197 - val_precision: 0.7143 - val_recall: 0.5282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/200\n",
      "426/426 - 1s - loss: 0.6688 - accuracy: 0.7418 - precision: 0.8160 - recall: 0.6455 - val_loss: 0.9073 - val_accuracy: 0.6549 - val_precision: 0.7143 - val_recall: 0.5282\n",
      "Epoch 97/200\n",
      "426/426 - 1s - loss: 0.6343 - accuracy: 0.7465 - precision: 0.8464 - recall: 0.6596 - val_loss: 1.2617 - val_accuracy: 0.5915 - val_precision: 0.6893 - val_recall: 0.5000\n",
      "Epoch 98/200\n",
      "426/426 - 1s - loss: 0.6528 - accuracy: 0.7559 - precision: 0.8373 - recall: 0.6526 - val_loss: 0.9333 - val_accuracy: 0.6479 - val_precision: 0.7523 - val_recall: 0.5775\n",
      "Epoch 99/200\n",
      "426/426 - 1s - loss: 0.5814 - accuracy: 0.7840 - precision: 0.8525 - recall: 0.6784 - val_loss: 0.9654 - val_accuracy: 0.6761 - val_precision: 0.7364 - val_recall: 0.5704\n",
      "Epoch 100/200\n",
      "426/426 - 1s - loss: 0.5630 - accuracy: 0.7958 - precision: 0.8500 - recall: 0.7183 - val_loss: 0.9417 - val_accuracy: 0.6761 - val_precision: 0.7193 - val_recall: 0.5775\n",
      "Epoch 101/200\n",
      "426/426 - 1s - loss: 0.4930 - accuracy: 0.8146 - precision: 0.8681 - recall: 0.7418 - val_loss: 0.8846 - val_accuracy: 0.6761 - val_precision: 0.7059 - val_recall: 0.5915\n",
      "Epoch 102/200\n",
      "426/426 - 1s - loss: 0.5542 - accuracy: 0.7911 - precision: 0.8483 - recall: 0.7089 - val_loss: 0.9523 - val_accuracy: 0.6901 - val_precision: 0.7265 - val_recall: 0.5986\n",
      "Epoch 103/200\n",
      "426/426 - 1s - loss: 0.5208 - accuracy: 0.7934 - precision: 0.8618 - recall: 0.7465 - val_loss: 0.9979 - val_accuracy: 0.6620 - val_precision: 0.6972 - val_recall: 0.5352\n",
      "Epoch 104/200\n",
      "426/426 - 1s - loss: 0.6021 - accuracy: 0.7746 - precision: 0.8219 - recall: 0.7042 - val_loss: 1.0254 - val_accuracy: 0.6197 - val_precision: 0.6838 - val_recall: 0.5634\n",
      "Epoch 105/200\n",
      "426/426 - 1s - loss: 0.6481 - accuracy: 0.7512 - precision: 0.7983 - recall: 0.6784 - val_loss: 1.0200 - val_accuracy: 0.6056 - val_precision: 0.6814 - val_recall: 0.5423\n",
      "Epoch 106/200\n",
      "426/426 - 1s - loss: 0.5665 - accuracy: 0.7793 - precision: 0.8576 - recall: 0.6925 - val_loss: 0.8757 - val_accuracy: 0.6761 - val_precision: 0.7364 - val_recall: 0.5704\n",
      "Epoch 107/200\n",
      "426/426 - 1s - loss: 0.5002 - accuracy: 0.7981 - precision: 0.8661 - recall: 0.7441 - val_loss: 0.9669 - val_accuracy: 0.6620 - val_precision: 0.7168 - val_recall: 0.5704\n",
      "Epoch 108/200\n",
      "426/426 - 1s - loss: 0.5305 - accuracy: 0.7981 - precision: 0.8544 - recall: 0.7441 - val_loss: 0.8848 - val_accuracy: 0.6831 - val_precision: 0.7522 - val_recall: 0.5986\n",
      "Epoch 109/200\n",
      "426/426 - 1s - loss: 0.5111 - accuracy: 0.7981 - precision: 0.8691 - recall: 0.7324 - val_loss: 1.0265 - val_accuracy: 0.5915 - val_precision: 0.6810 - val_recall: 0.5563\n",
      "Epoch 110/200\n",
      "426/426 - 1s - loss: 0.5629 - accuracy: 0.7770 - precision: 0.8462 - recall: 0.7230 - val_loss: 0.9465 - val_accuracy: 0.6690 - val_precision: 0.7522 - val_recall: 0.5986\n",
      "Epoch 111/200\n",
      "426/426 - 1s - loss: 0.4938 - accuracy: 0.8169 - precision: 0.9091 - recall: 0.7277 - val_loss: 0.8983 - val_accuracy: 0.6901 - val_precision: 0.7500 - val_recall: 0.6127\n",
      "Epoch 112/200\n",
      "426/426 - 1s - loss: 0.4874 - accuracy: 0.8216 - precision: 0.8855 - recall: 0.7441 - val_loss: 0.8236 - val_accuracy: 0.7254 - val_precision: 0.7870 - val_recall: 0.5986\n",
      "Epoch 113/200\n",
      "426/426 - 1s - loss: 0.4695 - accuracy: 0.8404 - precision: 0.8978 - recall: 0.7629 - val_loss: 0.8984 - val_accuracy: 0.6972 - val_precision: 0.7414 - val_recall: 0.6056\n",
      "Epoch 114/200\n",
      "426/426 - 1s - loss: 0.4276 - accuracy: 0.8568 - precision: 0.9096 - recall: 0.8028 - val_loss: 0.8881 - val_accuracy: 0.7465 - val_precision: 0.7647 - val_recall: 0.6408\n",
      "Epoch 115/200\n",
      "426/426 - 1s - loss: 0.3854 - accuracy: 0.8545 - precision: 0.9074 - recall: 0.8052 - val_loss: 0.8563 - val_accuracy: 0.6901 - val_precision: 0.7647 - val_recall: 0.6408\n",
      "Epoch 116/200\n",
      "426/426 - 1s - loss: 0.3651 - accuracy: 0.8592 - precision: 0.8982 - recall: 0.8286 - val_loss: 0.8548 - val_accuracy: 0.7113 - val_precision: 0.7438 - val_recall: 0.6338\n",
      "Epoch 117/200\n",
      "426/426 - 1s - loss: 0.3829 - accuracy: 0.8380 - precision: 0.8903 - recall: 0.8005 - val_loss: 0.8957 - val_accuracy: 0.6901 - val_precision: 0.7458 - val_recall: 0.6197\n",
      "Epoch 118/200\n",
      "426/426 - 1s - loss: 0.3826 - accuracy: 0.8685 - precision: 0.9122 - recall: 0.8052 - val_loss: 0.8685 - val_accuracy: 0.7042 - val_precision: 0.7586 - val_recall: 0.6197\n",
      "Epoch 119/200\n",
      "426/426 - 1s - loss: 0.3327 - accuracy: 0.8779 - precision: 0.9231 - recall: 0.8451 - val_loss: 0.8664 - val_accuracy: 0.7042 - val_precision: 0.7200 - val_recall: 0.6338\n",
      "Epoch 120/200\n",
      "426/426 - 1s - loss: 0.4381 - accuracy: 0.8310 - precision: 0.8862 - recall: 0.7676 - val_loss: 0.8246 - val_accuracy: 0.6901 - val_precision: 0.7355 - val_recall: 0.6268\n",
      "Epoch 121/200\n",
      "426/426 - 1s - loss: 0.4297 - accuracy: 0.8380 - precision: 0.8856 - recall: 0.7817 - val_loss: 0.8464 - val_accuracy: 0.6972 - val_precision: 0.7623 - val_recall: 0.6549\n",
      "Epoch 122/200\n",
      "426/426 - 1s - loss: 0.4581 - accuracy: 0.8028 - precision: 0.8644 - recall: 0.7629 - val_loss: 0.9834 - val_accuracy: 0.6620 - val_precision: 0.7018 - val_recall: 0.5634\n",
      "Epoch 123/200\n",
      "426/426 - 1s - loss: 0.5093 - accuracy: 0.8192 - precision: 0.8434 - recall: 0.7840 - val_loss: 0.8563 - val_accuracy: 0.7183 - val_precision: 0.7581 - val_recall: 0.6620\n",
      "Epoch 124/200\n",
      "426/426 - 1s - loss: 0.4284 - accuracy: 0.8451 - precision: 0.8853 - recall: 0.7793 - val_loss: 0.8617 - val_accuracy: 0.6761 - val_precision: 0.7288 - val_recall: 0.6056\n",
      "Epoch 125/200\n",
      "426/426 - 1s - loss: 0.5098 - accuracy: 0.8216 - precision: 0.8583 - recall: 0.7676 - val_loss: 0.9592 - val_accuracy: 0.6831 - val_precision: 0.7258 - val_recall: 0.6338\n",
      "Epoch 126/200\n",
      "426/426 - 1s - loss: 0.4646 - accuracy: 0.8075 - precision: 0.8483 - recall: 0.7746 - val_loss: 1.0565 - val_accuracy: 0.6620 - val_precision: 0.6960 - val_recall: 0.6127\n",
      "Epoch 127/200\n",
      "426/426 - 1s - loss: 0.5089 - accuracy: 0.8192 - precision: 0.8553 - recall: 0.7770 - val_loss: 0.9835 - val_accuracy: 0.6479 - val_precision: 0.7008 - val_recall: 0.6268\n",
      "Epoch 128/200\n",
      "426/426 - 1s - loss: 0.4060 - accuracy: 0.8474 - precision: 0.8964 - recall: 0.8122 - val_loss: 0.9314 - val_accuracy: 0.6338 - val_precision: 0.7059 - val_recall: 0.5915\n",
      "Epoch 129/200\n",
      "426/426 - 1s - loss: 0.3561 - accuracy: 0.8709 - precision: 0.8982 - recall: 0.8286 - val_loss: 0.8923 - val_accuracy: 0.6972 - val_precision: 0.7059 - val_recall: 0.6761\n",
      "Epoch 130/200\n",
      "426/426 - 1s - loss: 0.3629 - accuracy: 0.8709 - precision: 0.9038 - recall: 0.8380 - val_loss: 0.7984 - val_accuracy: 0.7183 - val_precision: 0.7480 - val_recall: 0.6479\n",
      "Epoch 131/200\n",
      "426/426 - 1s - loss: 0.3479 - accuracy: 0.8568 - precision: 0.8947 - recall: 0.8380 - val_loss: 0.9185 - val_accuracy: 0.6972 - val_precision: 0.7209 - val_recall: 0.6549\n",
      "Epoch 132/200\n",
      "426/426 - 1s - loss: 0.3453 - accuracy: 0.8779 - precision: 0.8943 - recall: 0.8545 - val_loss: 0.9351 - val_accuracy: 0.7113 - val_precision: 0.7348 - val_recall: 0.6831\n",
      "Epoch 133/200\n",
      "426/426 - 1s - loss: 0.3432 - accuracy: 0.8685 - precision: 0.9084 - recall: 0.8380 - val_loss: 0.9243 - val_accuracy: 0.6972 - val_precision: 0.7059 - val_recall: 0.6761\n",
      "Epoch 134/200\n",
      "426/426 - 1s - loss: 0.3305 - accuracy: 0.8779 - precision: 0.8968 - recall: 0.8568 - val_loss: 0.9084 - val_accuracy: 0.7254 - val_precision: 0.7197 - val_recall: 0.6690\n",
      "Epoch 135/200\n",
      "426/426 - 1s - loss: 0.3527 - accuracy: 0.8732 - precision: 0.8947 - recall: 0.8380 - val_loss: 0.8607 - val_accuracy: 0.6408 - val_precision: 0.7154 - val_recall: 0.6197\n",
      "Epoch 136/200\n",
      "426/426 - 1s - loss: 0.2802 - accuracy: 0.8873 - precision: 0.9152 - recall: 0.8615 - val_loss: 0.8732 - val_accuracy: 0.6690 - val_precision: 0.6984 - val_recall: 0.6197\n",
      "Epoch 137/200\n",
      "426/426 - 1s - loss: 0.3246 - accuracy: 0.8662 - precision: 0.8959 - recall: 0.8286 - val_loss: 1.0389 - val_accuracy: 0.6408 - val_precision: 0.6929 - val_recall: 0.6197\n",
      "Epoch 138/200\n",
      "426/426 - 1s - loss: 0.3635 - accuracy: 0.8451 - precision: 0.8706 - recall: 0.8216 - val_loss: 0.9076 - val_accuracy: 0.6690 - val_precision: 0.7317 - val_recall: 0.6338\n",
      "Epoch 139/200\n",
      "426/426 - 1s - loss: 0.3363 - accuracy: 0.8709 - precision: 0.8990 - recall: 0.8357 - val_loss: 0.7984 - val_accuracy: 0.7042 - val_precision: 0.7812 - val_recall: 0.7042\n",
      "Epoch 140/200\n",
      "426/426 - 1s - loss: 0.3096 - accuracy: 0.8850 - precision: 0.9064 - recall: 0.8638 - val_loss: 0.8219 - val_accuracy: 0.7254 - val_precision: 0.7634 - val_recall: 0.7042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/200\n",
      "426/426 - 1s - loss: 0.3148 - accuracy: 0.8709 - precision: 0.8978 - recall: 0.8451 - val_loss: 0.7372 - val_accuracy: 0.7394 - val_precision: 0.7863 - val_recall: 0.7254\n",
      "Epoch 142/200\n",
      "426/426 - 1s - loss: 0.5024 - accuracy: 0.8263 - precision: 0.8663 - recall: 0.7911 - val_loss: 0.9743 - val_accuracy: 0.6620 - val_precision: 0.7143 - val_recall: 0.5986\n",
      "Epoch 143/200\n",
      "426/426 - 1s - loss: 0.2987 - accuracy: 0.8826 - precision: 0.9162 - recall: 0.8474 - val_loss: 0.9371 - val_accuracy: 0.6479 - val_precision: 0.7097 - val_recall: 0.6197\n",
      "Epoch 144/200\n",
      "426/426 - 1s - loss: 0.2888 - accuracy: 0.8944 - precision: 0.9132 - recall: 0.8638 - val_loss: 0.9539 - val_accuracy: 0.6901 - val_precision: 0.7188 - val_recall: 0.6479\n",
      "Epoch 145/200\n",
      "426/426 - 1s - loss: 0.4047 - accuracy: 0.8474 - precision: 0.8800 - recall: 0.8263 - val_loss: 1.0118 - val_accuracy: 0.6690 - val_precision: 0.7063 - val_recall: 0.6268\n",
      "Epoch 146/200\n",
      "426/426 - 1s - loss: 0.3272 - accuracy: 0.8662 - precision: 0.8928 - recall: 0.8404 - val_loss: 0.8992 - val_accuracy: 0.6761 - val_precision: 0.7154 - val_recall: 0.6549\n",
      "Epoch 147/200\n",
      "426/426 - 1s - loss: 0.2639 - accuracy: 0.8944 - precision: 0.9136 - recall: 0.8685 - val_loss: 0.8107 - val_accuracy: 0.7183 - val_precision: 0.7597 - val_recall: 0.6901\n",
      "Epoch 148/200\n",
      "426/426 - 1s - loss: 0.2242 - accuracy: 0.9131 - precision: 0.9341 - recall: 0.8991 - val_loss: 0.8149 - val_accuracy: 0.7535 - val_precision: 0.7744 - val_recall: 0.7254\n",
      "Epoch 149/200\n",
      "426/426 - 1s - loss: 0.2069 - accuracy: 0.9249 - precision: 0.9463 - recall: 0.9108 - val_loss: 0.8038 - val_accuracy: 0.7465 - val_precision: 0.7704 - val_recall: 0.7324\n",
      "Epoch 150/200\n",
      "426/426 - 1s - loss: 0.2030 - accuracy: 0.9249 - precision: 0.9465 - recall: 0.9131 - val_loss: 0.8830 - val_accuracy: 0.6901 - val_precision: 0.7313 - val_recall: 0.6901\n",
      "Epoch 151/200\n",
      "426/426 - 1s - loss: 0.1934 - accuracy: 0.9272 - precision: 0.9465 - recall: 0.9131 - val_loss: 0.8152 - val_accuracy: 0.7535 - val_precision: 0.7820 - val_recall: 0.7324\n",
      "Epoch 152/200\n",
      "426/426 - 1s - loss: 0.1877 - accuracy: 0.9366 - precision: 0.9561 - recall: 0.9202 - val_loss: 0.8054 - val_accuracy: 0.7676 - val_precision: 0.7926 - val_recall: 0.7535\n",
      "Epoch 153/200\n",
      "426/426 - 1s - loss: 0.2920 - accuracy: 0.9014 - precision: 0.9191 - recall: 0.8803 - val_loss: 0.8264 - val_accuracy: 0.7817 - val_precision: 0.7914 - val_recall: 0.7746\n",
      "Epoch 154/200\n",
      "426/426 - 1s - loss: 0.2426 - accuracy: 0.9108 - precision: 0.9163 - recall: 0.8991 - val_loss: 0.8828 - val_accuracy: 0.7324 - val_precision: 0.7500 - val_recall: 0.7183\n",
      "Epoch 155/200\n",
      "426/426 - 1s - loss: 0.2121 - accuracy: 0.9225 - precision: 0.9305 - recall: 0.9108 - val_loss: 0.8167 - val_accuracy: 0.7394 - val_precision: 0.7704 - val_recall: 0.7324\n",
      "Epoch 156/200\n",
      "426/426 - 1s - loss: 0.2377 - accuracy: 0.9178 - precision: 0.9324 - recall: 0.9061 - val_loss: 1.0876 - val_accuracy: 0.6549 - val_precision: 0.6742 - val_recall: 0.6268\n",
      "Epoch 157/200\n",
      "426/426 - 1s - loss: 0.3107 - accuracy: 0.9061 - precision: 0.9173 - recall: 0.8850 - val_loss: 0.8897 - val_accuracy: 0.7113 - val_precision: 0.7385 - val_recall: 0.6761\n",
      "Epoch 158/200\n",
      "426/426 - 1s - loss: 0.2553 - accuracy: 0.9014 - precision: 0.9155 - recall: 0.8897 - val_loss: 0.7608 - val_accuracy: 0.7817 - val_precision: 0.8140 - val_recall: 0.7394\n",
      "Epoch 159/200\n",
      "426/426 - 1s - loss: 0.2025 - accuracy: 0.9390 - precision: 0.9561 - recall: 0.9202 - val_loss: 0.7856 - val_accuracy: 0.7746 - val_precision: 0.7778 - val_recall: 0.7394\n",
      "Epoch 160/200\n",
      "426/426 - 1s - loss: 0.1991 - accuracy: 0.9319 - precision: 0.9399 - recall: 0.9178 - val_loss: 0.9758 - val_accuracy: 0.7113 - val_precision: 0.7122 - val_recall: 0.6972\n",
      "Epoch 161/200\n",
      "426/426 - 1s - loss: 0.3233 - accuracy: 0.8850 - precision: 0.9064 - recall: 0.8638 - val_loss: 0.8825 - val_accuracy: 0.7042 - val_precision: 0.7462 - val_recall: 0.6831\n",
      "Epoch 162/200\n",
      "426/426 - 1s - loss: 0.2852 - accuracy: 0.8944 - precision: 0.9051 - recall: 0.8732 - val_loss: 0.9239 - val_accuracy: 0.7113 - val_precision: 0.7328 - val_recall: 0.6761\n",
      "Epoch 163/200\n",
      "426/426 - 1s - loss: 0.3826 - accuracy: 0.8474 - precision: 0.8731 - recall: 0.8239 - val_loss: 1.1111 - val_accuracy: 0.6479 - val_precision: 0.6822 - val_recall: 0.6197\n",
      "Epoch 164/200\n",
      "426/426 - 1s - loss: 0.4181 - accuracy: 0.8592 - precision: 0.8784 - recall: 0.8310 - val_loss: 0.8395 - val_accuracy: 0.7254 - val_precision: 0.7727 - val_recall: 0.7183\n",
      "Epoch 165/200\n",
      "426/426 - 1s - loss: 0.3117 - accuracy: 0.8873 - precision: 0.9132 - recall: 0.8638 - val_loss: 0.7716 - val_accuracy: 0.7254 - val_precision: 0.7594 - val_recall: 0.7113\n",
      "Epoch 166/200\n",
      "426/426 - 1s - loss: 0.2682 - accuracy: 0.9085 - precision: 0.9173 - recall: 0.8850 - val_loss: 0.7922 - val_accuracy: 0.7113 - val_precision: 0.7218 - val_recall: 0.6761\n",
      "Epoch 167/200\n",
      "426/426 - 1s - loss: 0.2335 - accuracy: 0.9155 - precision: 0.9258 - recall: 0.9085 - val_loss: 0.8273 - val_accuracy: 0.7254 - val_precision: 0.7357 - val_recall: 0.7254\n",
      "Epoch 168/200\n",
      "426/426 - 1s - loss: 0.1834 - accuracy: 0.9413 - precision: 0.9520 - recall: 0.9319 - val_loss: 0.8586 - val_accuracy: 0.6901 - val_precision: 0.7080 - val_recall: 0.6831\n",
      "Epoch 169/200\n",
      "426/426 - 1s - loss: 0.2971 - accuracy: 0.8944 - precision: 0.9060 - recall: 0.8826 - val_loss: 0.9197 - val_accuracy: 0.7183 - val_precision: 0.7293 - val_recall: 0.6831\n",
      "Epoch 170/200\n",
      "426/426 - 1s - loss: 0.2617 - accuracy: 0.9061 - precision: 0.9265 - recall: 0.8873 - val_loss: 0.8255 - val_accuracy: 0.7606 - val_precision: 0.7794 - val_recall: 0.7465\n",
      "Epoch 171/200\n",
      "426/426 - 1s - loss: 0.1943 - accuracy: 0.9343 - precision: 0.9402 - recall: 0.9225 - val_loss: 0.7838 - val_accuracy: 0.7606 - val_precision: 0.7643 - val_recall: 0.7535\n",
      "Epoch 172/200\n",
      "426/426 - 1s - loss: 0.1422 - accuracy: 0.9624 - precision: 0.9643 - recall: 0.9507 - val_loss: 0.8158 - val_accuracy: 0.7465 - val_precision: 0.7518 - val_recall: 0.7254\n",
      "Epoch 173/200\n",
      "426/426 - 1s - loss: 0.1405 - accuracy: 0.9577 - precision: 0.9573 - recall: 0.9484 - val_loss: 0.7146 - val_accuracy: 0.7535 - val_precision: 0.7664 - val_recall: 0.7394\n",
      "Epoch 174/200\n",
      "426/426 - 1s - loss: 0.1448 - accuracy: 0.9507 - precision: 0.9545 - recall: 0.9366 - val_loss: 0.7703 - val_accuracy: 0.7254 - val_precision: 0.7338 - val_recall: 0.7183\n",
      "Epoch 175/200\n",
      "426/426 - 1s - loss: 0.1371 - accuracy: 0.9437 - precision: 0.9500 - recall: 0.9366 - val_loss: 0.7534 - val_accuracy: 0.8028 - val_precision: 0.8029 - val_recall: 0.7746\n",
      "Epoch 176/200\n",
      "426/426 - 1s - loss: 0.1809 - accuracy: 0.9343 - precision: 0.9424 - recall: 0.9225 - val_loss: 0.8526 - val_accuracy: 0.7535 - val_precision: 0.7852 - val_recall: 0.7465\n",
      "Epoch 177/200\n",
      "426/426 - 1s - loss: 0.3227 - accuracy: 0.8944 - precision: 0.9100 - recall: 0.8779 - val_loss: 1.0348 - val_accuracy: 0.6690 - val_precision: 0.6889 - val_recall: 0.6549\n",
      "Epoch 178/200\n",
      "426/426 - 1s - loss: 0.3136 - accuracy: 0.9131 - precision: 0.9205 - recall: 0.8967 - val_loss: 0.8365 - val_accuracy: 0.7254 - val_precision: 0.7444 - val_recall: 0.6972\n",
      "Epoch 179/200\n",
      "426/426 - 1s - loss: 0.2041 - accuracy: 0.9343 - precision: 0.9470 - recall: 0.9225 - val_loss: 0.8369 - val_accuracy: 0.7535 - val_precision: 0.7664 - val_recall: 0.7394\n",
      "Epoch 180/200\n",
      "426/426 - 1s - loss: 0.1660 - accuracy: 0.9413 - precision: 0.9475 - recall: 0.9319 - val_loss: 0.7379 - val_accuracy: 0.7746 - val_precision: 0.7883 - val_recall: 0.7606\n",
      "Epoch 181/200\n",
      "426/426 - 1s - loss: 0.1534 - accuracy: 0.9484 - precision: 0.9547 - recall: 0.9390 - val_loss: 0.8123 - val_accuracy: 0.7254 - val_precision: 0.7464 - val_recall: 0.7254\n",
      "Epoch 182/200\n",
      "426/426 - 1s - loss: 0.1490 - accuracy: 0.9507 - precision: 0.9549 - recall: 0.9437 - val_loss: 0.7332 - val_accuracy: 0.7958 - val_precision: 0.8015 - val_recall: 0.7676\n",
      "Epoch 183/200\n",
      "426/426 - 1s - loss: 0.1668 - accuracy: 0.9366 - precision: 0.9450 - recall: 0.9272 - val_loss: 0.7314 - val_accuracy: 0.7676 - val_precision: 0.7664 - val_recall: 0.7394\n",
      "Epoch 184/200\n",
      "426/426 - 1s - loss: 0.1472 - accuracy: 0.9437 - precision: 0.9458 - recall: 0.9413 - val_loss: 0.8619 - val_accuracy: 0.7113 - val_precision: 0.7246 - val_recall: 0.7042\n",
      "Epoch 185/200\n",
      "426/426 - 1s - loss: 0.1404 - accuracy: 0.9437 - precision: 0.9481 - recall: 0.9437 - val_loss: 0.7462 - val_accuracy: 0.7746 - val_precision: 0.7941 - val_recall: 0.7606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/200\n",
      "426/426 - 1s - loss: 0.1479 - accuracy: 0.9531 - precision: 0.9571 - recall: 0.9437 - val_loss: 0.8876 - val_accuracy: 0.7676 - val_precision: 0.7714 - val_recall: 0.7606\n",
      "Epoch 187/200\n",
      "426/426 - 1s - loss: 0.1443 - accuracy: 0.9460 - precision: 0.9481 - recall: 0.9437 - val_loss: 0.8334 - val_accuracy: 0.7465 - val_precision: 0.7518 - val_recall: 0.7254\n",
      "Epoch 188/200\n",
      "426/426 - 1s - loss: 0.1523 - accuracy: 0.9484 - precision: 0.9573 - recall: 0.9484 - val_loss: 0.8048 - val_accuracy: 0.7746 - val_precision: 0.7786 - val_recall: 0.7676\n",
      "Epoch 189/200\n",
      "426/426 - 1s - loss: 0.2666 - accuracy: 0.9108 - precision: 0.9161 - recall: 0.8967 - val_loss: 0.8959 - val_accuracy: 0.7113 - val_precision: 0.7444 - val_recall: 0.6972\n",
      "Epoch 190/200\n",
      "426/426 - 1s - loss: 0.2032 - accuracy: 0.9319 - precision: 0.9396 - recall: 0.9131 - val_loss: 0.8814 - val_accuracy: 0.7254 - val_precision: 0.7407 - val_recall: 0.7042\n",
      "Epoch 191/200\n",
      "426/426 - 1s - loss: 0.1627 - accuracy: 0.9460 - precision: 0.9545 - recall: 0.9366 - val_loss: 0.8555 - val_accuracy: 0.7254 - val_precision: 0.7464 - val_recall: 0.7254\n",
      "Epoch 192/200\n",
      "426/426 - 1s - loss: 0.2044 - accuracy: 0.9155 - precision: 0.9185 - recall: 0.8991 - val_loss: 1.1743 - val_accuracy: 0.6549 - val_precision: 0.6739 - val_recall: 0.6549\n",
      "Epoch 193/200\n",
      "426/426 - 1s - loss: 0.4274 - accuracy: 0.8685 - precision: 0.8854 - recall: 0.8521 - val_loss: 0.9964 - val_accuracy: 0.6972 - val_precision: 0.7239 - val_recall: 0.6831\n",
      "Epoch 194/200\n",
      "426/426 - 1s - loss: 0.3830 - accuracy: 0.8638 - precision: 0.8778 - recall: 0.8427 - val_loss: 0.7990 - val_accuracy: 0.7606 - val_precision: 0.7895 - val_recall: 0.7394\n",
      "Epoch 195/200\n",
      "426/426 - 1s - loss: 0.2500 - accuracy: 0.9249 - precision: 0.9346 - recall: 0.9061 - val_loss: 0.7404 - val_accuracy: 0.7465 - val_precision: 0.7687 - val_recall: 0.7254\n",
      "Epoch 196/200\n",
      "426/426 - 1s - loss: 0.3254 - accuracy: 0.8920 - precision: 0.9045 - recall: 0.8897 - val_loss: 0.6978 - val_accuracy: 0.7676 - val_precision: 0.7794 - val_recall: 0.7465\n",
      "Epoch 197/200\n",
      "426/426 - 1s - loss: 0.2647 - accuracy: 0.9202 - precision: 0.9253 - recall: 0.9014 - val_loss: 0.7888 - val_accuracy: 0.7676 - val_precision: 0.7803 - val_recall: 0.7254\n",
      "Epoch 198/200\n",
      "426/426 - 1s - loss: 0.2111 - accuracy: 0.9343 - precision: 0.9381 - recall: 0.9249 - val_loss: 0.8034 - val_accuracy: 0.7465 - val_precision: 0.7778 - val_recall: 0.7394\n",
      "Epoch 199/200\n",
      "426/426 - 1s - loss: 0.1959 - accuracy: 0.9437 - precision: 0.9522 - recall: 0.9343 - val_loss: 0.7846 - val_accuracy: 0.7606 - val_precision: 0.7820 - val_recall: 0.7324\n",
      "Epoch 200/200\n",
      "426/426 - 1s - loss: 0.1301 - accuracy: 0.9671 - precision: 0.9693 - recall: 0.9624 - val_loss: 0.7709 - val_accuracy: 0.7606 - val_precision: 0.7626 - val_recall: 0.7465\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 192)          214272    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 192)          295680    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 128)          164352    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 64)           49408     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1164      \n",
      "=================================================================\n",
      "Total params: 786,700\n",
      "Trainable params: 786,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Adamax\n",
      "\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/200\n",
      "426/426 - 11s - loss: 2.4555 - accuracy: 0.1033 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3899 - val_accuracy: 0.1268 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      "426/426 - 1s - loss: 2.3465 - accuracy: 0.1643 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.2812 - val_accuracy: 0.1690 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/200\n",
      "426/426 - 1s - loss: 2.1982 - accuracy: 0.2183 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0867 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/200\n",
      "426/426 - 1s - loss: 2.0012 - accuracy: 0.2465 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9402 - val_accuracy: 0.2817 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/200\n",
      "426/426 - 1s - loss: 1.8648 - accuracy: 0.2770 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8315 - val_accuracy: 0.2113 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/200\n",
      "426/426 - 1s - loss: 1.8022 - accuracy: 0.3075 - precision: 1.0000 - recall: 0.0023 - val_loss: 1.7926 - val_accuracy: 0.2324 - val_precision: 1.0000 - val_recall: 0.0141\n",
      "Epoch 7/200\n",
      "426/426 - 1s - loss: 1.7657 - accuracy: 0.3052 - precision: 0.7500 - recall: 0.0211 - val_loss: 1.7538 - val_accuracy: 0.2113 - val_precision: 0.5714 - val_recall: 0.0563\n",
      "Epoch 8/200\n",
      "426/426 - 1s - loss: 1.7679 - accuracy: 0.3192 - precision: 0.5778 - recall: 0.0610 - val_loss: 1.7370 - val_accuracy: 0.2676 - val_precision: 0.7273 - val_recall: 0.0563\n",
      "Epoch 9/200\n",
      "426/426 - 1s - loss: 1.7439 - accuracy: 0.3216 - precision: 0.6579 - recall: 0.0587 - val_loss: 1.7007 - val_accuracy: 0.2465 - val_precision: 0.6923 - val_recall: 0.0634\n",
      "Epoch 10/200\n",
      "426/426 - 1s - loss: 1.6838 - accuracy: 0.3333 - precision: 0.8000 - recall: 0.0563 - val_loss: 1.7250 - val_accuracy: 0.2394 - val_precision: 0.8333 - val_recall: 0.0352\n",
      "Epoch 11/200\n",
      "426/426 - 1s - loss: 1.6845 - accuracy: 0.3333 - precision: 0.7105 - recall: 0.0634 - val_loss: 1.6646 - val_accuracy: 0.2817 - val_precision: 0.9000 - val_recall: 0.0634\n",
      "Epoch 12/200\n",
      "426/426 - 1s - loss: 1.6447 - accuracy: 0.3474 - precision: 0.6667 - recall: 0.0798 - val_loss: 1.6014 - val_accuracy: 0.3028 - val_precision: 0.7647 - val_recall: 0.0915\n",
      "Epoch 13/200\n",
      "426/426 - 1s - loss: 1.5888 - accuracy: 0.3732 - precision: 0.7119 - recall: 0.0986 - val_loss: 1.5396 - val_accuracy: 0.4437 - val_precision: 0.7857 - val_recall: 0.0775\n",
      "Epoch 14/200\n",
      "426/426 - 1s - loss: 1.6265 - accuracy: 0.3615 - precision: 0.7667 - recall: 0.0540 - val_loss: 1.5913 - val_accuracy: 0.3662 - val_precision: 0.6667 - val_recall: 0.0563\n",
      "Epoch 15/200\n",
      "426/426 - 1s - loss: 1.5566 - accuracy: 0.3967 - precision: 0.7843 - recall: 0.0939 - val_loss: 1.5416 - val_accuracy: 0.3451 - val_precision: 0.6429 - val_recall: 0.0634\n",
      "Epoch 16/200\n",
      "426/426 - 1s - loss: 1.5973 - accuracy: 0.3427 - precision: 0.7872 - recall: 0.0869 - val_loss: 1.4175 - val_accuracy: 0.4437 - val_precision: 0.8235 - val_recall: 0.0986\n",
      "Epoch 17/200\n",
      "426/426 - 1s - loss: 1.5389 - accuracy: 0.4155 - precision: 0.6667 - recall: 0.0939 - val_loss: 1.4120 - val_accuracy: 0.4507 - val_precision: 0.9000 - val_recall: 0.1268\n",
      "Epoch 18/200\n",
      "426/426 - 1s - loss: 1.5051 - accuracy: 0.4249 - precision: 0.6905 - recall: 0.1362 - val_loss: 1.4573 - val_accuracy: 0.3873 - val_precision: 0.9231 - val_recall: 0.1690\n",
      "Epoch 19/200\n",
      "426/426 - 1s - loss: 1.4583 - accuracy: 0.4249 - precision: 0.7228 - recall: 0.1714 - val_loss: 1.4294 - val_accuracy: 0.4014 - val_precision: 0.7778 - val_recall: 0.1972\n",
      "Epoch 20/200\n",
      "426/426 - 1s - loss: 1.5163 - accuracy: 0.3944 - precision: 0.6364 - recall: 0.1479 - val_loss: 1.5548 - val_accuracy: 0.3732 - val_precision: 0.6400 - val_recall: 0.1127\n",
      "Epoch 21/200\n",
      "426/426 - 1s - loss: 1.4496 - accuracy: 0.4554 - precision: 0.7315 - recall: 0.1854 - val_loss: 1.4710 - val_accuracy: 0.4014 - val_precision: 0.7179 - val_recall: 0.1972\n",
      "Epoch 22/200\n",
      "426/426 - 1s - loss: 1.3839 - accuracy: 0.4460 - precision: 0.7113 - recall: 0.2371 - val_loss: 1.4674 - val_accuracy: 0.4296 - val_precision: 0.6939 - val_recall: 0.2394\n",
      "Epoch 23/200\n",
      "426/426 - 1s - loss: 1.3609 - accuracy: 0.4742 - precision: 0.7464 - recall: 0.2418 - val_loss: 1.3931 - val_accuracy: 0.4507 - val_precision: 0.7857 - val_recall: 0.2324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200\n",
      "426/426 - 1s - loss: 1.3499 - accuracy: 0.4789 - precision: 0.7279 - recall: 0.2512 - val_loss: 1.3245 - val_accuracy: 0.4930 - val_precision: 0.7778 - val_recall: 0.2958\n",
      "Epoch 25/200\n",
      "426/426 - 1s - loss: 1.3036 - accuracy: 0.5047 - precision: 0.7840 - recall: 0.2981 - val_loss: 1.3462 - val_accuracy: 0.4789 - val_precision: 0.7000 - val_recall: 0.2958\n",
      "Epoch 26/200\n",
      "426/426 - 1s - loss: 1.4013 - accuracy: 0.4531 - precision: 0.7143 - recall: 0.2465 - val_loss: 1.3523 - val_accuracy: 0.4437 - val_precision: 0.7442 - val_recall: 0.2254\n",
      "Epoch 27/200\n",
      "426/426 - 1s - loss: 1.2869 - accuracy: 0.4930 - precision: 0.7456 - recall: 0.2958 - val_loss: 1.2803 - val_accuracy: 0.4859 - val_precision: 0.7586 - val_recall: 0.3099\n",
      "Epoch 28/200\n",
      "426/426 - 1s - loss: 1.2521 - accuracy: 0.5047 - precision: 0.7738 - recall: 0.3052 - val_loss: 1.2546 - val_accuracy: 0.5352 - val_precision: 0.7627 - val_recall: 0.3169\n",
      "Epoch 29/200\n",
      "426/426 - 1s - loss: 1.2628 - accuracy: 0.5000 - precision: 0.7368 - recall: 0.2958 - val_loss: 1.2986 - val_accuracy: 0.4507 - val_precision: 0.8163 - val_recall: 0.2817\n",
      "Epoch 30/200\n",
      "426/426 - 1s - loss: 1.3107 - accuracy: 0.4789 - precision: 0.7024 - recall: 0.2770 - val_loss: 1.2862 - val_accuracy: 0.4366 - val_precision: 0.7800 - val_recall: 0.2746\n",
      "Epoch 31/200\n",
      "426/426 - 1s - loss: 1.2713 - accuracy: 0.4906 - precision: 0.7628 - recall: 0.2793 - val_loss: 1.2709 - val_accuracy: 0.4718 - val_precision: 0.8039 - val_recall: 0.2887\n",
      "Epoch 32/200\n",
      "426/426 - 1s - loss: 1.2480 - accuracy: 0.5164 - precision: 0.7727 - recall: 0.2793 - val_loss: 1.2555 - val_accuracy: 0.4789 - val_precision: 0.8298 - val_recall: 0.2746\n",
      "Epoch 33/200\n",
      "426/426 - 1s - loss: 1.2348 - accuracy: 0.5235 - precision: 0.8309 - recall: 0.2653 - val_loss: 1.2237 - val_accuracy: 0.5141 - val_precision: 0.8269 - val_recall: 0.3028\n",
      "Epoch 34/200\n",
      "426/426 - 1s - loss: 1.2673 - accuracy: 0.5023 - precision: 0.7778 - recall: 0.2793 - val_loss: 1.3639 - val_accuracy: 0.5000 - val_precision: 0.8462 - val_recall: 0.3099\n",
      "Epoch 35/200\n",
      "426/426 - 1s - loss: 1.3107 - accuracy: 0.4695 - precision: 0.7566 - recall: 0.2700 - val_loss: 1.1932 - val_accuracy: 0.5211 - val_precision: 0.8095 - val_recall: 0.3592\n",
      "Epoch 36/200\n",
      "426/426 - 1s - loss: 1.1716 - accuracy: 0.5446 - precision: 0.8323 - recall: 0.3263 - val_loss: 1.2128 - val_accuracy: 0.5282 - val_precision: 0.8103 - val_recall: 0.3310\n",
      "Epoch 37/200\n",
      "426/426 - 1s - loss: 1.1738 - accuracy: 0.5235 - precision: 0.7833 - recall: 0.3310 - val_loss: 1.3044 - val_accuracy: 0.4577 - val_precision: 0.7321 - val_recall: 0.2887\n",
      "Epoch 38/200\n",
      "426/426 - 1s - loss: 1.1812 - accuracy: 0.5446 - precision: 0.7989 - recall: 0.3357 - val_loss: 1.1919 - val_accuracy: 0.5141 - val_precision: 0.8182 - val_recall: 0.3803\n",
      "Epoch 39/200\n",
      "426/426 - 1s - loss: 1.2274 - accuracy: 0.5070 - precision: 0.7759 - recall: 0.3169 - val_loss: 1.2777 - val_accuracy: 0.5000 - val_precision: 0.8036 - val_recall: 0.3169\n",
      "Epoch 40/200\n",
      "426/426 - 1s - loss: 1.2650 - accuracy: 0.5047 - precision: 0.7098 - recall: 0.3216 - val_loss: 1.4210 - val_accuracy: 0.4437 - val_precision: 0.6984 - val_recall: 0.3099\n",
      "Epoch 41/200\n",
      "426/426 - 1s - loss: 1.3011 - accuracy: 0.5023 - precision: 0.7126 - recall: 0.2793 - val_loss: 1.3236 - val_accuracy: 0.4789 - val_precision: 0.8269 - val_recall: 0.3028\n",
      "Epoch 42/200\n",
      "426/426 - 1s - loss: 1.1743 - accuracy: 0.5446 - precision: 0.7554 - recall: 0.3263 - val_loss: 1.2234 - val_accuracy: 0.5000 - val_precision: 0.7424 - val_recall: 0.3451\n",
      "Epoch 43/200\n",
      "426/426 - 1s - loss: 1.1974 - accuracy: 0.5352 - precision: 0.7853 - recall: 0.3263 - val_loss: 1.2679 - val_accuracy: 0.4577 - val_precision: 0.7742 - val_recall: 0.3380\n",
      "Epoch 44/200\n",
      "426/426 - 1s - loss: 1.1598 - accuracy: 0.5376 - precision: 0.7876 - recall: 0.3568 - val_loss: 1.3218 - val_accuracy: 0.4577 - val_precision: 0.7969 - val_recall: 0.3592\n",
      "Epoch 45/200\n",
      "426/426 - 1s - loss: 1.2135 - accuracy: 0.5117 - precision: 0.8483 - recall: 0.3545 - val_loss: 1.2708 - val_accuracy: 0.5000 - val_precision: 0.8103 - val_recall: 0.3310\n",
      "Epoch 46/200\n",
      "426/426 - 1s - loss: 1.1231 - accuracy: 0.5798 - precision: 0.8588 - recall: 0.3427 - val_loss: 1.2249 - val_accuracy: 0.5282 - val_precision: 0.7681 - val_recall: 0.3732\n",
      "Epoch 47/200\n",
      "426/426 - 1s - loss: 1.1206 - accuracy: 0.5845 - precision: 0.8095 - recall: 0.3592 - val_loss: 1.2760 - val_accuracy: 0.4930 - val_precision: 0.7500 - val_recall: 0.3380\n",
      "Epoch 48/200\n",
      "426/426 - 1s - loss: 1.0843 - accuracy: 0.5775 - precision: 0.8444 - recall: 0.3568 - val_loss: 1.2394 - val_accuracy: 0.5423 - val_precision: 0.7937 - val_recall: 0.3521\n",
      "Epoch 49/200\n",
      "426/426 - 1s - loss: 1.0583 - accuracy: 0.6033 - precision: 0.8267 - recall: 0.3920 - val_loss: 1.1297 - val_accuracy: 0.5423 - val_precision: 0.7467 - val_recall: 0.3944\n",
      "Epoch 50/200\n",
      "426/426 - 1s - loss: 1.0290 - accuracy: 0.5892 - precision: 0.8056 - recall: 0.4085 - val_loss: 1.1720 - val_accuracy: 0.5282 - val_precision: 0.7600 - val_recall: 0.4014\n",
      "Epoch 51/200\n",
      "426/426 - 1s - loss: 1.0058 - accuracy: 0.6103 - precision: 0.8356 - recall: 0.4413 - val_loss: 1.1643 - val_accuracy: 0.5634 - val_precision: 0.7662 - val_recall: 0.4155\n",
      "Epoch 52/200\n",
      "426/426 - 1s - loss: 0.9899 - accuracy: 0.6362 - precision: 0.8540 - recall: 0.4531 - val_loss: 1.2128 - val_accuracy: 0.5423 - val_precision: 0.7468 - val_recall: 0.4155\n",
      "Epoch 53/200\n",
      "426/426 - 1s - loss: 0.9821 - accuracy: 0.6502 - precision: 0.8369 - recall: 0.4577 - val_loss: 1.2217 - val_accuracy: 0.5141 - val_precision: 0.8143 - val_recall: 0.4014\n",
      "Epoch 54/200\n",
      "426/426 - 1s - loss: 1.0535 - accuracy: 0.5869 - precision: 0.7948 - recall: 0.4272 - val_loss: 1.2785 - val_accuracy: 0.5141 - val_precision: 0.7500 - val_recall: 0.3803\n",
      "Epoch 55/200\n",
      "426/426 - 1s - loss: 1.0228 - accuracy: 0.5869 - precision: 0.8318 - recall: 0.4178 - val_loss: 1.1563 - val_accuracy: 0.5634 - val_precision: 0.8028 - val_recall: 0.4014\n",
      "Epoch 56/200\n",
      "426/426 - 1s - loss: 0.9848 - accuracy: 0.6221 - precision: 0.8721 - recall: 0.4484 - val_loss: 1.1621 - val_accuracy: 0.5211 - val_precision: 0.7532 - val_recall: 0.4085\n",
      "Epoch 57/200\n",
      "426/426 - 1s - loss: 0.9640 - accuracy: 0.6197 - precision: 0.8515 - recall: 0.4577 - val_loss: 1.1085 - val_accuracy: 0.6127 - val_precision: 0.7922 - val_recall: 0.4296\n",
      "Epoch 58/200\n",
      "426/426 - 1s - loss: 1.0023 - accuracy: 0.6244 - precision: 0.8148 - recall: 0.4648 - val_loss: 1.1492 - val_accuracy: 0.5493 - val_precision: 0.8000 - val_recall: 0.3944\n",
      "Epoch 59/200\n",
      "426/426 - 1s - loss: 1.0503 - accuracy: 0.5892 - precision: 0.7897 - recall: 0.4319 - val_loss: 1.3460 - val_accuracy: 0.4789 - val_precision: 0.6420 - val_recall: 0.3662\n",
      "Epoch 60/200\n",
      "426/426 - 1s - loss: 1.0005 - accuracy: 0.5939 - precision: 0.7746 - recall: 0.4437 - val_loss: 1.1487 - val_accuracy: 0.5775 - val_precision: 0.7778 - val_recall: 0.4437\n",
      "Epoch 61/200\n",
      "426/426 - 1s - loss: 0.9598 - accuracy: 0.6315 - precision: 0.8080 - recall: 0.4742 - val_loss: 1.0926 - val_accuracy: 0.5775 - val_precision: 0.7792 - val_recall: 0.4225\n",
      "Epoch 62/200\n",
      "426/426 - 1s - loss: 0.9412 - accuracy: 0.6385 - precision: 0.7820 - recall: 0.4883 - val_loss: 1.1148 - val_accuracy: 0.5775 - val_precision: 0.7470 - val_recall: 0.4366\n",
      "Epoch 63/200\n",
      "426/426 - 1s - loss: 0.9107 - accuracy: 0.6549 - precision: 0.7887 - recall: 0.4906 - val_loss: 1.0990 - val_accuracy: 0.5775 - val_precision: 0.7312 - val_recall: 0.4789\n",
      "Epoch 64/200\n",
      "426/426 - 1s - loss: 0.8853 - accuracy: 0.6620 - precision: 0.8327 - recall: 0.5023 - val_loss: 1.0650 - val_accuracy: 0.5704 - val_precision: 0.7158 - val_recall: 0.4789\n",
      "Epoch 65/200\n",
      "426/426 - 1s - loss: 0.8120 - accuracy: 0.6854 - precision: 0.8315 - recall: 0.5329 - val_loss: 1.0668 - val_accuracy: 0.5563 - val_precision: 0.6989 - val_recall: 0.4577\n",
      "Epoch 66/200\n",
      "426/426 - 1s - loss: 0.8283 - accuracy: 0.6643 - precision: 0.8216 - recall: 0.5188 - val_loss: 1.0786 - val_accuracy: 0.5845 - val_precision: 0.7528 - val_recall: 0.4718\n",
      "Epoch 67/200\n",
      "426/426 - 1s - loss: 0.7559 - accuracy: 0.7136 - precision: 0.8271 - recall: 0.5728 - val_loss: 1.0695 - val_accuracy: 0.5704 - val_precision: 0.7416 - val_recall: 0.4648\n",
      "Epoch 68/200\n",
      "426/426 - 1s - loss: 0.7059 - accuracy: 0.7371 - precision: 0.8612 - recall: 0.5681 - val_loss: 0.9704 - val_accuracy: 0.5986 - val_precision: 0.7634 - val_recall: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200\n",
      "426/426 - 1s - loss: 0.7667 - accuracy: 0.6854 - precision: 0.8206 - recall: 0.5798 - val_loss: 1.3615 - val_accuracy: 0.4789 - val_precision: 0.6628 - val_recall: 0.4014\n",
      "Epoch 70/200\n",
      "426/426 - 1s - loss: 1.0409 - accuracy: 0.6197 - precision: 0.7889 - recall: 0.5000 - val_loss: 1.1691 - val_accuracy: 0.5915 - val_precision: 0.7340 - val_recall: 0.4859\n",
      "Epoch 71/200\n",
      "426/426 - 1s - loss: 0.8578 - accuracy: 0.6854 - precision: 0.8293 - recall: 0.5587 - val_loss: 1.1326 - val_accuracy: 0.5563 - val_precision: 0.7128 - val_recall: 0.4718\n",
      "Epoch 72/200\n",
      "426/426 - 1s - loss: 0.7435 - accuracy: 0.7277 - precision: 0.8419 - recall: 0.6127 - val_loss: 1.1086 - val_accuracy: 0.5563 - val_precision: 0.7368 - val_recall: 0.4930\n",
      "Epoch 73/200\n",
      "426/426 - 1s - loss: 0.7315 - accuracy: 0.7277 - precision: 0.8403 - recall: 0.6174 - val_loss: 1.0352 - val_accuracy: 0.5845 - val_precision: 0.7172 - val_recall: 0.5000\n",
      "Epoch 74/200\n",
      "426/426 - 1s - loss: 0.8145 - accuracy: 0.6854 - precision: 0.7857 - recall: 0.5939 - val_loss: 1.0467 - val_accuracy: 0.5915 - val_precision: 0.7087 - val_recall: 0.5141\n",
      "Epoch 75/200\n",
      "426/426 - 1s - loss: 0.7354 - accuracy: 0.6854 - precision: 0.8414 - recall: 0.5728 - val_loss: 1.0683 - val_accuracy: 0.5915 - val_precision: 0.6939 - val_recall: 0.4789\n",
      "Epoch 76/200\n",
      "426/426 - 1s - loss: 0.7003 - accuracy: 0.7418 - precision: 0.8763 - recall: 0.6150 - val_loss: 0.9950 - val_accuracy: 0.6127 - val_precision: 0.7912 - val_recall: 0.5070\n",
      "Epoch 77/200\n",
      "426/426 - 1s - loss: 0.6988 - accuracy: 0.7230 - precision: 0.8318 - recall: 0.6385 - val_loss: 1.0301 - val_accuracy: 0.5986 - val_precision: 0.6981 - val_recall: 0.5211\n",
      "Epoch 78/200\n",
      "426/426 - 1s - loss: 0.6728 - accuracy: 0.7512 - precision: 0.8405 - recall: 0.6432 - val_loss: 1.0258 - val_accuracy: 0.6197 - val_precision: 0.7184 - val_recall: 0.5211\n",
      "Epoch 79/200\n",
      "426/426 - 1s - loss: 0.7357 - accuracy: 0.7230 - precision: 0.7901 - recall: 0.6362 - val_loss: 0.9350 - val_accuracy: 0.6549 - val_precision: 0.7383 - val_recall: 0.5563\n",
      "Epoch 80/200\n",
      "426/426 - 1s - loss: 0.6012 - accuracy: 0.7817 - precision: 0.8588 - recall: 0.7136 - val_loss: 1.0195 - val_accuracy: 0.5986 - val_precision: 0.6952 - val_recall: 0.5141\n",
      "Epoch 81/200\n",
      "426/426 - 1s - loss: 0.6744 - accuracy: 0.7441 - precision: 0.8121 - recall: 0.6596 - val_loss: 0.9451 - val_accuracy: 0.6197 - val_precision: 0.7000 - val_recall: 0.5423\n",
      "Epoch 82/200\n",
      "426/426 - 1s - loss: 0.5847 - accuracy: 0.7770 - precision: 0.8451 - recall: 0.7042 - val_loss: 0.9689 - val_accuracy: 0.6549 - val_precision: 0.7064 - val_recall: 0.5423\n",
      "Epoch 83/200\n",
      "426/426 - 1s - loss: 0.5831 - accuracy: 0.7723 - precision: 0.8601 - recall: 0.6925 - val_loss: 0.9921 - val_accuracy: 0.6620 - val_precision: 0.7193 - val_recall: 0.5775\n",
      "Epoch 84/200\n",
      "426/426 - 1s - loss: 0.5841 - accuracy: 0.7911 - precision: 0.8417 - recall: 0.7113 - val_loss: 0.8673 - val_accuracy: 0.6901 - val_precision: 0.7586 - val_recall: 0.6197\n",
      "Epoch 85/200\n",
      "426/426 - 1s - loss: 0.5168 - accuracy: 0.7887 - precision: 0.8630 - recall: 0.7394 - val_loss: 0.8760 - val_accuracy: 0.6690 - val_precision: 0.7544 - val_recall: 0.6056\n",
      "Epoch 86/200\n",
      "426/426 - 1s - loss: 0.5763 - accuracy: 0.7793 - precision: 0.8371 - recall: 0.6995 - val_loss: 0.9830 - val_accuracy: 0.6831 - val_precision: 0.7632 - val_recall: 0.6127\n",
      "Epoch 87/200\n",
      "426/426 - 1s - loss: 0.5289 - accuracy: 0.7934 - precision: 0.8525 - recall: 0.7465 - val_loss: 0.8926 - val_accuracy: 0.6831 - val_precision: 0.7768 - val_recall: 0.6127\n",
      "Epoch 88/200\n",
      "426/426 - 1s - loss: 0.5914 - accuracy: 0.7653 - precision: 0.8357 - recall: 0.7042 - val_loss: 1.0007 - val_accuracy: 0.6268 - val_precision: 0.6667 - val_recall: 0.5493\n",
      "Epoch 89/200\n",
      "426/426 - 1s - loss: 0.5300 - accuracy: 0.7793 - precision: 0.8669 - recall: 0.6878 - val_loss: 0.9090 - val_accuracy: 0.6620 - val_precision: 0.7091 - val_recall: 0.5493\n",
      "Epoch 90/200\n",
      "426/426 - 1s - loss: 0.4977 - accuracy: 0.8192 - precision: 0.8743 - recall: 0.7512 - val_loss: 1.0303 - val_accuracy: 0.6408 - val_precision: 0.6694 - val_recall: 0.5704\n",
      "Epoch 91/200\n",
      "426/426 - 1s - loss: 0.4687 - accuracy: 0.8192 - precision: 0.8598 - recall: 0.7488 - val_loss: 0.9597 - val_accuracy: 0.6549 - val_precision: 0.6992 - val_recall: 0.6056\n",
      "Epoch 92/200\n",
      "426/426 - 1s - loss: 0.5138 - accuracy: 0.8028 - precision: 0.8374 - recall: 0.7254 - val_loss: 0.9189 - val_accuracy: 0.6690 - val_precision: 0.7311 - val_recall: 0.6127\n",
      "Epoch 93/200\n",
      "426/426 - 1s - loss: 0.4739 - accuracy: 0.8146 - precision: 0.8763 - recall: 0.7653 - val_loss: 0.8450 - val_accuracy: 0.6972 - val_precision: 0.7719 - val_recall: 0.6197\n",
      "Epoch 94/200\n",
      "426/426 - 1s - loss: 0.4359 - accuracy: 0.8333 - precision: 0.8943 - recall: 0.7746 - val_loss: 0.8806 - val_accuracy: 0.7042 - val_precision: 0.7273 - val_recall: 0.6761\n",
      "Epoch 95/200\n",
      "426/426 - 1s - loss: 0.4117 - accuracy: 0.8404 - precision: 0.8772 - recall: 0.8052 - val_loss: 0.9025 - val_accuracy: 0.6972 - val_precision: 0.7480 - val_recall: 0.6479\n",
      "Epoch 96/200\n",
      "426/426 - 1s - loss: 0.3882 - accuracy: 0.8615 - precision: 0.8964 - recall: 0.8122 - val_loss: 0.7841 - val_accuracy: 0.7324 - val_precision: 0.7760 - val_recall: 0.6831\n",
      "Epoch 97/200\n",
      "426/426 - 1s - loss: 0.3944 - accuracy: 0.8498 - precision: 0.8763 - recall: 0.8146 - val_loss: 0.7750 - val_accuracy: 0.7183 - val_precision: 0.7680 - val_recall: 0.6761\n",
      "Epoch 98/200\n",
      "426/426 - 1s - loss: 0.4796 - accuracy: 0.8427 - precision: 0.8600 - recall: 0.8075 - val_loss: 0.8660 - val_accuracy: 0.7324 - val_precision: 0.7444 - val_recall: 0.6972\n",
      "Epoch 99/200\n",
      "426/426 - 1s - loss: 0.4862 - accuracy: 0.8310 - precision: 0.8582 - recall: 0.7958 - val_loss: 0.8303 - val_accuracy: 0.7183 - val_precision: 0.7638 - val_recall: 0.6831\n",
      "Epoch 100/200\n",
      "426/426 - 1s - loss: 0.5315 - accuracy: 0.8146 - precision: 0.8380 - recall: 0.7653 - val_loss: 0.8691 - val_accuracy: 0.7042 - val_precision: 0.7422 - val_recall: 0.6690\n",
      "Epoch 101/200\n",
      "426/426 - 1s - loss: 0.4773 - accuracy: 0.8498 - precision: 0.8564 - recall: 0.7700 - val_loss: 0.9236 - val_accuracy: 0.6549 - val_precision: 0.6894 - val_recall: 0.6408\n",
      "Epoch 102/200\n",
      "426/426 - 1s - loss: 0.4183 - accuracy: 0.8592 - precision: 0.8677 - recall: 0.8005 - val_loss: 0.7708 - val_accuracy: 0.7042 - val_precision: 0.7444 - val_recall: 0.6972\n",
      "Epoch 103/200\n",
      "426/426 - 1s - loss: 0.5753 - accuracy: 0.7723 - precision: 0.8104 - recall: 0.7324 - val_loss: 0.9912 - val_accuracy: 0.6408 - val_precision: 0.6905 - val_recall: 0.6127\n",
      "Epoch 104/200\n",
      "426/426 - 1s - loss: 0.5108 - accuracy: 0.7723 - precision: 0.8276 - recall: 0.7324 - val_loss: 0.9069 - val_accuracy: 0.6972 - val_precision: 0.7381 - val_recall: 0.6549\n",
      "Epoch 105/200\n",
      "426/426 - 1s - loss: 0.4033 - accuracy: 0.8638 - precision: 0.9008 - recall: 0.7887 - val_loss: 0.8422 - val_accuracy: 0.7183 - val_precision: 0.7698 - val_recall: 0.6831\n",
      "Epoch 106/200\n",
      "426/426 - 1s - loss: 0.4178 - accuracy: 0.8592 - precision: 0.8926 - recall: 0.8192 - val_loss: 0.8398 - val_accuracy: 0.7042 - val_precision: 0.7600 - val_recall: 0.6690\n",
      "Epoch 107/200\n",
      "426/426 - 1s - loss: 0.3691 - accuracy: 0.8568 - precision: 0.8815 - recall: 0.8380 - val_loss: 0.7450 - val_accuracy: 0.7324 - val_precision: 0.7829 - val_recall: 0.7113\n",
      "Epoch 108/200\n",
      "426/426 - 1s - loss: 0.3314 - accuracy: 0.8897 - precision: 0.9298 - recall: 0.8709 - val_loss: 0.7752 - val_accuracy: 0.7324 - val_precision: 0.7734 - val_recall: 0.6972\n",
      "Epoch 109/200\n",
      "426/426 - 1s - loss: 0.3038 - accuracy: 0.8897 - precision: 0.9113 - recall: 0.8685 - val_loss: 0.8389 - val_accuracy: 0.7254 - val_precision: 0.7444 - val_recall: 0.6972\n",
      "Epoch 110/200\n",
      "426/426 - 1s - loss: 0.3102 - accuracy: 0.8944 - precision: 0.9075 - recall: 0.8756 - val_loss: 0.7108 - val_accuracy: 0.7746 - val_precision: 0.8120 - val_recall: 0.7606\n",
      "Epoch 111/200\n",
      "426/426 - 1s - loss: 0.3427 - accuracy: 0.8850 - precision: 0.8981 - recall: 0.8685 - val_loss: 0.7477 - val_accuracy: 0.7183 - val_precision: 0.7444 - val_recall: 0.6972\n",
      "Epoch 112/200\n",
      "426/426 - 1s - loss: 0.2977 - accuracy: 0.9085 - precision: 0.9225 - recall: 0.8944 - val_loss: 0.7478 - val_accuracy: 0.7817 - val_precision: 0.8074 - val_recall: 0.7676\n",
      "Epoch 113/200\n",
      "426/426 - 1s - loss: 0.2625 - accuracy: 0.9178 - precision: 0.9324 - recall: 0.9061 - val_loss: 0.6999 - val_accuracy: 0.7606 - val_precision: 0.7737 - val_recall: 0.7465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200\n",
      "426/426 - 1s - loss: 0.2577 - accuracy: 0.9131 - precision: 0.9194 - recall: 0.9108 - val_loss: 0.7714 - val_accuracy: 0.7324 - val_precision: 0.7556 - val_recall: 0.7183\n",
      "Epoch 115/200\n",
      "426/426 - 1s - loss: 0.3107 - accuracy: 0.8709 - precision: 0.8849 - recall: 0.8662 - val_loss: 0.7389 - val_accuracy: 0.7746 - val_precision: 0.7794 - val_recall: 0.7465\n",
      "Epoch 116/200\n",
      "426/426 - 1s - loss: 0.2899 - accuracy: 0.8920 - precision: 0.9053 - recall: 0.8756 - val_loss: 0.7030 - val_accuracy: 0.7746 - val_precision: 0.8160 - val_recall: 0.7183\n",
      "Epoch 117/200\n",
      "426/426 - 1s - loss: 0.2572 - accuracy: 0.9038 - precision: 0.9071 - recall: 0.8944 - val_loss: 0.6678 - val_accuracy: 0.7746 - val_precision: 0.7883 - val_recall: 0.7606\n",
      "Epoch 118/200\n",
      "426/426 - 1s - loss: 0.2209 - accuracy: 0.9390 - precision: 0.9406 - recall: 0.9296 - val_loss: 0.6522 - val_accuracy: 0.7746 - val_precision: 0.8148 - val_recall: 0.7746\n",
      "Epoch 119/200\n",
      "426/426 - 1s - loss: 0.2397 - accuracy: 0.9225 - precision: 0.9262 - recall: 0.9131 - val_loss: 0.6974 - val_accuracy: 0.7606 - val_precision: 0.7852 - val_recall: 0.7465\n",
      "Epoch 120/200\n",
      "426/426 - 1s - loss: 0.3117 - accuracy: 0.9131 - precision: 0.9189 - recall: 0.9038 - val_loss: 0.8199 - val_accuracy: 0.7183 - val_precision: 0.7612 - val_recall: 0.7183\n",
      "Epoch 121/200\n",
      "426/426 - 1s - loss: 0.2509 - accuracy: 0.9202 - precision: 0.9327 - recall: 0.9108 - val_loss: 0.7324 - val_accuracy: 0.7606 - val_precision: 0.7868 - val_recall: 0.7535\n",
      "Epoch 122/200\n",
      "426/426 - 1s - loss: 0.2016 - accuracy: 0.9366 - precision: 0.9540 - recall: 0.9249 - val_loss: 0.6387 - val_accuracy: 0.8028 - val_precision: 0.8195 - val_recall: 0.7676\n",
      "Epoch 123/200\n",
      "426/426 - 1s - loss: 0.2830 - accuracy: 0.9038 - precision: 0.9074 - recall: 0.8967 - val_loss: 0.7000 - val_accuracy: 0.7887 - val_precision: 0.8102 - val_recall: 0.7817\n",
      "Epoch 124/200\n",
      "426/426 - 1s - loss: 0.2323 - accuracy: 0.9155 - precision: 0.9248 - recall: 0.8944 - val_loss: 0.6716 - val_accuracy: 0.7958 - val_precision: 0.8043 - val_recall: 0.7817\n",
      "Epoch 125/200\n",
      "426/426 - 1s - loss: 0.2310 - accuracy: 0.9249 - precision: 0.9333 - recall: 0.9202 - val_loss: 0.7076 - val_accuracy: 0.7606 - val_precision: 0.7895 - val_recall: 0.7394\n",
      "Epoch 126/200\n",
      "426/426 - 1s - loss: 0.3446 - accuracy: 0.8756 - precision: 0.8852 - recall: 0.8685 - val_loss: 0.6713 - val_accuracy: 0.7817 - val_precision: 0.7956 - val_recall: 0.7676\n",
      "Epoch 127/200\n",
      "426/426 - 1s - loss: 0.3033 - accuracy: 0.8967 - precision: 0.9140 - recall: 0.8732 - val_loss: 0.7384 - val_accuracy: 0.7465 - val_precision: 0.7609 - val_recall: 0.7394\n",
      "Epoch 128/200\n",
      "426/426 - 1s - loss: 0.2827 - accuracy: 0.8873 - precision: 0.8966 - recall: 0.8756 - val_loss: 0.7765 - val_accuracy: 0.7394 - val_precision: 0.7820 - val_recall: 0.7324\n",
      "Epoch 129/200\n",
      "426/426 - 1s - loss: 0.2455 - accuracy: 0.9131 - precision: 0.9372 - recall: 0.9108 - val_loss: 0.7317 - val_accuracy: 0.7817 - val_precision: 0.7956 - val_recall: 0.7676\n",
      "Epoch 130/200\n",
      "426/426 - 1s - loss: 0.3070 - accuracy: 0.8991 - precision: 0.9045 - recall: 0.8897 - val_loss: 0.9769 - val_accuracy: 0.7183 - val_precision: 0.7407 - val_recall: 0.7042\n",
      "Epoch 131/200\n",
      "426/426 - 1s - loss: 0.2441 - accuracy: 0.9155 - precision: 0.9236 - recall: 0.9085 - val_loss: 0.7602 - val_accuracy: 0.7676 - val_precision: 0.7842 - val_recall: 0.7676\n",
      "Epoch 132/200\n",
      "426/426 - 1s - loss: 0.2679 - accuracy: 0.9202 - precision: 0.9306 - recall: 0.9131 - val_loss: 0.9184 - val_accuracy: 0.7042 - val_precision: 0.7101 - val_recall: 0.6901\n",
      "Epoch 133/200\n",
      "426/426 - 1s - loss: 0.3060 - accuracy: 0.8967 - precision: 0.9108 - recall: 0.8873 - val_loss: 0.8683 - val_accuracy: 0.7324 - val_precision: 0.7429 - val_recall: 0.7324\n",
      "Epoch 134/200\n",
      "426/426 - 1s - loss: 0.2722 - accuracy: 0.8967 - precision: 0.9087 - recall: 0.8873 - val_loss: 0.7041 - val_accuracy: 0.7887 - val_precision: 0.8074 - val_recall: 0.7676\n",
      "Epoch 135/200\n",
      "426/426 - 1s - loss: 0.2243 - accuracy: 0.9272 - precision: 0.9356 - recall: 0.9202 - val_loss: 0.9678 - val_accuracy: 0.7042 - val_precision: 0.7185 - val_recall: 0.6831\n",
      "Epoch 136/200\n",
      "426/426 - 1s - loss: 0.4009 - accuracy: 0.8568 - precision: 0.8696 - recall: 0.8451 - val_loss: 0.6715 - val_accuracy: 0.7676 - val_precision: 0.8000 - val_recall: 0.7606\n",
      "Epoch 137/200\n",
      "426/426 - 1s - loss: 0.4630 - accuracy: 0.8192 - precision: 0.8471 - recall: 0.7934 - val_loss: 0.8526 - val_accuracy: 0.7254 - val_precision: 0.7692 - val_recall: 0.7042\n",
      "Epoch 138/200\n",
      "426/426 - 1s - loss: 0.5168 - accuracy: 0.8216 - precision: 0.8391 - recall: 0.7958 - val_loss: 1.4807 - val_accuracy: 0.6056 - val_precision: 0.6269 - val_recall: 0.5915\n",
      "Epoch 139/200\n",
      "426/426 - 1s - loss: 0.6123 - accuracy: 0.7911 - precision: 0.8117 - recall: 0.7793 - val_loss: 0.8613 - val_accuracy: 0.7324 - val_precision: 0.7500 - val_recall: 0.6972\n",
      "Epoch 140/200\n",
      "426/426 - 1s - loss: 0.3560 - accuracy: 0.8779 - precision: 0.8892 - recall: 0.8474 - val_loss: 0.7294 - val_accuracy: 0.7606 - val_precision: 0.7969 - val_recall: 0.7183\n",
      "Epoch 141/200\n",
      "426/426 - 1s - loss: 0.2504 - accuracy: 0.9178 - precision: 0.9327 - recall: 0.9108 - val_loss: 0.7661 - val_accuracy: 0.7817 - val_precision: 0.7956 - val_recall: 0.7676\n",
      "Epoch 142/200\n",
      "426/426 - 1s - loss: 0.2410 - accuracy: 0.9178 - precision: 0.9330 - recall: 0.9155 - val_loss: 0.7964 - val_accuracy: 0.7606 - val_precision: 0.7810 - val_recall: 0.7535\n",
      "Epoch 143/200\n",
      "426/426 - 1s - loss: 0.2285 - accuracy: 0.9249 - precision: 0.9310 - recall: 0.9178 - val_loss: 0.8274 - val_accuracy: 0.7535 - val_precision: 0.7778 - val_recall: 0.7394\n",
      "Epoch 144/200\n",
      "426/426 - 1s - loss: 0.2107 - accuracy: 0.9155 - precision: 0.9281 - recall: 0.9085 - val_loss: 0.7936 - val_accuracy: 0.7465 - val_precision: 0.7630 - val_recall: 0.7254\n",
      "Epoch 145/200\n",
      "426/426 - 1s - loss: 0.1951 - accuracy: 0.9272 - precision: 0.9381 - recall: 0.9249 - val_loss: 0.7099 - val_accuracy: 0.7958 - val_precision: 0.8043 - val_recall: 0.7817\n",
      "Epoch 146/200\n",
      "426/426 - 1s - loss: 0.1960 - accuracy: 0.9390 - precision: 0.9433 - recall: 0.9366 - val_loss: 0.7452 - val_accuracy: 0.7958 - val_precision: 0.8102 - val_recall: 0.7817\n",
      "Epoch 147/200\n",
      "426/426 - 1s - loss: 0.1625 - accuracy: 0.9507 - precision: 0.9551 - recall: 0.9484 - val_loss: 0.7130 - val_accuracy: 0.8028 - val_precision: 0.8116 - val_recall: 0.7887\n",
      "Epoch 148/200\n",
      "426/426 - 1s - loss: 0.2375 - accuracy: 0.9225 - precision: 0.9286 - recall: 0.9155 - val_loss: 0.7647 - val_accuracy: 0.7676 - val_precision: 0.7956 - val_recall: 0.7676\n",
      "Epoch 149/200\n",
      "426/426 - 1s - loss: 0.2920 - accuracy: 0.9061 - precision: 0.9223 - recall: 0.8920 - val_loss: 0.8486 - val_accuracy: 0.7676 - val_precision: 0.7985 - val_recall: 0.7535\n",
      "Epoch 150/200\n",
      "426/426 - 1s - loss: 0.3429 - accuracy: 0.8850 - precision: 0.8918 - recall: 0.8709 - val_loss: 0.9241 - val_accuracy: 0.7254 - val_precision: 0.7426 - val_recall: 0.7113\n",
      "Epoch 151/200\n",
      "426/426 - 1s - loss: 0.2649 - accuracy: 0.9178 - precision: 0.9300 - recall: 0.9038 - val_loss: 0.7917 - val_accuracy: 0.7746 - val_precision: 0.7970 - val_recall: 0.7465\n",
      "Epoch 152/200\n",
      "426/426 - 1s - loss: 0.2418 - accuracy: 0.9296 - precision: 0.9379 - recall: 0.9225 - val_loss: 0.7328 - val_accuracy: 0.7958 - val_precision: 0.8175 - val_recall: 0.7887\n",
      "Epoch 153/200\n",
      "426/426 - 1s - loss: 0.1740 - accuracy: 0.9319 - precision: 0.9408 - recall: 0.9319 - val_loss: 0.6691 - val_accuracy: 0.7817 - val_precision: 0.7868 - val_recall: 0.7535\n",
      "Epoch 154/200\n",
      "426/426 - 1s - loss: 0.2594 - accuracy: 0.9085 - precision: 0.9258 - recall: 0.9085 - val_loss: 0.7905 - val_accuracy: 0.7606 - val_precision: 0.7737 - val_recall: 0.7465\n",
      "Epoch 155/200\n",
      "426/426 - 1s - loss: 0.1694 - accuracy: 0.9460 - precision: 0.9569 - recall: 0.9390 - val_loss: 0.7832 - val_accuracy: 0.7676 - val_precision: 0.7826 - val_recall: 0.7606\n",
      "Epoch 156/200\n",
      "426/426 - 1s - loss: 0.1920 - accuracy: 0.9366 - precision: 0.9427 - recall: 0.9272 - val_loss: 0.9041 - val_accuracy: 0.7465 - val_precision: 0.7681 - val_recall: 0.7465\n",
      "Epoch 157/200\n",
      "426/426 - 1s - loss: 0.4079 - accuracy: 0.8615 - precision: 0.8657 - recall: 0.8474 - val_loss: 0.7304 - val_accuracy: 0.7817 - val_precision: 0.8074 - val_recall: 0.7676\n",
      "Epoch 158/200\n",
      "426/426 - 1s - loss: 0.2351 - accuracy: 0.9178 - precision: 0.9306 - recall: 0.9131 - val_loss: 0.6970 - val_accuracy: 0.7746 - val_precision: 0.7910 - val_recall: 0.7465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/200\n",
      "426/426 - 1s - loss: 0.1808 - accuracy: 0.9390 - precision: 0.9455 - recall: 0.9366 - val_loss: 0.6360 - val_accuracy: 0.8099 - val_precision: 0.8143 - val_recall: 0.8028\n",
      "Epoch 160/200\n",
      "426/426 - 1s - loss: 0.2177 - accuracy: 0.9202 - precision: 0.9218 - recall: 0.9131 - val_loss: 0.6306 - val_accuracy: 0.7746 - val_precision: 0.8088 - val_recall: 0.7746\n",
      "Epoch 161/200\n",
      "426/426 - 1s - loss: 0.1977 - accuracy: 0.9343 - precision: 0.9356 - recall: 0.9202 - val_loss: 0.7709 - val_accuracy: 0.7676 - val_precision: 0.7899 - val_recall: 0.7676\n",
      "Epoch 162/200\n",
      "426/426 - 1s - loss: 0.1561 - accuracy: 0.9507 - precision: 0.9592 - recall: 0.9390 - val_loss: 0.6635 - val_accuracy: 0.7958 - val_precision: 0.8058 - val_recall: 0.7887\n",
      "Epoch 163/200\n",
      "426/426 - 1s - loss: 0.1396 - accuracy: 0.9577 - precision: 0.9621 - recall: 0.9531 - val_loss: 0.6823 - val_accuracy: 0.8310 - val_precision: 0.8417 - val_recall: 0.8239\n",
      "Epoch 164/200\n",
      "426/426 - 1s - loss: 0.1235 - accuracy: 0.9671 - precision: 0.9692 - recall: 0.9601 - val_loss: 0.7060 - val_accuracy: 0.7887 - val_precision: 0.8162 - val_recall: 0.7817\n",
      "Epoch 165/200\n",
      "426/426 - 1s - loss: 0.1149 - accuracy: 0.9624 - precision: 0.9716 - recall: 0.9624 - val_loss: 0.7252 - val_accuracy: 0.7887 - val_precision: 0.8102 - val_recall: 0.7817\n",
      "Epoch 166/200\n",
      "426/426 - 1s - loss: 0.1019 - accuracy: 0.9695 - precision: 0.9739 - recall: 0.9648 - val_loss: 0.6511 - val_accuracy: 0.8099 - val_precision: 0.8273 - val_recall: 0.8099\n",
      "Epoch 167/200\n",
      "426/426 - 1s - loss: 0.0838 - accuracy: 0.9812 - precision: 0.9812 - recall: 0.9789 - val_loss: 0.6433 - val_accuracy: 0.8310 - val_precision: 0.8467 - val_recall: 0.8169\n",
      "Epoch 168/200\n",
      "426/426 - 1s - loss: 0.0942 - accuracy: 0.9742 - precision: 0.9740 - recall: 0.9671 - val_loss: 0.6896 - val_accuracy: 0.8099 - val_precision: 0.8382 - val_recall: 0.8028\n",
      "Epoch 169/200\n",
      "426/426 - 1s - loss: 0.0844 - accuracy: 0.9765 - precision: 0.9764 - recall: 0.9718 - val_loss: 0.7835 - val_accuracy: 0.7817 - val_precision: 0.7971 - val_recall: 0.7746\n",
      "Epoch 170/200\n",
      "426/426 - 1s - loss: 0.0930 - accuracy: 0.9742 - precision: 0.9741 - recall: 0.9718 - val_loss: 0.6618 - val_accuracy: 0.8028 - val_precision: 0.8296 - val_recall: 0.7887\n",
      "Epoch 171/200\n",
      "426/426 - 1s - loss: 0.0948 - accuracy: 0.9718 - precision: 0.9718 - recall: 0.9695 - val_loss: 0.6998 - val_accuracy: 0.8099 - val_precision: 0.8261 - val_recall: 0.8028\n",
      "Epoch 172/200\n",
      "426/426 - 1s - loss: 0.1042 - accuracy: 0.9671 - precision: 0.9694 - recall: 0.9671 - val_loss: 0.6785 - val_accuracy: 0.8380 - val_precision: 0.8429 - val_recall: 0.8310\n",
      "Epoch 173/200\n",
      "426/426 - 1s - loss: 0.1115 - accuracy: 0.9671 - precision: 0.9693 - recall: 0.9648 - val_loss: 0.7371 - val_accuracy: 0.7887 - val_precision: 0.8043 - val_recall: 0.7817\n",
      "Epoch 174/200\n",
      "426/426 - 1s - loss: 0.1759 - accuracy: 0.9460 - precision: 0.9502 - recall: 0.9413 - val_loss: 0.7216 - val_accuracy: 0.7746 - val_precision: 0.7941 - val_recall: 0.7606\n",
      "Epoch 175/200\n",
      "426/426 - 1s - loss: 0.1767 - accuracy: 0.9249 - precision: 0.9249 - recall: 0.9249 - val_loss: 0.6360 - val_accuracy: 0.8099 - val_precision: 0.8394 - val_recall: 0.8099\n",
      "Epoch 176/200\n",
      "426/426 - 1s - loss: 0.1616 - accuracy: 0.9413 - precision: 0.9476 - recall: 0.9343 - val_loss: 0.6582 - val_accuracy: 0.8239 - val_precision: 0.8529 - val_recall: 0.8169\n",
      "Epoch 177/200\n",
      "426/426 - 1s - loss: 0.2281 - accuracy: 0.9038 - precision: 0.9100 - recall: 0.9014 - val_loss: 0.6807 - val_accuracy: 0.7676 - val_precision: 0.7842 - val_recall: 0.7676\n",
      "Epoch 178/200\n",
      "426/426 - 1s - loss: 0.2519 - accuracy: 0.9085 - precision: 0.9123 - recall: 0.9038 - val_loss: 0.7560 - val_accuracy: 0.7817 - val_precision: 0.8029 - val_recall: 0.7746\n",
      "Epoch 179/200\n",
      "426/426 - 1s - loss: 0.1805 - accuracy: 0.9319 - precision: 0.9405 - recall: 0.9272 - val_loss: 0.8164 - val_accuracy: 0.7746 - val_precision: 0.7826 - val_recall: 0.7606\n",
      "Epoch 180/200\n",
      "426/426 - 1s - loss: 0.1985 - accuracy: 0.9249 - precision: 0.9269 - recall: 0.9225 - val_loss: 1.0280 - val_accuracy: 0.7183 - val_precision: 0.7319 - val_recall: 0.7113\n",
      "Epoch 181/200\n",
      "426/426 - 1s - loss: 0.3055 - accuracy: 0.8873 - precision: 0.8993 - recall: 0.8803 - val_loss: 0.7656 - val_accuracy: 0.7465 - val_precision: 0.7664 - val_recall: 0.7394\n",
      "Epoch 182/200\n",
      "426/426 - 1s - loss: 0.1683 - accuracy: 0.9484 - precision: 0.9524 - recall: 0.9390 - val_loss: 0.6770 - val_accuracy: 0.8028 - val_precision: 0.8058 - val_recall: 0.7887\n",
      "Epoch 183/200\n",
      "426/426 - 1s - loss: 0.1478 - accuracy: 0.9484 - precision: 0.9505 - recall: 0.9460 - val_loss: 0.7366 - val_accuracy: 0.7746 - val_precision: 0.7971 - val_recall: 0.7746\n",
      "Epoch 184/200\n",
      "426/426 - 1s - loss: 0.1577 - accuracy: 0.9484 - precision: 0.9505 - recall: 0.9460 - val_loss: 0.8124 - val_accuracy: 0.7887 - val_precision: 0.8043 - val_recall: 0.7817\n",
      "Epoch 185/200\n",
      "426/426 - 1s - loss: 0.1348 - accuracy: 0.9507 - precision: 0.9507 - recall: 0.9507 - val_loss: 0.8842 - val_accuracy: 0.7887 - val_precision: 0.7986 - val_recall: 0.7817\n",
      "Epoch 186/200\n",
      "426/426 - 1s - loss: 0.2170 - accuracy: 0.9437 - precision: 0.9499 - recall: 0.9343 - val_loss: 0.8336 - val_accuracy: 0.8028 - val_precision: 0.8071 - val_recall: 0.7958\n",
      "Epoch 187/200\n",
      "426/426 - 1s - loss: 0.1884 - accuracy: 0.9460 - precision: 0.9480 - recall: 0.9413 - val_loss: 0.8026 - val_accuracy: 0.8099 - val_precision: 0.8143 - val_recall: 0.8028\n",
      "Epoch 188/200\n",
      "426/426 - 1s - loss: 0.1855 - accuracy: 0.9531 - precision: 0.9529 - recall: 0.9507 - val_loss: 0.6844 - val_accuracy: 0.8099 - val_precision: 0.8321 - val_recall: 0.8028\n",
      "Epoch 189/200\n",
      "426/426 - 1s - loss: 0.2486 - accuracy: 0.9249 - precision: 0.9332 - recall: 0.9178 - val_loss: 1.0027 - val_accuracy: 0.7324 - val_precision: 0.7481 - val_recall: 0.7113\n",
      "Epoch 190/200\n",
      "426/426 - 1s - loss: 0.2100 - accuracy: 0.9319 - precision: 0.9335 - recall: 0.9225 - val_loss: 0.8264 - val_accuracy: 0.7887 - val_precision: 0.8058 - val_recall: 0.7887\n",
      "Epoch 191/200\n",
      "426/426 - 1s - loss: 0.1613 - accuracy: 0.9531 - precision: 0.9551 - recall: 0.9484 - val_loss: 0.8313 - val_accuracy: 0.7746 - val_precision: 0.7842 - val_recall: 0.7676\n",
      "Epoch 192/200\n",
      "426/426 - 1s - loss: 0.1669 - accuracy: 0.9437 - precision: 0.9459 - recall: 0.9437 - val_loss: 0.8563 - val_accuracy: 0.8169 - val_precision: 0.8261 - val_recall: 0.8028\n",
      "Epoch 193/200\n",
      "426/426 - 1s - loss: 0.1634 - accuracy: 0.9484 - precision: 0.9528 - recall: 0.9484 - val_loss: 0.7100 - val_accuracy: 0.8380 - val_precision: 0.8440 - val_recall: 0.8380\n",
      "Epoch 194/200\n",
      "426/426 - 1s - loss: 0.1211 - accuracy: 0.9601 - precision: 0.9622 - recall: 0.9554 - val_loss: 0.6947 - val_accuracy: 0.8310 - val_precision: 0.8369 - val_recall: 0.8310\n",
      "Epoch 195/200\n",
      "426/426 - 1s - loss: 0.0875 - accuracy: 0.9742 - precision: 0.9764 - recall: 0.9718 - val_loss: 0.6627 - val_accuracy: 0.8169 - val_precision: 0.8235 - val_recall: 0.7887\n",
      "Epoch 196/200\n",
      "426/426 - 1s - loss: 0.0853 - accuracy: 0.9765 - precision: 0.9764 - recall: 0.9718 - val_loss: 0.6270 - val_accuracy: 0.8380 - val_precision: 0.8489 - val_recall: 0.8310\n",
      "Epoch 197/200\n",
      "426/426 - 1s - loss: 0.0742 - accuracy: 0.9812 - precision: 0.9812 - recall: 0.9812 - val_loss: 0.6953 - val_accuracy: 0.8028 - val_precision: 0.8129 - val_recall: 0.7958\n",
      "Epoch 198/200\n",
      "426/426 - 1s - loss: 0.1004 - accuracy: 0.9695 - precision: 0.9717 - recall: 0.9671 - val_loss: 0.6772 - val_accuracy: 0.7958 - val_precision: 0.8014 - val_recall: 0.7958\n",
      "Epoch 199/200\n",
      "426/426 - 1s - loss: 0.1444 - accuracy: 0.9554 - precision: 0.9554 - recall: 0.9554 - val_loss: 0.7045 - val_accuracy: 0.8310 - val_precision: 0.8417 - val_recall: 0.8239\n",
      "Epoch 200/200\n",
      "426/426 - 1s - loss: 0.2099 - accuracy: 0.9413 - precision: 0.9431 - recall: 0.9343 - val_loss: 0.6976 - val_accuracy: 0.7746 - val_precision: 0.8088 - val_recall: 0.7746\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: d2659a21f40236c9e87c1a968a35c794</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8051643371582031</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_1_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_2_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_End: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_input: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-optimizer: Adamax</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 256)          351232    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 128)          197120    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 128)          131584    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 64)           49408     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 763,148\n",
      "Trainable params: 763,148\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Adagrad\n",
      "\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/200\n",
      "426/426 - 10s - loss: 2.4024 - accuracy: 0.1362 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.2920 - val_accuracy: 0.1690 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      "426/426 - 1s - loss: 2.1932 - accuracy: 0.2113 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.1220 - val_accuracy: 0.1972 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/200\n",
      "426/426 - 1s - loss: 2.0154 - accuracy: 0.2207 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9713 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/200\n",
      "426/426 - 1s - loss: 1.9541 - accuracy: 0.2488 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9225 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/200\n",
      "426/426 - 1s - loss: 1.9050 - accuracy: 0.2817 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8848 - val_accuracy: 0.2183 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/200\n",
      "426/426 - 1s - loss: 1.8835 - accuracy: 0.2981 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9436 - val_accuracy: 0.2183 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/200\n",
      "426/426 - 1s - loss: 1.8883 - accuracy: 0.2723 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8439 - val_accuracy: 0.2042 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/200\n",
      "426/426 - 1s - loss: 1.8248 - accuracy: 0.2864 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8335 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/200\n",
      "426/426 - 1s - loss: 1.8082 - accuracy: 0.3005 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8253 - val_accuracy: 0.2324 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/200\n",
      "426/426 - 1s - loss: 1.7941 - accuracy: 0.3052 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8199 - val_accuracy: 0.2183 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/200\n",
      "426/426 - 1s - loss: 1.7861 - accuracy: 0.2934 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8048 - val_accuracy: 0.2746 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/200\n",
      "426/426 - 1s - loss: 1.8663 - accuracy: 0.3052 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8011 - val_accuracy: 0.2183 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/200\n",
      "426/426 - 1s - loss: 1.7758 - accuracy: 0.2887 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7989 - val_accuracy: 0.2465 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/200\n",
      "426/426 - 1s - loss: 1.7637 - accuracy: 0.3052 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7931 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/200\n",
      "426/426 - 1s - loss: 1.7493 - accuracy: 0.3122 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7825 - val_accuracy: 0.2394 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/200\n",
      "426/426 - 1s - loss: 1.7241 - accuracy: 0.3286 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8399 - val_accuracy: 0.2606 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/200\n",
      "426/426 - 1s - loss: 1.7490 - accuracy: 0.3146 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7473 - val_accuracy: 0.2746 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/200\n",
      "426/426 - 1s - loss: 1.7153 - accuracy: 0.3216 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7146 - val_accuracy: 0.2746 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/200\n",
      "426/426 - 1s - loss: 1.7080 - accuracy: 0.3286 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7174 - val_accuracy: 0.2958 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/200\n",
      "426/426 - 1s - loss: 1.6943 - accuracy: 0.3357 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7243 - val_accuracy: 0.2887 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/200\n",
      "426/426 - 1s - loss: 1.6790 - accuracy: 0.3310 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.6808 - val_accuracy: 0.2817 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/200\n",
      "426/426 - 1s - loss: 1.6589 - accuracy: 0.3498 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7185 - val_accuracy: 0.2394 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/200\n",
      "426/426 - 1s - loss: 1.6506 - accuracy: 0.3404 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7805 - val_accuracy: 0.2606 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/200\n",
      "426/426 - 1s - loss: 1.6470 - accuracy: 0.3333 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.6368 - val_accuracy: 0.2887 - val_precision: 1.0000 - val_recall: 0.0070\n",
      "Epoch 25/200\n",
      "426/426 - 1s - loss: 1.6228 - accuracy: 0.3803 - precision: 0.7500 - recall: 0.0070 - val_loss: 1.6274 - val_accuracy: 0.3451 - val_precision: 0.5000 - val_recall: 0.0141\n",
      "Epoch 26/200\n",
      "426/426 - 1s - loss: 1.6201 - accuracy: 0.3685 - precision: 0.6250 - recall: 0.0117 - val_loss: 1.7172 - val_accuracy: 0.3592 - val_precision: 0.6000 - val_recall: 0.0211\n",
      "Epoch 27/200\n",
      "426/426 - 1s - loss: 1.5980 - accuracy: 0.3803 - precision: 0.7500 - recall: 0.0423 - val_loss: 1.6667 - val_accuracy: 0.3803 - val_precision: 0.5769 - val_recall: 0.1056\n",
      "Epoch 28/200\n",
      "426/426 - 1s - loss: 1.5784 - accuracy: 0.4225 - precision: 0.7273 - recall: 0.0563 - val_loss: 1.5845 - val_accuracy: 0.4085 - val_precision: 0.6364 - val_recall: 0.0493\n",
      "Epoch 29/200\n",
      "426/426 - 1s - loss: 1.5944 - accuracy: 0.3897 - precision: 0.7500 - recall: 0.0423 - val_loss: 1.5939 - val_accuracy: 0.3944 - val_precision: 0.5714 - val_recall: 0.0845\n",
      "Epoch 30/200\n",
      "426/426 - 1s - loss: 1.5602 - accuracy: 0.4178 - precision: 0.6296 - recall: 0.0798 - val_loss: 1.6598 - val_accuracy: 0.3310 - val_precision: 0.7778 - val_recall: 0.0493\n",
      "Epoch 31/200\n",
      "426/426 - 1s - loss: 1.5467 - accuracy: 0.4108 - precision: 0.7333 - recall: 0.0516 - val_loss: 1.6024 - val_accuracy: 0.3380 - val_precision: 0.7692 - val_recall: 0.0704\n",
      "Epoch 32/200\n",
      "426/426 - 1s - loss: 1.5262 - accuracy: 0.4272 - precision: 0.7568 - recall: 0.0657 - val_loss: 1.6817 - val_accuracy: 0.3873 - val_precision: 0.7500 - val_recall: 0.0634\n",
      "Epoch 33/200\n",
      "426/426 - 1s - loss: 1.5185 - accuracy: 0.4390 - precision: 0.6863 - recall: 0.0822 - val_loss: 1.6232 - val_accuracy: 0.3944 - val_precision: 0.6500 - val_recall: 0.0915\n",
      "Epoch 34/200\n",
      "426/426 - 1s - loss: 1.5111 - accuracy: 0.4507 - precision: 0.7143 - recall: 0.0822 - val_loss: 1.5141 - val_accuracy: 0.4577 - val_precision: 0.6364 - val_recall: 0.0986\n",
      "Epoch 35/200\n",
      "426/426 - 1s - loss: 1.4980 - accuracy: 0.4413 - precision: 0.6923 - recall: 0.0845 - val_loss: 1.5199 - val_accuracy: 0.4366 - val_precision: 0.7500 - val_recall: 0.0845\n",
      "Epoch 36/200\n",
      "426/426 - 1s - loss: 1.5052 - accuracy: 0.4507 - precision: 0.6786 - recall: 0.0892 - val_loss: 1.5674 - val_accuracy: 0.3873 - val_precision: 0.7368 - val_recall: 0.0986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200\n",
      "426/426 - 1s - loss: 1.4902 - accuracy: 0.4437 - precision: 0.6667 - recall: 0.0892 - val_loss: 1.5172 - val_accuracy: 0.3803 - val_precision: 0.6071 - val_recall: 0.1197\n",
      "Epoch 38/200\n",
      "426/426 - 1s - loss: 1.4655 - accuracy: 0.4554 - precision: 0.6970 - recall: 0.1080 - val_loss: 1.5390 - val_accuracy: 0.4225 - val_precision: 0.8095 - val_recall: 0.1197\n",
      "Epoch 39/200\n",
      "426/426 - 1s - loss: 1.4447 - accuracy: 0.4718 - precision: 0.7273 - recall: 0.1502 - val_loss: 1.4745 - val_accuracy: 0.4437 - val_precision: 0.8889 - val_recall: 0.1127\n",
      "Epoch 40/200\n",
      "426/426 - 1s - loss: 1.4683 - accuracy: 0.4507 - precision: 0.6517 - recall: 0.1362 - val_loss: 1.4887 - val_accuracy: 0.4296 - val_precision: 0.7059 - val_recall: 0.1690\n",
      "Epoch 41/200\n",
      "426/426 - 1s - loss: 1.4242 - accuracy: 0.4789 - precision: 0.7647 - recall: 0.1526 - val_loss: 1.4707 - val_accuracy: 0.4085 - val_precision: 0.7073 - val_recall: 0.2042\n",
      "Epoch 42/200\n",
      "426/426 - 1s - loss: 1.4410 - accuracy: 0.4507 - precision: 0.7333 - recall: 0.1808 - val_loss: 1.4584 - val_accuracy: 0.4366 - val_precision: 0.9259 - val_recall: 0.1761\n",
      "Epoch 43/200\n",
      "426/426 - 1s - loss: 1.4058 - accuracy: 0.4906 - precision: 0.8163 - recall: 0.1878 - val_loss: 1.5598 - val_accuracy: 0.3662 - val_precision: 0.8261 - val_recall: 0.1338\n",
      "Epoch 44/200\n",
      "426/426 - 1s - loss: 1.4081 - accuracy: 0.4765 - precision: 0.8652 - recall: 0.1808 - val_loss: 1.4347 - val_accuracy: 0.4225 - val_precision: 0.8108 - val_recall: 0.2113\n",
      "Epoch 45/200\n",
      "426/426 - 1s - loss: 1.4028 - accuracy: 0.4554 - precision: 0.7864 - recall: 0.1901 - val_loss: 1.5717 - val_accuracy: 0.3662 - val_precision: 0.6279 - val_recall: 0.1901\n",
      "Epoch 46/200\n",
      "426/426 - 1s - loss: 1.4267 - accuracy: 0.4507 - precision: 0.7193 - recall: 0.1925 - val_loss: 1.4424 - val_accuracy: 0.4718 - val_precision: 0.7805 - val_recall: 0.2254\n",
      "Epoch 47/200\n",
      "426/426 - 1s - loss: 1.3842 - accuracy: 0.4883 - precision: 0.7727 - recall: 0.1995 - val_loss: 1.4664 - val_accuracy: 0.4507 - val_precision: 0.6667 - val_recall: 0.2535\n",
      "Epoch 48/200\n",
      "426/426 - 1s - loss: 1.3755 - accuracy: 0.4977 - precision: 0.6875 - recall: 0.2066 - val_loss: 1.3973 - val_accuracy: 0.4930 - val_precision: 0.7857 - val_recall: 0.2324\n",
      "Epoch 49/200\n",
      "426/426 - 1s - loss: 1.3722 - accuracy: 0.5023 - precision: 0.7845 - recall: 0.2136 - val_loss: 1.4308 - val_accuracy: 0.4225 - val_precision: 0.6667 - val_recall: 0.2254\n",
      "Epoch 50/200\n",
      "426/426 - 1s - loss: 1.3587 - accuracy: 0.5211 - precision: 0.7153 - recall: 0.2300 - val_loss: 1.4280 - val_accuracy: 0.4437 - val_precision: 0.7500 - val_recall: 0.2324\n",
      "Epoch 51/200\n",
      "426/426 - 1s - loss: 1.3442 - accuracy: 0.5282 - precision: 0.8036 - recall: 0.2113 - val_loss: 1.3873 - val_accuracy: 0.5000 - val_precision: 0.7609 - val_recall: 0.2465\n",
      "Epoch 52/200\n",
      "426/426 - 1s - loss: 1.3164 - accuracy: 0.5540 - precision: 0.7984 - recall: 0.2324 - val_loss: 1.4330 - val_accuracy: 0.4577 - val_precision: 0.8108 - val_recall: 0.2113\n",
      "Epoch 53/200\n",
      "426/426 - 1s - loss: 1.3165 - accuracy: 0.5211 - precision: 0.8167 - recall: 0.2300 - val_loss: 1.5041 - val_accuracy: 0.4296 - val_precision: 0.7000 - val_recall: 0.2465\n",
      "Epoch 54/200\n",
      "426/426 - 1s - loss: 1.2865 - accuracy: 0.5587 - precision: 0.8387 - recall: 0.2441 - val_loss: 1.4413 - val_accuracy: 0.4155 - val_precision: 0.6889 - val_recall: 0.2183\n",
      "Epoch 55/200\n",
      "426/426 - 1s - loss: 1.3537 - accuracy: 0.5070 - precision: 0.7523 - recall: 0.1925 - val_loss: 1.4170 - val_accuracy: 0.4437 - val_precision: 0.8571 - val_recall: 0.2113\n",
      "Epoch 56/200\n",
      "426/426 - 1s - loss: 1.3115 - accuracy: 0.5141 - precision: 0.8049 - recall: 0.2324 - val_loss: 1.3728 - val_accuracy: 0.4859 - val_precision: 0.7778 - val_recall: 0.2465\n",
      "Epoch 57/200\n",
      "426/426 - 1s - loss: 1.2824 - accuracy: 0.5516 - precision: 0.8480 - recall: 0.2488 - val_loss: 1.6285 - val_accuracy: 0.3521 - val_precision: 0.5873 - val_recall: 0.2606\n",
      "Epoch 58/200\n",
      "426/426 - 1s - loss: 1.2922 - accuracy: 0.5493 - precision: 0.8227 - recall: 0.2723 - val_loss: 1.4238 - val_accuracy: 0.4507 - val_precision: 0.7193 - val_recall: 0.2887\n",
      "Epoch 59/200\n",
      "426/426 - 1s - loss: 1.2426 - accuracy: 0.5892 - precision: 0.8243 - recall: 0.2864 - val_loss: 1.3637 - val_accuracy: 0.4930 - val_precision: 0.7500 - val_recall: 0.2746\n",
      "Epoch 60/200\n",
      "426/426 - 1s - loss: 1.2537 - accuracy: 0.5775 - precision: 0.8166 - recall: 0.3239 - val_loss: 1.5021 - val_accuracy: 0.4366 - val_precision: 0.7541 - val_recall: 0.3239\n",
      "Epoch 61/200\n",
      "426/426 - 1s - loss: 1.2470 - accuracy: 0.5704 - precision: 0.8114 - recall: 0.3333 - val_loss: 1.4609 - val_accuracy: 0.4789 - val_precision: 0.6981 - val_recall: 0.2606\n",
      "Epoch 62/200\n",
      "426/426 - 1s - loss: 1.2132 - accuracy: 0.5822 - precision: 0.8232 - recall: 0.3169 - val_loss: 1.5938 - val_accuracy: 0.3803 - val_precision: 0.5846 - val_recall: 0.2676\n",
      "Epoch 63/200\n",
      "426/426 - 1s - loss: 1.2043 - accuracy: 0.5798 - precision: 0.8182 - recall: 0.3380 - val_loss: 1.3334 - val_accuracy: 0.5211 - val_precision: 0.8413 - val_recall: 0.3732\n",
      "Epoch 64/200\n",
      "426/426 - 1s - loss: 1.2483 - accuracy: 0.5587 - precision: 0.7907 - recall: 0.3192 - val_loss: 1.3080 - val_accuracy: 0.4789 - val_precision: 0.8039 - val_recall: 0.2887\n",
      "Epoch 65/200\n",
      "426/426 - 1s - loss: 1.1580 - accuracy: 0.6338 - precision: 0.8482 - recall: 0.3803 - val_loss: 1.3533 - val_accuracy: 0.5000 - val_precision: 0.8226 - val_recall: 0.3592\n",
      "Epoch 66/200\n",
      "426/426 - 1s - loss: 1.1951 - accuracy: 0.5775 - precision: 0.8342 - recall: 0.3779 - val_loss: 1.2824 - val_accuracy: 0.4930 - val_precision: 0.7586 - val_recall: 0.3099\n",
      "Epoch 67/200\n",
      "426/426 - 1s - loss: 1.1852 - accuracy: 0.5939 - precision: 0.8281 - recall: 0.3732 - val_loss: 1.2762 - val_accuracy: 0.5423 - val_precision: 0.7969 - val_recall: 0.3592\n",
      "Epoch 68/200\n",
      "426/426 - 1s - loss: 1.1757 - accuracy: 0.6244 - precision: 0.8186 - recall: 0.3920 - val_loss: 1.2359 - val_accuracy: 0.5352 - val_precision: 0.8060 - val_recall: 0.3803\n",
      "Epoch 69/200\n",
      "426/426 - 1s - loss: 1.0998 - accuracy: 0.6643 - precision: 0.8551 - recall: 0.4296 - val_loss: 1.2814 - val_accuracy: 0.5070 - val_precision: 0.8060 - val_recall: 0.3803\n",
      "Epoch 70/200\n",
      "426/426 - 1s - loss: 1.1221 - accuracy: 0.6244 - precision: 0.8408 - recall: 0.3967 - val_loss: 1.3290 - val_accuracy: 0.4859 - val_precision: 0.7258 - val_recall: 0.3169\n",
      "Epoch 71/200\n",
      "426/426 - 1s - loss: 1.0929 - accuracy: 0.6479 - precision: 0.8512 - recall: 0.4296 - val_loss: 1.3040 - val_accuracy: 0.5000 - val_precision: 0.6933 - val_recall: 0.3662\n",
      "Epoch 72/200\n",
      "426/426 - 1s - loss: 1.0673 - accuracy: 0.6596 - precision: 0.8636 - recall: 0.4460 - val_loss: 1.2621 - val_accuracy: 0.5141 - val_precision: 0.7576 - val_recall: 0.3521\n",
      "Epoch 73/200\n",
      "426/426 - 1s - loss: 1.1000 - accuracy: 0.6221 - precision: 0.8458 - recall: 0.4249 - val_loss: 1.4111 - val_accuracy: 0.4789 - val_precision: 0.6949 - val_recall: 0.2887\n",
      "Epoch 74/200\n",
      "426/426 - 1s - loss: 1.0616 - accuracy: 0.6408 - precision: 0.8605 - recall: 0.4343 - val_loss: 1.4471 - val_accuracy: 0.4859 - val_precision: 0.6044 - val_recall: 0.3873\n",
      "Epoch 75/200\n",
      "426/426 - 1s - loss: 1.0820 - accuracy: 0.6479 - precision: 0.8391 - recall: 0.4531 - val_loss: 1.1851 - val_accuracy: 0.5493 - val_precision: 0.7746 - val_recall: 0.3873\n",
      "Epoch 76/200\n",
      "426/426 - 1s - loss: 1.0099 - accuracy: 0.6854 - precision: 0.8855 - recall: 0.4718 - val_loss: 1.1488 - val_accuracy: 0.5986 - val_precision: 0.7500 - val_recall: 0.4437\n",
      "Epoch 77/200\n",
      "426/426 - 1s - loss: 1.0754 - accuracy: 0.6549 - precision: 0.7940 - recall: 0.4343 - val_loss: 1.1648 - val_accuracy: 0.5775 - val_precision: 0.7467 - val_recall: 0.3944\n",
      "Epoch 78/200\n",
      "426/426 - 1s - loss: 1.0067 - accuracy: 0.6690 - precision: 0.8860 - recall: 0.4742 - val_loss: 1.1331 - val_accuracy: 0.5634 - val_precision: 0.7600 - val_recall: 0.4014\n",
      "Epoch 79/200\n",
      "426/426 - 1s - loss: 0.9828 - accuracy: 0.6831 - precision: 0.8954 - recall: 0.5023 - val_loss: 1.2786 - val_accuracy: 0.5000 - val_precision: 0.8194 - val_recall: 0.4155\n",
      "Epoch 80/200\n",
      "426/426 - 1s - loss: 0.9651 - accuracy: 0.7066 - precision: 0.9118 - recall: 0.5094 - val_loss: 1.2582 - val_accuracy: 0.5070 - val_precision: 0.7895 - val_recall: 0.4225\n",
      "Epoch 81/200\n",
      "426/426 - 1s - loss: 0.9776 - accuracy: 0.6667 - precision: 0.8627 - recall: 0.4718 - val_loss: 1.0726 - val_accuracy: 0.6056 - val_precision: 0.8356 - val_recall: 0.4296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "426/426 - 1s - loss: 0.9745 - accuracy: 0.6620 - precision: 0.8917 - recall: 0.5023 - val_loss: 1.1653 - val_accuracy: 0.5775 - val_precision: 0.7857 - val_recall: 0.3873\n",
      "Epoch 83/200\n",
      "426/426 - 1s - loss: 0.9677 - accuracy: 0.6925 - precision: 0.8809 - recall: 0.4859 - val_loss: 1.2237 - val_accuracy: 0.5634 - val_precision: 0.7375 - val_recall: 0.4155\n",
      "Epoch 84/200\n",
      "426/426 - 1s - loss: 0.9882 - accuracy: 0.6714 - precision: 0.8306 - recall: 0.4836 - val_loss: 1.1440 - val_accuracy: 0.5845 - val_precision: 0.7879 - val_recall: 0.3662\n",
      "Epoch 85/200\n",
      "426/426 - 1s - loss: 0.9187 - accuracy: 0.7136 - precision: 0.9072 - recall: 0.5047 - val_loss: 1.0728 - val_accuracy: 0.6408 - val_precision: 0.8205 - val_recall: 0.4507\n",
      "Epoch 86/200\n",
      "426/426 - 0s - loss: 0.9362 - accuracy: 0.6995 - precision: 0.8821 - recall: 0.5094 - val_loss: 1.4272 - val_accuracy: 0.4507 - val_precision: 0.7067 - val_recall: 0.3732\n",
      "Epoch 87/200\n",
      "426/426 - 1s - loss: 0.9199 - accuracy: 0.7042 - precision: 0.8849 - recall: 0.5235 - val_loss: 1.0927 - val_accuracy: 0.6197 - val_precision: 0.8333 - val_recall: 0.4225\n",
      "Epoch 88/200\n",
      "426/426 - 1s - loss: 0.8586 - accuracy: 0.7371 - precision: 0.9027 - recall: 0.5446 - val_loss: 1.7790 - val_accuracy: 0.3873 - val_precision: 0.5862 - val_recall: 0.2394\n",
      "Epoch 89/200\n",
      "426/426 - 1s - loss: 1.1759 - accuracy: 0.6127 - precision: 0.8028 - recall: 0.4108 - val_loss: 1.0799 - val_accuracy: 0.6268 - val_precision: 0.8171 - val_recall: 0.4718\n",
      "Epoch 90/200\n",
      "426/426 - 1s - loss: 0.8539 - accuracy: 0.7324 - precision: 0.8919 - recall: 0.5423 - val_loss: 1.1499 - val_accuracy: 0.5493 - val_precision: 0.7595 - val_recall: 0.4225\n",
      "Epoch 91/200\n",
      "426/426 - 1s - loss: 0.8416 - accuracy: 0.7347 - precision: 0.9120 - recall: 0.5352 - val_loss: 1.1462 - val_accuracy: 0.5563 - val_precision: 0.7105 - val_recall: 0.3803\n",
      "Epoch 92/200\n",
      "426/426 - 1s - loss: 0.8517 - accuracy: 0.7300 - precision: 0.8731 - recall: 0.5329 - val_loss: 1.0225 - val_accuracy: 0.6338 - val_precision: 0.8500 - val_recall: 0.4789\n",
      "Epoch 93/200\n",
      "426/426 - 1s - loss: 0.7736 - accuracy: 0.7864 - precision: 0.9213 - recall: 0.5775 - val_loss: 1.0110 - val_accuracy: 0.6479 - val_precision: 0.8354 - val_recall: 0.4648\n",
      "Epoch 94/200\n",
      "426/426 - 1s - loss: 0.7523 - accuracy: 0.8028 - precision: 0.9145 - recall: 0.5775 - val_loss: 1.0674 - val_accuracy: 0.6479 - val_precision: 0.8293 - val_recall: 0.4789\n",
      "Epoch 95/200\n",
      "426/426 - 1s - loss: 0.8584 - accuracy: 0.7324 - precision: 0.8889 - recall: 0.5446 - val_loss: 1.0264 - val_accuracy: 0.6408 - val_precision: 0.8205 - val_recall: 0.4507\n",
      "Epoch 96/200\n",
      "426/426 - 1s - loss: 0.8065 - accuracy: 0.7676 - precision: 0.8969 - recall: 0.5516 - val_loss: 1.1810 - val_accuracy: 0.5845 - val_precision: 0.8421 - val_recall: 0.4507\n",
      "Epoch 97/200\n",
      "426/426 - 1s - loss: 0.7679 - accuracy: 0.7746 - precision: 0.9242 - recall: 0.5728 - val_loss: 0.9286 - val_accuracy: 0.7183 - val_precision: 0.8947 - val_recall: 0.4789\n",
      "Epoch 98/200\n",
      "426/426 - 1s - loss: 0.7432 - accuracy: 0.7981 - precision: 0.9197 - recall: 0.5915 - val_loss: 1.0188 - val_accuracy: 0.6268 - val_precision: 0.7935 - val_recall: 0.5141\n",
      "Epoch 99/200\n",
      "426/426 - 1s - loss: 0.7200 - accuracy: 0.8146 - precision: 0.9121 - recall: 0.5845 - val_loss: 1.0286 - val_accuracy: 0.6479 - val_precision: 0.7816 - val_recall: 0.4789\n",
      "Epoch 100/200\n",
      "426/426 - 1s - loss: 0.6769 - accuracy: 0.8263 - precision: 0.9410 - recall: 0.6362 - val_loss: 1.2251 - val_accuracy: 0.5282 - val_precision: 0.7216 - val_recall: 0.4930\n",
      "Epoch 101/200\n",
      "426/426 - 1s - loss: 0.7416 - accuracy: 0.8192 - precision: 0.9078 - recall: 0.6009 - val_loss: 0.9006 - val_accuracy: 0.7394 - val_precision: 0.8608 - val_recall: 0.4789\n",
      "Epoch 102/200\n",
      "426/426 - 1s - loss: 0.6830 - accuracy: 0.8474 - precision: 0.9362 - recall: 0.6197 - val_loss: 0.9324 - val_accuracy: 0.6690 - val_precision: 0.8140 - val_recall: 0.4930\n",
      "Epoch 103/200\n",
      "426/426 - 1s - loss: 0.6579 - accuracy: 0.8545 - precision: 0.9313 - recall: 0.6362 - val_loss: 1.2367 - val_accuracy: 0.5775 - val_precision: 0.6915 - val_recall: 0.4577\n",
      "Epoch 104/200\n",
      "426/426 - 1s - loss: 0.7529 - accuracy: 0.7864 - precision: 0.9020 - recall: 0.6268 - val_loss: 0.8889 - val_accuracy: 0.7324 - val_precision: 0.8488 - val_recall: 0.5141\n",
      "Epoch 105/200\n",
      "426/426 - 1s - loss: 0.6691 - accuracy: 0.8404 - precision: 0.9302 - recall: 0.6573 - val_loss: 0.8939 - val_accuracy: 0.6761 - val_precision: 0.8298 - val_recall: 0.5493\n",
      "Epoch 106/200\n",
      "426/426 - 1s - loss: 0.6534 - accuracy: 0.8451 - precision: 0.9279 - recall: 0.6643 - val_loss: 1.2251 - val_accuracy: 0.5845 - val_precision: 0.7701 - val_recall: 0.4718\n",
      "Epoch 107/200\n",
      "426/426 - 1s - loss: 0.7388 - accuracy: 0.7981 - precision: 0.8946 - recall: 0.6174 - val_loss: 1.0841 - val_accuracy: 0.6056 - val_precision: 0.7129 - val_recall: 0.5070\n",
      "Epoch 108/200\n",
      "426/426 - 1s - loss: 0.8434 - accuracy: 0.7418 - precision: 0.8480 - recall: 0.5892 - val_loss: 0.8746 - val_accuracy: 0.7254 - val_precision: 0.8387 - val_recall: 0.5493\n",
      "Epoch 109/200\n",
      "426/426 - 1s - loss: 0.6073 - accuracy: 0.8498 - precision: 0.9486 - recall: 0.6925 - val_loss: 0.8674 - val_accuracy: 0.7042 - val_precision: 0.8421 - val_recall: 0.5634\n",
      "Epoch 110/200\n",
      "426/426 - 1s - loss: 0.6164 - accuracy: 0.8263 - precision: 0.9365 - recall: 0.6925 - val_loss: 0.9079 - val_accuracy: 0.6761 - val_precision: 0.7959 - val_recall: 0.5493\n",
      "Epoch 111/200\n",
      "426/426 - 1s - loss: 0.6314 - accuracy: 0.8427 - precision: 0.9281 - recall: 0.6972 - val_loss: 0.8766 - val_accuracy: 0.7113 - val_precision: 0.8469 - val_recall: 0.5845\n",
      "Epoch 112/200\n",
      "426/426 - 1s - loss: 0.5664 - accuracy: 0.8709 - precision: 0.9431 - recall: 0.7394 - val_loss: 0.8131 - val_accuracy: 0.7394 - val_precision: 0.8646 - val_recall: 0.5845\n",
      "Epoch 113/200\n",
      "426/426 - 1s - loss: 0.6180 - accuracy: 0.8427 - precision: 0.9308 - recall: 0.6948 - val_loss: 1.2618 - val_accuracy: 0.5704 - val_precision: 0.6789 - val_recall: 0.5211\n",
      "Epoch 114/200\n",
      "426/426 - 1s - loss: 0.6556 - accuracy: 0.8192 - precision: 0.8754 - recall: 0.7089 - val_loss: 0.7869 - val_accuracy: 0.7324 - val_precision: 0.8737 - val_recall: 0.5845\n",
      "Epoch 115/200\n",
      "426/426 - 1s - loss: 0.6651 - accuracy: 0.8263 - precision: 0.8829 - recall: 0.6901 - val_loss: 1.1869 - val_accuracy: 0.5704 - val_precision: 0.6465 - val_recall: 0.4507\n",
      "Epoch 116/200\n",
      "426/426 - 1s - loss: 0.6034 - accuracy: 0.8451 - precision: 0.9159 - recall: 0.7160 - val_loss: 0.7900 - val_accuracy: 0.7394 - val_precision: 0.8454 - val_recall: 0.5775\n",
      "Epoch 117/200\n",
      "426/426 - 1s - loss: 0.5218 - accuracy: 0.8944 - precision: 0.9503 - recall: 0.7629 - val_loss: 1.0626 - val_accuracy: 0.6338 - val_precision: 0.7843 - val_recall: 0.5634\n",
      "Epoch 118/200\n",
      "426/426 - 1s - loss: 0.6462 - accuracy: 0.8310 - precision: 0.8841 - recall: 0.7160 - val_loss: 0.8505 - val_accuracy: 0.7113 - val_precision: 0.8350 - val_recall: 0.6056\n",
      "Epoch 119/200\n",
      "426/426 - 1s - loss: 0.5687 - accuracy: 0.8662 - precision: 0.9290 - recall: 0.7371 - val_loss: 1.3105 - val_accuracy: 0.5634 - val_precision: 0.6019 - val_recall: 0.4366\n",
      "Epoch 120/200\n",
      "426/426 - 1s - loss: 0.9044 - accuracy: 0.7300 - precision: 0.7699 - recall: 0.6127 - val_loss: 0.9392 - val_accuracy: 0.6479 - val_precision: 0.7879 - val_recall: 0.5493\n",
      "Epoch 121/200\n",
      "426/426 - 1s - loss: 0.6289 - accuracy: 0.8146 - precision: 0.8953 - recall: 0.7230 - val_loss: 0.8886 - val_accuracy: 0.7042 - val_precision: 0.7963 - val_recall: 0.6056\n",
      "Epoch 122/200\n",
      "426/426 - 1s - loss: 0.5297 - accuracy: 0.8826 - precision: 0.9288 - recall: 0.7653 - val_loss: 0.8648 - val_accuracy: 0.6972 - val_precision: 0.8081 - val_recall: 0.5634\n",
      "Epoch 123/200\n",
      "426/426 - 1s - loss: 0.5946 - accuracy: 0.8474 - precision: 0.9046 - recall: 0.7347 - val_loss: 1.1503 - val_accuracy: 0.6197 - val_precision: 0.7018 - val_recall: 0.5634\n",
      "Epoch 124/200\n",
      "426/426 - 1s - loss: 0.5440 - accuracy: 0.8662 - precision: 0.9226 - recall: 0.7559 - val_loss: 0.7827 - val_accuracy: 0.7113 - val_precision: 0.8302 - val_recall: 0.6197\n",
      "Epoch 125/200\n",
      "426/426 - 1s - loss: 0.4874 - accuracy: 0.8756 - precision: 0.9379 - recall: 0.7793 - val_loss: 0.7346 - val_accuracy: 0.7535 - val_precision: 0.8958 - val_recall: 0.6056\n",
      "Epoch 126/200\n",
      "426/426 - 1s - loss: 0.5025 - accuracy: 0.8756 - precision: 0.9504 - recall: 0.7653 - val_loss: 1.2874 - val_accuracy: 0.6127 - val_precision: 0.7000 - val_recall: 0.5423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/200\n",
      "426/426 - 1s - loss: 0.5736 - accuracy: 0.8404 - precision: 0.9249 - recall: 0.7230 - val_loss: 0.7878 - val_accuracy: 0.7394 - val_precision: 0.8476 - val_recall: 0.6268\n",
      "Epoch 128/200\n",
      "426/426 - 1s - loss: 0.4420 - accuracy: 0.8967 - precision: 0.9551 - recall: 0.7981 - val_loss: 0.7470 - val_accuracy: 0.7535 - val_precision: 0.8532 - val_recall: 0.6549\n",
      "Epoch 129/200\n",
      "426/426 - 1s - loss: 0.4434 - accuracy: 0.9038 - precision: 0.9512 - recall: 0.8239 - val_loss: 0.9181 - val_accuracy: 0.6901 - val_precision: 0.7739 - val_recall: 0.6268\n",
      "Epoch 130/200\n",
      "426/426 - 1s - loss: 0.4544 - accuracy: 0.8897 - precision: 0.9421 - recall: 0.8028 - val_loss: 0.7383 - val_accuracy: 0.7465 - val_precision: 0.8922 - val_recall: 0.6408\n",
      "Epoch 131/200\n",
      "426/426 - 1s - loss: 0.4348 - accuracy: 0.9038 - precision: 0.9507 - recall: 0.8146 - val_loss: 0.7936 - val_accuracy: 0.7324 - val_precision: 0.8396 - val_recall: 0.6268\n",
      "Epoch 132/200\n",
      "426/426 - 1s - loss: 0.4235 - accuracy: 0.9085 - precision: 0.9507 - recall: 0.8146 - val_loss: 0.7817 - val_accuracy: 0.7394 - val_precision: 0.8378 - val_recall: 0.6549\n",
      "Epoch 133/200\n",
      "426/426 - 1s - loss: 0.4198 - accuracy: 0.9061 - precision: 0.9539 - recall: 0.8263 - val_loss: 0.8122 - val_accuracy: 0.7254 - val_precision: 0.8224 - val_recall: 0.6197\n",
      "Epoch 134/200\n",
      "426/426 - 1s - loss: 0.4044 - accuracy: 0.9155 - precision: 0.9572 - recall: 0.8404 - val_loss: 0.7249 - val_accuracy: 0.7394 - val_precision: 0.8692 - val_recall: 0.6549\n",
      "Epoch 135/200\n",
      "426/426 - 0s - loss: 0.4170 - accuracy: 0.8991 - precision: 0.9520 - recall: 0.8380 - val_loss: 0.8039 - val_accuracy: 0.7254 - val_precision: 0.8505 - val_recall: 0.6408\n",
      "Epoch 136/200\n",
      "426/426 - 1s - loss: 0.4953 - accuracy: 0.8826 - precision: 0.9392 - recall: 0.7981 - val_loss: 0.7062 - val_accuracy: 0.7746 - val_precision: 0.8750 - val_recall: 0.6901\n",
      "Epoch 137/200\n",
      "426/426 - 0s - loss: 0.4194 - accuracy: 0.8991 - precision: 0.9465 - recall: 0.8310 - val_loss: 0.6962 - val_accuracy: 0.7606 - val_precision: 0.8611 - val_recall: 0.6549\n",
      "Epoch 138/200\n",
      "426/426 - 1s - loss: 0.4067 - accuracy: 0.9131 - precision: 0.9572 - recall: 0.8404 - val_loss: 0.7022 - val_accuracy: 0.7746 - val_precision: 0.8509 - val_recall: 0.6831\n",
      "Epoch 139/200\n",
      "426/426 - 1s - loss: 0.4123 - accuracy: 0.8967 - precision: 0.9439 - recall: 0.8286 - val_loss: 0.7059 - val_accuracy: 0.7817 - val_precision: 0.8547 - val_recall: 0.7042\n",
      "Epoch 140/200\n",
      "426/426 - 1s - loss: 0.4216 - accuracy: 0.8991 - precision: 0.9454 - recall: 0.8122 - val_loss: 0.7143 - val_accuracy: 0.7817 - val_precision: 0.8421 - val_recall: 0.6761\n",
      "Epoch 141/200\n",
      "426/426 - 1s - loss: 0.4120 - accuracy: 0.9061 - precision: 0.9468 - recall: 0.8357 - val_loss: 0.9997 - val_accuracy: 0.6549 - val_precision: 0.7250 - val_recall: 0.6127\n",
      "Epoch 142/200\n",
      "426/426 - 1s - loss: 0.5403 - accuracy: 0.8568 - precision: 0.9096 - recall: 0.8028 - val_loss: 0.7343 - val_accuracy: 0.7394 - val_precision: 0.8214 - val_recall: 0.6479\n",
      "Epoch 143/200\n",
      "426/426 - 1s - loss: 0.3912 - accuracy: 0.9155 - precision: 0.9545 - recall: 0.8380 - val_loss: 0.7957 - val_accuracy: 0.7324 - val_precision: 0.8198 - val_recall: 0.6408\n",
      "Epoch 144/200\n",
      "426/426 - 1s - loss: 0.4667 - accuracy: 0.8826 - precision: 0.9223 - recall: 0.8075 - val_loss: 0.9238 - val_accuracy: 0.6549 - val_precision: 0.7391 - val_recall: 0.5986\n",
      "Epoch 145/200\n",
      "426/426 - 1s - loss: 0.4930 - accuracy: 0.8638 - precision: 0.9000 - recall: 0.8028 - val_loss: 0.7744 - val_accuracy: 0.7394 - val_precision: 0.7913 - val_recall: 0.6408\n",
      "Epoch 146/200\n",
      "426/426 - 1s - loss: 0.4838 - accuracy: 0.8803 - precision: 0.9153 - recall: 0.7864 - val_loss: 0.7220 - val_accuracy: 0.7535 - val_precision: 0.8417 - val_recall: 0.7113\n",
      "Epoch 147/200\n",
      "426/426 - 1s - loss: 0.3775 - accuracy: 0.9249 - precision: 0.9459 - recall: 0.8615 - val_loss: 0.7052 - val_accuracy: 0.7676 - val_precision: 0.8435 - val_recall: 0.6831\n",
      "Epoch 148/200\n",
      "426/426 - 1s - loss: 0.4391 - accuracy: 0.8873 - precision: 0.9328 - recall: 0.8146 - val_loss: 0.7489 - val_accuracy: 0.7746 - val_precision: 0.8362 - val_recall: 0.6831\n",
      "Epoch 149/200\n",
      "426/426 - 1s - loss: 0.3733 - accuracy: 0.9202 - precision: 0.9531 - recall: 0.8592 - val_loss: 0.6947 - val_accuracy: 0.7817 - val_precision: 0.8403 - val_recall: 0.7042\n",
      "Epoch 150/200\n",
      "426/426 - 1s - loss: 0.3651 - accuracy: 0.9178 - precision: 0.9563 - recall: 0.8732 - val_loss: 0.6573 - val_accuracy: 0.7887 - val_precision: 0.8621 - val_recall: 0.7042\n",
      "Epoch 151/200\n",
      "426/426 - 1s - loss: 0.3504 - accuracy: 0.9272 - precision: 0.9517 - recall: 0.8779 - val_loss: 0.7011 - val_accuracy: 0.7746 - val_precision: 0.8403 - val_recall: 0.7042\n",
      "Epoch 152/200\n",
      "426/426 - 1s - loss: 0.6104 - accuracy: 0.8099 - precision: 0.8568 - recall: 0.7582 - val_loss: 0.7116 - val_accuracy: 0.7746 - val_precision: 0.7984 - val_recall: 0.6972\n",
      "Epoch 153/200\n",
      "426/426 - 1s - loss: 0.3795 - accuracy: 0.8967 - precision: 0.9406 - recall: 0.8545 - val_loss: 0.6892 - val_accuracy: 0.7676 - val_precision: 0.8796 - val_recall: 0.6690\n",
      "Epoch 154/200\n",
      "426/426 - 1s - loss: 0.3502 - accuracy: 0.9225 - precision: 0.9519 - recall: 0.8826 - val_loss: 0.6883 - val_accuracy: 0.7887 - val_precision: 0.8644 - val_recall: 0.7183\n",
      "Epoch 155/200\n",
      "426/426 - 1s - loss: 0.3555 - accuracy: 0.9178 - precision: 0.9392 - recall: 0.8709 - val_loss: 0.6921 - val_accuracy: 0.7817 - val_precision: 0.8548 - val_recall: 0.7465\n",
      "Epoch 156/200\n",
      "426/426 - 1s - loss: 0.3266 - accuracy: 0.9343 - precision: 0.9618 - recall: 0.8873 - val_loss: 0.7103 - val_accuracy: 0.7676 - val_precision: 0.8390 - val_recall: 0.6972\n",
      "Epoch 157/200\n",
      "426/426 - 1s - loss: 0.4211 - accuracy: 0.8967 - precision: 0.9239 - recall: 0.8545 - val_loss: 1.3304 - val_accuracy: 0.6056 - val_precision: 0.6694 - val_recall: 0.5845\n",
      "Epoch 158/200\n",
      "426/426 - 1s - loss: 0.5877 - accuracy: 0.8099 - precision: 0.8586 - recall: 0.7700 - val_loss: 0.7414 - val_accuracy: 0.7465 - val_precision: 0.8120 - val_recall: 0.6690\n",
      "Epoch 159/200\n",
      "426/426 - 1s - loss: 0.3537 - accuracy: 0.9155 - precision: 0.9443 - recall: 0.8756 - val_loss: 0.7082 - val_accuracy: 0.7606 - val_precision: 0.8595 - val_recall: 0.7324\n",
      "Epoch 160/200\n",
      "426/426 - 1s - loss: 0.3240 - accuracy: 0.9272 - precision: 0.9596 - recall: 0.8920 - val_loss: 0.7075 - val_accuracy: 0.7394 - val_precision: 0.8390 - val_recall: 0.6972\n",
      "Epoch 161/200\n",
      "426/426 - 1s - loss: 0.3684 - accuracy: 0.9155 - precision: 0.9345 - recall: 0.8709 - val_loss: 0.6961 - val_accuracy: 0.7535 - val_precision: 0.8462 - val_recall: 0.6972\n",
      "Epoch 162/200\n",
      "426/426 - 1s - loss: 0.3040 - accuracy: 0.9437 - precision: 0.9653 - recall: 0.9155 - val_loss: 0.6656 - val_accuracy: 0.7817 - val_precision: 0.8333 - val_recall: 0.7394\n",
      "Epoch 163/200\n",
      "426/426 - 1s - loss: 0.2973 - accuracy: 0.9460 - precision: 0.9654 - recall: 0.9178 - val_loss: 1.1065 - val_accuracy: 0.6549 - val_precision: 0.7025 - val_recall: 0.5986\n",
      "Epoch 164/200\n",
      "426/426 - 1s - loss: 0.4343 - accuracy: 0.8873 - precision: 0.9129 - recall: 0.8615 - val_loss: 1.7132 - val_accuracy: 0.5423 - val_precision: 0.5714 - val_recall: 0.4789\n",
      "Epoch 165/200\n",
      "426/426 - 1s - loss: 1.1626 - accuracy: 0.6620 - precision: 0.7239 - recall: 0.6033 - val_loss: 1.0365 - val_accuracy: 0.6338 - val_precision: 0.7431 - val_recall: 0.5704\n",
      "Epoch 166/200\n",
      "426/426 - 1s - loss: 0.5733 - accuracy: 0.8122 - precision: 0.8830 - recall: 0.7441 - val_loss: 0.6812 - val_accuracy: 0.7606 - val_precision: 0.8624 - val_recall: 0.6620\n",
      "Epoch 167/200\n",
      "426/426 - 0s - loss: 0.3874 - accuracy: 0.8944 - precision: 0.9378 - recall: 0.8146 - val_loss: 1.0755 - val_accuracy: 0.6690 - val_precision: 0.7250 - val_recall: 0.6127\n",
      "Epoch 168/200\n",
      "426/426 - 1s - loss: 0.4818 - accuracy: 0.8709 - precision: 0.8927 - recall: 0.8005 - val_loss: 0.7674 - val_accuracy: 0.7465 - val_precision: 0.8276 - val_recall: 0.6761\n",
      "Epoch 169/200\n",
      "426/426 - 1s - loss: 0.4679 - accuracy: 0.8732 - precision: 0.9079 - recall: 0.8099 - val_loss: 0.7365 - val_accuracy: 0.7676 - val_precision: 0.8333 - val_recall: 0.7042\n",
      "Epoch 170/200\n",
      "426/426 - 1s - loss: 0.3980 - accuracy: 0.9038 - precision: 0.9284 - recall: 0.8521 - val_loss: 0.7378 - val_accuracy: 0.7887 - val_precision: 0.8417 - val_recall: 0.7113\n",
      "Epoch 171/200\n",
      "426/426 - 1s - loss: 0.3215 - accuracy: 0.9390 - precision: 0.9571 - recall: 0.8897 - val_loss: 0.6685 - val_accuracy: 0.7958 - val_precision: 0.8417 - val_recall: 0.7113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "426/426 - 1s - loss: 0.3044 - accuracy: 0.9343 - precision: 0.9542 - recall: 0.8803 - val_loss: 0.6990 - val_accuracy: 0.8028 - val_precision: 0.8468 - val_recall: 0.7394\n",
      "Epoch 173/200\n",
      "426/426 - 1s - loss: 0.3080 - accuracy: 0.9343 - precision: 0.9502 - recall: 0.8967 - val_loss: 0.6736 - val_accuracy: 0.8028 - val_precision: 0.8537 - val_recall: 0.7394\n",
      "Epoch 174/200\n",
      "426/426 - 1s - loss: 0.2899 - accuracy: 0.9413 - precision: 0.9631 - recall: 0.9178 - val_loss: 0.7215 - val_accuracy: 0.7535 - val_precision: 0.8130 - val_recall: 0.7042\n",
      "Epoch 175/200\n",
      "426/426 - 0s - loss: 0.2960 - accuracy: 0.9366 - precision: 0.9630 - recall: 0.9155 - val_loss: 0.6594 - val_accuracy: 0.8028 - val_precision: 0.8468 - val_recall: 0.7394\n",
      "Epoch 176/200\n",
      "426/426 - 0s - loss: 0.3509 - accuracy: 0.9061 - precision: 0.9263 - recall: 0.8850 - val_loss: 0.7043 - val_accuracy: 0.7958 - val_precision: 0.8211 - val_recall: 0.7113\n",
      "Epoch 177/200\n",
      "426/426 - 1s - loss: 0.2982 - accuracy: 0.9319 - precision: 0.9581 - recall: 0.9131 - val_loss: 0.7953 - val_accuracy: 0.7324 - val_precision: 0.7778 - val_recall: 0.6901\n",
      "Epoch 178/200\n",
      "426/426 - 1s - loss: 0.3132 - accuracy: 0.9272 - precision: 0.9479 - recall: 0.8967 - val_loss: 0.8006 - val_accuracy: 0.7113 - val_precision: 0.7559 - val_recall: 0.6761\n",
      "Epoch 179/200\n",
      "426/426 - 1s - loss: 0.3207 - accuracy: 0.9202 - precision: 0.9416 - recall: 0.9085 - val_loss: 0.6750 - val_accuracy: 0.8099 - val_precision: 0.8400 - val_recall: 0.7394\n",
      "Epoch 180/200\n",
      "426/426 - 1s - loss: 0.2760 - accuracy: 0.9484 - precision: 0.9611 - recall: 0.9272 - val_loss: 0.7857 - val_accuracy: 0.7746 - val_precision: 0.7937 - val_recall: 0.7042\n",
      "Epoch 181/200\n",
      "426/426 - 1s - loss: 0.3662 - accuracy: 0.8944 - precision: 0.9268 - recall: 0.8615 - val_loss: 0.7664 - val_accuracy: 0.7535 - val_precision: 0.8016 - val_recall: 0.7113\n",
      "Epoch 182/200\n",
      "426/426 - 1s - loss: 0.3952 - accuracy: 0.8920 - precision: 0.9093 - recall: 0.8709 - val_loss: 0.7749 - val_accuracy: 0.7394 - val_precision: 0.8130 - val_recall: 0.7042\n",
      "Epoch 183/200\n",
      "426/426 - 1s - loss: 0.2782 - accuracy: 0.9460 - precision: 0.9588 - recall: 0.9296 - val_loss: 0.6792 - val_accuracy: 0.7887 - val_precision: 0.8160 - val_recall: 0.7183\n",
      "Epoch 184/200\n",
      "426/426 - 1s - loss: 0.2725 - accuracy: 0.9413 - precision: 0.9588 - recall: 0.9296 - val_loss: 0.6800 - val_accuracy: 0.8099 - val_precision: 0.8320 - val_recall: 0.7324\n",
      "Epoch 185/200\n",
      "426/426 - 1s - loss: 0.2640 - accuracy: 0.9437 - precision: 0.9614 - recall: 0.9343 - val_loss: 0.6643 - val_accuracy: 0.7887 - val_precision: 0.8607 - val_recall: 0.7394\n",
      "Epoch 186/200\n",
      "426/426 - 1s - loss: 0.2517 - accuracy: 0.9531 - precision: 0.9641 - recall: 0.9460 - val_loss: 0.6565 - val_accuracy: 0.8239 - val_precision: 0.8537 - val_recall: 0.7394\n",
      "Epoch 187/200\n",
      "426/426 - 1s - loss: 0.2866 - accuracy: 0.9272 - precision: 0.9489 - recall: 0.9155 - val_loss: 0.6394 - val_accuracy: 0.8310 - val_precision: 0.8661 - val_recall: 0.7746\n",
      "Epoch 188/200\n",
      "426/426 - 0s - loss: 0.2522 - accuracy: 0.9531 - precision: 0.9710 - recall: 0.9437 - val_loss: 0.6684 - val_accuracy: 0.8239 - val_precision: 0.8387 - val_recall: 0.7324\n",
      "Epoch 189/200\n",
      "426/426 - 1s - loss: 0.2524 - accuracy: 0.9484 - precision: 0.9590 - recall: 0.9343 - val_loss: 0.6498 - val_accuracy: 0.8099 - val_precision: 0.8571 - val_recall: 0.7606\n",
      "Epoch 190/200\n",
      "426/426 - 0s - loss: 0.3163 - accuracy: 0.9108 - precision: 0.9389 - recall: 0.9014 - val_loss: 0.7406 - val_accuracy: 0.7958 - val_precision: 0.8088 - val_recall: 0.7746\n",
      "Epoch 191/200\n",
      "426/426 - 1s - loss: 0.3178 - accuracy: 0.9155 - precision: 0.9366 - recall: 0.9014 - val_loss: 0.6966 - val_accuracy: 0.7746 - val_precision: 0.8077 - val_recall: 0.7394\n",
      "Epoch 192/200\n",
      "426/426 - 1s - loss: 0.2763 - accuracy: 0.9366 - precision: 0.9538 - recall: 0.9202 - val_loss: 0.6639 - val_accuracy: 0.8099 - val_precision: 0.8321 - val_recall: 0.7676\n",
      "Epoch 193/200\n",
      "426/426 - 1s - loss: 0.2439 - accuracy: 0.9484 - precision: 0.9710 - recall: 0.9437 - val_loss: 0.7285 - val_accuracy: 0.7887 - val_precision: 0.8240 - val_recall: 0.7254\n",
      "Epoch 194/200\n",
      "426/426 - 1s - loss: 0.2584 - accuracy: 0.9460 - precision: 0.9565 - recall: 0.9296 - val_loss: 0.6690 - val_accuracy: 0.8099 - val_precision: 0.8400 - val_recall: 0.7394\n",
      "Epoch 195/200\n",
      "426/426 - 1s - loss: 0.2367 - accuracy: 0.9531 - precision: 0.9709 - recall: 0.9390 - val_loss: 0.6535 - val_accuracy: 0.8028 - val_precision: 0.8308 - val_recall: 0.7606\n",
      "Epoch 196/200\n",
      "426/426 - 1s - loss: 0.2404 - accuracy: 0.9507 - precision: 0.9639 - recall: 0.9413 - val_loss: 0.6589 - val_accuracy: 0.8099 - val_precision: 0.8504 - val_recall: 0.7606\n",
      "Epoch 197/200\n",
      "426/426 - 1s - loss: 0.2299 - accuracy: 0.9531 - precision: 0.9735 - recall: 0.9484 - val_loss: 0.6650 - val_accuracy: 0.7958 - val_precision: 0.8217 - val_recall: 0.7465\n",
      "Epoch 198/200\n",
      "426/426 - 1s - loss: 0.2271 - accuracy: 0.9577 - precision: 0.9688 - recall: 0.9484 - val_loss: 0.6466 - val_accuracy: 0.8169 - val_precision: 0.8438 - val_recall: 0.7606\n",
      "Epoch 199/200\n",
      "426/426 - 1s - loss: 0.2319 - accuracy: 0.9554 - precision: 0.9713 - recall: 0.9531 - val_loss: 0.6950 - val_accuracy: 0.7887 - val_precision: 0.8308 - val_recall: 0.7606\n",
      "Epoch 200/200\n",
      "426/426 - 1s - loss: 0.2230 - accuracy: 0.9648 - precision: 0.9760 - recall: 0.9554 - val_loss: 0.6498 - val_accuracy: 0.8169 - val_precision: 0.8321 - val_recall: 0.7676\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 256)          351232    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 128)          197120    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 128)          131584    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 64)           49408     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 763,148\n",
      "Trainable params: 763,148\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Adagrad\n",
      "\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/200\n",
      "426/426 - 10s - loss: 2.4183 - accuracy: 0.1268 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.2738 - val_accuracy: 0.2324 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      "426/426 - 1s - loss: 2.1649 - accuracy: 0.2042 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0136 - val_accuracy: 0.1831 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/200\n",
      "426/426 - 1s - loss: 2.0079 - accuracy: 0.2042 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9108 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/200\n",
      "426/426 - 1s - loss: 1.9230 - accuracy: 0.2277 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8779 - val_accuracy: 0.2324 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/200\n",
      "426/426 - 1s - loss: 1.8819 - accuracy: 0.2371 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8688 - val_accuracy: 0.2465 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/200\n",
      "426/426 - 1s - loss: 1.8609 - accuracy: 0.2817 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8296 - val_accuracy: 0.2606 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/200\n",
      "426/426 - 1s - loss: 1.8279 - accuracy: 0.2864 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8197 - val_accuracy: 0.2535 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/200\n",
      "426/426 - 1s - loss: 1.8029 - accuracy: 0.2934 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8244 - val_accuracy: 0.2394 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/200\n",
      "426/426 - 1s - loss: 1.7998 - accuracy: 0.2958 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7976 - val_accuracy: 0.2394 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200\n",
      "426/426 - 1s - loss: 1.7818 - accuracy: 0.3099 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7906 - val_accuracy: 0.2817 - val_precision: 1.0000 - val_recall: 0.0070\n",
      "Epoch 11/200\n",
      "426/426 - 1s - loss: 1.7705 - accuracy: 0.3052 - precision: 0.5000 - recall: 0.0047 - val_loss: 1.7937 - val_accuracy: 0.2324 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/200\n",
      "426/426 - 1s - loss: 1.7566 - accuracy: 0.3216 - precision: 1.0000 - recall: 0.0023 - val_loss: 1.7635 - val_accuracy: 0.2465 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/200\n",
      "426/426 - 0s - loss: 1.7364 - accuracy: 0.3310 - precision: 1.0000 - recall: 0.0023 - val_loss: 1.7078 - val_accuracy: 0.2958 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 14/200\n",
      "426/426 - 1s - loss: 1.7105 - accuracy: 0.3498 - precision: 0.9167 - recall: 0.0258 - val_loss: 1.6875 - val_accuracy: 0.2887 - val_precision: 1.0000 - val_recall: 0.0282\n",
      "Epoch 15/200\n",
      "426/426 - 1s - loss: 1.6808 - accuracy: 0.3615 - precision: 0.7857 - recall: 0.0258 - val_loss: 1.7049 - val_accuracy: 0.3099 - val_precision: 0.6364 - val_recall: 0.0493\n",
      "Epoch 16/200\n",
      "426/426 - 1s - loss: 1.6901 - accuracy: 0.3615 - precision: 0.8182 - recall: 0.0423 - val_loss: 2.6097 - val_accuracy: 0.1620 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/200\n",
      "426/426 - 1s - loss: 1.8454 - accuracy: 0.2981 - precision: 0.7333 - recall: 0.0258 - val_loss: 2.1835 - val_accuracy: 0.2676 - val_precision: 0.5556 - val_recall: 0.0352\n",
      "Epoch 18/200\n",
      "426/426 - 1s - loss: 1.7099 - accuracy: 0.3380 - precision: 0.6667 - recall: 0.0329 - val_loss: 1.7306 - val_accuracy: 0.3028 - val_precision: 1.0000 - val_recall: 0.0282\n",
      "Epoch 19/200\n",
      "426/426 - 1s - loss: 1.6322 - accuracy: 0.3944 - precision: 0.8182 - recall: 0.0423 - val_loss: 1.6087 - val_accuracy: 0.3944 - val_precision: 0.6000 - val_recall: 0.0423\n",
      "Epoch 20/200\n",
      "426/426 - 1s - loss: 1.6079 - accuracy: 0.3944 - precision: 0.6957 - recall: 0.0376 - val_loss: 1.8117 - val_accuracy: 0.3169 - val_precision: 0.5714 - val_recall: 0.0563\n",
      "Epoch 21/200\n",
      "426/426 - 1s - loss: 1.6270 - accuracy: 0.3873 - precision: 0.6000 - recall: 0.0493 - val_loss: 1.5843 - val_accuracy: 0.4507 - val_precision: 0.7143 - val_recall: 0.0704\n",
      "Epoch 22/200\n",
      "426/426 - 1s - loss: 1.5807 - accuracy: 0.4249 - precision: 0.6757 - recall: 0.0587 - val_loss: 1.6772 - val_accuracy: 0.3592 - val_precision: 0.6667 - val_recall: 0.0845\n",
      "Epoch 23/200\n",
      "426/426 - 1s - loss: 1.5714 - accuracy: 0.3897 - precision: 0.6949 - recall: 0.0962 - val_loss: 1.7154 - val_accuracy: 0.2887 - val_precision: 0.4167 - val_recall: 0.0352\n",
      "Epoch 24/200\n",
      "426/426 - 1s - loss: 1.5502 - accuracy: 0.4366 - precision: 0.7500 - recall: 0.0634 - val_loss: 1.6422 - val_accuracy: 0.4155 - val_precision: 0.6667 - val_recall: 0.1127\n",
      "Epoch 25/200\n",
      "426/426 - 1s - loss: 1.5394 - accuracy: 0.4249 - precision: 0.6406 - recall: 0.0962 - val_loss: 1.5420 - val_accuracy: 0.3873 - val_precision: 0.4583 - val_recall: 0.0775\n",
      "Epoch 26/200\n",
      "426/426 - 1s - loss: 1.5181 - accuracy: 0.4390 - precision: 0.6949 - recall: 0.0962 - val_loss: 1.5945 - val_accuracy: 0.3873 - val_precision: 0.7857 - val_recall: 0.0775\n",
      "Epoch 27/200\n",
      "426/426 - 1s - loss: 1.5213 - accuracy: 0.4296 - precision: 0.6066 - recall: 0.0869 - val_loss: 1.5019 - val_accuracy: 0.4085 - val_precision: 0.7333 - val_recall: 0.0775\n",
      "Epoch 28/200\n",
      "426/426 - 1s - loss: 1.4821 - accuracy: 0.4624 - precision: 0.7407 - recall: 0.0939 - val_loss: 1.4740 - val_accuracy: 0.4366 - val_precision: 0.7308 - val_recall: 0.1338\n",
      "Epoch 29/200\n",
      "426/426 - 1s - loss: 1.5035 - accuracy: 0.4296 - precision: 0.7432 - recall: 0.1291 - val_loss: 1.5158 - val_accuracy: 0.4507 - val_precision: 0.6000 - val_recall: 0.1479\n",
      "Epoch 30/200\n",
      "426/426 - 1s - loss: 1.4825 - accuracy: 0.4484 - precision: 0.7375 - recall: 0.1385 - val_loss: 1.5246 - val_accuracy: 0.4366 - val_precision: 0.7097 - val_recall: 0.1549\n",
      "Epoch 31/200\n",
      "426/426 - 1s - loss: 1.4438 - accuracy: 0.4601 - precision: 0.7609 - recall: 0.1643 - val_loss: 1.4408 - val_accuracy: 0.4718 - val_precision: 0.6957 - val_recall: 0.2254\n",
      "Epoch 32/200\n",
      "426/426 - 1s - loss: 1.4529 - accuracy: 0.4319 - precision: 0.7333 - recall: 0.1808 - val_loss: 1.4780 - val_accuracy: 0.4296 - val_precision: 0.8929 - val_recall: 0.1761\n",
      "Epoch 33/200\n",
      "426/426 - 1s - loss: 1.4274 - accuracy: 0.4507 - precision: 0.8022 - recall: 0.1714 - val_loss: 1.4403 - val_accuracy: 0.4366 - val_precision: 0.8000 - val_recall: 0.1972\n",
      "Epoch 34/200\n",
      "426/426 - 1s - loss: 1.4543 - accuracy: 0.4648 - precision: 0.6916 - recall: 0.1737 - val_loss: 1.4091 - val_accuracy: 0.4648 - val_precision: 0.7561 - val_recall: 0.2183\n",
      "Epoch 35/200\n",
      "426/426 - 1s - loss: 1.4245 - accuracy: 0.4507 - precision: 0.7685 - recall: 0.1948 - val_loss: 1.4594 - val_accuracy: 0.3873 - val_precision: 0.6944 - val_recall: 0.1761\n",
      "Epoch 36/200\n",
      "426/426 - 1s - loss: 1.4273 - accuracy: 0.4601 - precision: 0.7328 - recall: 0.1995 - val_loss: 1.5779 - val_accuracy: 0.3732 - val_precision: 0.5366 - val_recall: 0.1549\n",
      "Epoch 37/200\n",
      "426/426 - 1s - loss: 1.4074 - accuracy: 0.4531 - precision: 0.7500 - recall: 0.2042 - val_loss: 1.4653 - val_accuracy: 0.4085 - val_precision: 0.7429 - val_recall: 0.1831\n",
      "Epoch 38/200\n",
      "426/426 - 1s - loss: 1.4028 - accuracy: 0.4601 - precision: 0.7154 - recall: 0.2066 - val_loss: 1.4074 - val_accuracy: 0.4577 - val_precision: 0.7955 - val_recall: 0.2465\n",
      "Epoch 39/200\n",
      "426/426 - 1s - loss: 1.3769 - accuracy: 0.4859 - precision: 0.7460 - recall: 0.2207 - val_loss: 1.4439 - val_accuracy: 0.4085 - val_precision: 0.8108 - val_recall: 0.2113\n",
      "Epoch 40/200\n",
      "426/426 - 1s - loss: 1.3983 - accuracy: 0.4742 - precision: 0.7638 - recall: 0.2277 - val_loss: 1.4085 - val_accuracy: 0.4014 - val_precision: 0.7297 - val_recall: 0.1901\n",
      "Epoch 41/200\n",
      "426/426 - 1s - loss: 1.3843 - accuracy: 0.4531 - precision: 0.7500 - recall: 0.2183 - val_loss: 1.3642 - val_accuracy: 0.4577 - val_precision: 0.8158 - val_recall: 0.2183\n",
      "Epoch 42/200\n",
      "426/426 - 1s - loss: 1.3579 - accuracy: 0.5047 - precision: 0.7576 - recall: 0.2347 - val_loss: 1.5239 - val_accuracy: 0.3803 - val_precision: 0.6923 - val_recall: 0.1901\n",
      "Epoch 43/200\n",
      "426/426 - 1s - loss: 1.3766 - accuracy: 0.4836 - precision: 0.7541 - recall: 0.2160 - val_loss: 1.3714 - val_accuracy: 0.4789 - val_precision: 0.7500 - val_recall: 0.2958\n",
      "Epoch 44/200\n",
      "426/426 - 1s - loss: 1.3564 - accuracy: 0.4718 - precision: 0.7466 - recall: 0.2559 - val_loss: 1.3919 - val_accuracy: 0.4577 - val_precision: 0.7083 - val_recall: 0.2394\n",
      "Epoch 45/200\n",
      "426/426 - 1s - loss: 1.3325 - accuracy: 0.5047 - precision: 0.7786 - recall: 0.2394 - val_loss: 1.3753 - val_accuracy: 0.4366 - val_precision: 0.7143 - val_recall: 0.2465\n",
      "Epoch 46/200\n",
      "426/426 - 1s - loss: 1.3549 - accuracy: 0.4953 - precision: 0.7868 - recall: 0.2512 - val_loss: 1.4752 - val_accuracy: 0.4085 - val_precision: 0.7000 - val_recall: 0.2465\n",
      "Epoch 47/200\n",
      "426/426 - 1s - loss: 1.3577 - accuracy: 0.4695 - precision: 0.7606 - recall: 0.2535 - val_loss: 1.3600 - val_accuracy: 0.4507 - val_precision: 0.7200 - val_recall: 0.2535\n",
      "Epoch 48/200\n",
      "426/426 - 1s - loss: 1.3335 - accuracy: 0.5094 - precision: 0.7292 - recall: 0.2465 - val_loss: 1.3688 - val_accuracy: 0.4648 - val_precision: 0.7917 - val_recall: 0.2676\n",
      "Epoch 49/200\n",
      "426/426 - 1s - loss: 1.3217 - accuracy: 0.4953 - precision: 0.7692 - recall: 0.2582 - val_loss: 1.4344 - val_accuracy: 0.4225 - val_precision: 0.6078 - val_recall: 0.2183\n",
      "Epoch 50/200\n",
      "426/426 - 1s - loss: 1.3419 - accuracy: 0.5000 - precision: 0.7755 - recall: 0.2676 - val_loss: 1.4443 - val_accuracy: 0.4225 - val_precision: 0.7321 - val_recall: 0.2887\n",
      "Epoch 51/200\n",
      "426/426 - 1s - loss: 1.3180 - accuracy: 0.5141 - precision: 0.7584 - recall: 0.2653 - val_loss: 1.4318 - val_accuracy: 0.4155 - val_precision: 0.6800 - val_recall: 0.2394\n",
      "Epoch 52/200\n",
      "426/426 - 1s - loss: 1.3256 - accuracy: 0.4906 - precision: 0.7533 - recall: 0.2653 - val_loss: 1.3983 - val_accuracy: 0.4225 - val_precision: 0.7818 - val_recall: 0.3028\n",
      "Epoch 53/200\n",
      "426/426 - 1s - loss: 1.2941 - accuracy: 0.5070 - precision: 0.8041 - recall: 0.2793 - val_loss: 1.3179 - val_accuracy: 0.4577 - val_precision: 0.6981 - val_recall: 0.2606\n",
      "Epoch 54/200\n",
      "426/426 - 1s - loss: 1.2904 - accuracy: 0.5164 - precision: 0.7799 - recall: 0.2911 - val_loss: 1.3540 - val_accuracy: 0.4648 - val_precision: 0.6923 - val_recall: 0.2535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "426/426 - 1s - loss: 1.2676 - accuracy: 0.5329 - precision: 0.7750 - recall: 0.2911 - val_loss: 1.3370 - val_accuracy: 0.4789 - val_precision: 0.7455 - val_recall: 0.2887\n",
      "Epoch 56/200\n",
      "426/426 - 1s - loss: 1.2400 - accuracy: 0.5305 - precision: 0.8194 - recall: 0.2981 - val_loss: 1.3905 - val_accuracy: 0.4577 - val_precision: 0.7018 - val_recall: 0.2817\n",
      "Epoch 57/200\n",
      "426/426 - 1s - loss: 1.2512 - accuracy: 0.5376 - precision: 0.7952 - recall: 0.3099 - val_loss: 1.5042 - val_accuracy: 0.4437 - val_precision: 0.7541 - val_recall: 0.3239\n",
      "Epoch 58/200\n",
      "426/426 - 1s - loss: 1.2851 - accuracy: 0.5399 - precision: 0.7516 - recall: 0.2840 - val_loss: 1.3026 - val_accuracy: 0.5000 - val_precision: 0.7692 - val_recall: 0.2817\n",
      "Epoch 59/200\n",
      "426/426 - 1s - loss: 1.2769 - accuracy: 0.5376 - precision: 0.7799 - recall: 0.2911 - val_loss: 1.3578 - val_accuracy: 0.4437 - val_precision: 0.7018 - val_recall: 0.2817\n",
      "Epoch 60/200\n",
      "426/426 - 1s - loss: 1.2350 - accuracy: 0.5258 - precision: 0.8049 - recall: 0.3099 - val_loss: 1.3744 - val_accuracy: 0.4507 - val_precision: 0.7778 - val_recall: 0.2958\n",
      "Epoch 61/200\n",
      "426/426 - 1s - loss: 1.2548 - accuracy: 0.5399 - precision: 0.7719 - recall: 0.3099 - val_loss: 1.3206 - val_accuracy: 0.4648 - val_precision: 0.6852 - val_recall: 0.2606\n",
      "Epoch 62/200\n",
      "426/426 - 1s - loss: 1.2429 - accuracy: 0.5352 - precision: 0.7904 - recall: 0.3099 - val_loss: 1.3042 - val_accuracy: 0.4930 - val_precision: 0.7222 - val_recall: 0.2746\n",
      "Epoch 63/200\n",
      "426/426 - 1s - loss: 1.2253 - accuracy: 0.5469 - precision: 0.8263 - recall: 0.3239 - val_loss: 1.3357 - val_accuracy: 0.4930 - val_precision: 0.6897 - val_recall: 0.2817\n",
      "Epoch 64/200\n",
      "426/426 - 1s - loss: 1.2450 - accuracy: 0.5399 - precision: 0.7544 - recall: 0.3028 - val_loss: 1.2959 - val_accuracy: 0.5000 - val_precision: 0.7333 - val_recall: 0.3099\n",
      "Epoch 65/200\n",
      "426/426 - 1s - loss: 1.2234 - accuracy: 0.5329 - precision: 0.7844 - recall: 0.3075 - val_loss: 1.3655 - val_accuracy: 0.4648 - val_precision: 0.7447 - val_recall: 0.2465\n",
      "Epoch 66/200\n",
      "426/426 - 1s - loss: 1.2575 - accuracy: 0.5305 - precision: 0.7730 - recall: 0.2958 - val_loss: 1.3380 - val_accuracy: 0.4366 - val_precision: 0.6731 - val_recall: 0.2465\n",
      "Epoch 67/200\n",
      "426/426 - 1s - loss: 1.2231 - accuracy: 0.5446 - precision: 0.7861 - recall: 0.3451 - val_loss: 1.3345 - val_accuracy: 0.4577 - val_precision: 0.7037 - val_recall: 0.2676\n",
      "Epoch 68/200\n",
      "426/426 - 1s - loss: 1.1988 - accuracy: 0.5516 - precision: 0.8118 - recall: 0.3545 - val_loss: 1.3139 - val_accuracy: 0.4930 - val_precision: 0.7241 - val_recall: 0.2958\n",
      "Epoch 69/200\n",
      "426/426 - 1s - loss: 1.2093 - accuracy: 0.5493 - precision: 0.8021 - recall: 0.3521 - val_loss: 1.2749 - val_accuracy: 0.5211 - val_precision: 0.7581 - val_recall: 0.3310\n",
      "Epoch 70/200\n",
      "426/426 - 1s - loss: 1.2097 - accuracy: 0.5423 - precision: 0.7944 - recall: 0.3357 - val_loss: 1.3084 - val_accuracy: 0.4718 - val_precision: 0.6949 - val_recall: 0.2887\n",
      "Epoch 71/200\n",
      "426/426 - 1s - loss: 1.1836 - accuracy: 0.5563 - precision: 0.8122 - recall: 0.3451 - val_loss: 1.2364 - val_accuracy: 0.5141 - val_precision: 0.7544 - val_recall: 0.3028\n",
      "Epoch 72/200\n",
      "426/426 - 1s - loss: 1.1998 - accuracy: 0.5446 - precision: 0.7760 - recall: 0.3333 - val_loss: 1.3055 - val_accuracy: 0.4718 - val_precision: 0.7188 - val_recall: 0.3239\n",
      "Epoch 73/200\n",
      "426/426 - 1s - loss: 1.1566 - accuracy: 0.5728 - precision: 0.8389 - recall: 0.3545 - val_loss: 1.3021 - val_accuracy: 0.4930 - val_precision: 0.7818 - val_recall: 0.3028\n",
      "Epoch 74/200\n",
      "426/426 - 1s - loss: 1.1609 - accuracy: 0.5587 - precision: 0.8192 - recall: 0.3404 - val_loss: 1.2996 - val_accuracy: 0.4859 - val_precision: 0.7742 - val_recall: 0.3380\n",
      "Epoch 75/200\n",
      "426/426 - 1s - loss: 1.1877 - accuracy: 0.5657 - precision: 0.7821 - recall: 0.3286 - val_loss: 1.3276 - val_accuracy: 0.4930 - val_precision: 0.6613 - val_recall: 0.2887\n",
      "Epoch 76/200\n",
      "426/426 - 1s - loss: 1.1538 - accuracy: 0.5681 - precision: 0.8268 - recall: 0.3474 - val_loss: 1.2563 - val_accuracy: 0.5070 - val_precision: 0.8136 - val_recall: 0.3380\n",
      "Epoch 77/200\n",
      "426/426 - 1s - loss: 1.1536 - accuracy: 0.5962 - precision: 0.8171 - recall: 0.3357 - val_loss: 1.2373 - val_accuracy: 0.5282 - val_precision: 0.7895 - val_recall: 0.3169\n",
      "Epoch 78/200\n",
      "426/426 - 1s - loss: 1.1206 - accuracy: 0.5939 - precision: 0.8432 - recall: 0.3662 - val_loss: 1.2908 - val_accuracy: 0.5211 - val_precision: 0.6935 - val_recall: 0.3028\n",
      "Epoch 79/200\n",
      "426/426 - 1s - loss: 1.1184 - accuracy: 0.5986 - precision: 0.8525 - recall: 0.3662 - val_loss: 1.2200 - val_accuracy: 0.5704 - val_precision: 0.8333 - val_recall: 0.3521\n",
      "Epoch 80/200\n",
      "426/426 - 1s - loss: 1.1033 - accuracy: 0.5939 - precision: 0.8611 - recall: 0.3638 - val_loss: 1.5189 - val_accuracy: 0.4366 - val_precision: 0.6324 - val_recall: 0.3028\n",
      "Epoch 81/200\n",
      "426/426 - 1s - loss: 1.1885 - accuracy: 0.5657 - precision: 0.7872 - recall: 0.3474 - val_loss: 1.2220 - val_accuracy: 0.5423 - val_precision: 0.7903 - val_recall: 0.3451\n",
      "Epoch 82/200\n",
      "426/426 - 1s - loss: 1.1447 - accuracy: 0.5845 - precision: 0.8042 - recall: 0.3568 - val_loss: 1.3734 - val_accuracy: 0.4507 - val_precision: 0.7206 - val_recall: 0.3451\n",
      "Epoch 83/200\n",
      "426/426 - 1s - loss: 1.0882 - accuracy: 0.6127 - precision: 0.8413 - recall: 0.3732 - val_loss: 1.1873 - val_accuracy: 0.5211 - val_precision: 0.8226 - val_recall: 0.3592\n",
      "Epoch 84/200\n",
      "426/426 - 1s - loss: 1.0892 - accuracy: 0.5892 - precision: 0.8274 - recall: 0.3826 - val_loss: 1.2217 - val_accuracy: 0.5352 - val_precision: 0.8065 - val_recall: 0.3521\n",
      "Epoch 85/200\n",
      "426/426 - 1s - loss: 1.0849 - accuracy: 0.6455 - precision: 0.8534 - recall: 0.3826 - val_loss: 1.4119 - val_accuracy: 0.4507 - val_precision: 0.7125 - val_recall: 0.4014\n",
      "Epoch 86/200\n",
      "426/426 - 1s - loss: 1.0716 - accuracy: 0.6455 - precision: 0.8381 - recall: 0.4131 - val_loss: 1.2217 - val_accuracy: 0.5211 - val_precision: 0.7778 - val_recall: 0.3451\n",
      "Epoch 87/200\n",
      "426/426 - 1s - loss: 1.0338 - accuracy: 0.6596 - precision: 0.8770 - recall: 0.3850 - val_loss: 1.2438 - val_accuracy: 0.5211 - val_precision: 0.7188 - val_recall: 0.3239\n",
      "Epoch 88/200\n",
      "426/426 - 1s - loss: 1.1159 - accuracy: 0.6197 - precision: 0.8135 - recall: 0.3685 - val_loss: 1.3017 - val_accuracy: 0.5211 - val_precision: 0.7031 - val_recall: 0.3169\n",
      "Epoch 89/200\n",
      "426/426 - 1s - loss: 1.0742 - accuracy: 0.6479 - precision: 0.8241 - recall: 0.3850 - val_loss: 1.2048 - val_accuracy: 0.5423 - val_precision: 0.7761 - val_recall: 0.3662\n",
      "Epoch 90/200\n",
      "426/426 - 1s - loss: 1.1253 - accuracy: 0.6362 - precision: 0.7822 - recall: 0.3709 - val_loss: 1.1594 - val_accuracy: 0.5352 - val_precision: 0.8000 - val_recall: 0.3662\n",
      "Epoch 91/200\n",
      "426/426 - 1s - loss: 1.0289 - accuracy: 0.6502 - precision: 0.8442 - recall: 0.3944 - val_loss: 1.3540 - val_accuracy: 0.4648 - val_precision: 0.5873 - val_recall: 0.2606\n",
      "Epoch 92/200\n",
      "426/426 - 1s - loss: 1.0174 - accuracy: 0.6854 - precision: 0.8372 - recall: 0.4225 - val_loss: 1.1720 - val_accuracy: 0.5634 - val_precision: 0.8333 - val_recall: 0.3873\n",
      "Epoch 93/200\n",
      "426/426 - 1s - loss: 0.9573 - accuracy: 0.7066 - precision: 0.8967 - recall: 0.4484 - val_loss: 1.2550 - val_accuracy: 0.5000 - val_precision: 0.7286 - val_recall: 0.3592\n",
      "Epoch 94/200\n",
      "426/426 - 1s - loss: 1.0361 - accuracy: 0.6174 - precision: 0.8009 - recall: 0.4061 - val_loss: 1.2230 - val_accuracy: 0.4718 - val_precision: 0.7538 - val_recall: 0.3451\n",
      "Epoch 95/200\n",
      "426/426 - 1s - loss: 1.0507 - accuracy: 0.6244 - precision: 0.8402 - recall: 0.3826 - val_loss: 1.1275 - val_accuracy: 0.5775 - val_precision: 0.7917 - val_recall: 0.4014\n",
      "Epoch 96/200\n",
      "426/426 - 1s - loss: 0.9581 - accuracy: 0.6925 - precision: 0.8784 - recall: 0.4577 - val_loss: 1.1231 - val_accuracy: 0.5704 - val_precision: 0.7903 - val_recall: 0.3451\n",
      "Epoch 97/200\n",
      "426/426 - 1s - loss: 0.9430 - accuracy: 0.6972 - precision: 0.8920 - recall: 0.4460 - val_loss: 1.0885 - val_accuracy: 0.5845 - val_precision: 0.7973 - val_recall: 0.4155\n",
      "Epoch 98/200\n",
      "426/426 - 1s - loss: 0.9399 - accuracy: 0.6901 - precision: 0.8761 - recall: 0.4648 - val_loss: 1.1343 - val_accuracy: 0.5845 - val_precision: 0.7973 - val_recall: 0.4155\n",
      "Epoch 99/200\n",
      "426/426 - 1s - loss: 0.9098 - accuracy: 0.7160 - precision: 0.8719 - recall: 0.4953 - val_loss: 1.1232 - val_accuracy: 0.5493 - val_precision: 0.8082 - val_recall: 0.4155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "426/426 - 1s - loss: 0.9658 - accuracy: 0.6667 - precision: 0.8624 - recall: 0.4413 - val_loss: 1.1342 - val_accuracy: 0.5704 - val_precision: 0.7536 - val_recall: 0.3662\n",
      "Epoch 101/200\n",
      "426/426 - 1s - loss: 0.9081 - accuracy: 0.7089 - precision: 0.8734 - recall: 0.4859 - val_loss: 1.0968 - val_accuracy: 0.6197 - val_precision: 0.8082 - val_recall: 0.4155\n",
      "Epoch 102/200\n",
      "426/426 - 1s - loss: 0.8992 - accuracy: 0.7183 - precision: 0.9027 - recall: 0.4789 - val_loss: 1.2074 - val_accuracy: 0.5352 - val_precision: 0.7460 - val_recall: 0.3310\n",
      "Epoch 103/200\n",
      "426/426 - 1s - loss: 0.8848 - accuracy: 0.7300 - precision: 0.8866 - recall: 0.4953 - val_loss: 1.0714 - val_accuracy: 0.5845 - val_precision: 0.7838 - val_recall: 0.4085\n",
      "Epoch 104/200\n",
      "426/426 - 1s - loss: 0.8869 - accuracy: 0.7019 - precision: 0.8816 - recall: 0.5070 - val_loss: 1.1851 - val_accuracy: 0.5563 - val_precision: 0.7703 - val_recall: 0.4014\n",
      "Epoch 105/200\n",
      "426/426 - 1s - loss: 0.8574 - accuracy: 0.7277 - precision: 0.8902 - recall: 0.5141 - val_loss: 1.1037 - val_accuracy: 0.5634 - val_precision: 0.8182 - val_recall: 0.3803\n",
      "Epoch 106/200\n",
      "426/426 - 1s - loss: 0.9062 - accuracy: 0.6901 - precision: 0.8689 - recall: 0.4977 - val_loss: 1.1396 - val_accuracy: 0.5634 - val_precision: 0.7619 - val_recall: 0.4507\n",
      "Epoch 107/200\n",
      "426/426 - 1s - loss: 0.8673 - accuracy: 0.7089 - precision: 0.8898 - recall: 0.5117 - val_loss: 1.0953 - val_accuracy: 0.5775 - val_precision: 0.7711 - val_recall: 0.4507\n",
      "Epoch 108/200\n",
      "426/426 - 1s - loss: 0.8271 - accuracy: 0.7324 - precision: 0.8968 - recall: 0.5305 - val_loss: 1.3772 - val_accuracy: 0.4930 - val_precision: 0.7746 - val_recall: 0.3873\n",
      "Epoch 109/200\n",
      "426/426 - 1s - loss: 1.0196 - accuracy: 0.6502 - precision: 0.8894 - recall: 0.4718 - val_loss: 1.2080 - val_accuracy: 0.5634 - val_precision: 0.7097 - val_recall: 0.4648\n",
      "Epoch 110/200\n",
      "426/426 - 1s - loss: 0.8381 - accuracy: 0.7300 - precision: 0.8808 - recall: 0.5376 - val_loss: 1.0897 - val_accuracy: 0.5986 - val_precision: 0.8194 - val_recall: 0.4155\n",
      "Epoch 111/200\n",
      "426/426 - 1s - loss: 0.8118 - accuracy: 0.7465 - precision: 0.9141 - recall: 0.5493 - val_loss: 1.1778 - val_accuracy: 0.5070 - val_precision: 0.7922 - val_recall: 0.4296\n",
      "Epoch 112/200\n",
      "426/426 - 1s - loss: 0.9414 - accuracy: 0.6620 - precision: 0.8678 - recall: 0.4930 - val_loss: 1.0830 - val_accuracy: 0.6127 - val_precision: 0.7949 - val_recall: 0.4366\n",
      "Epoch 113/200\n",
      "426/426 - 1s - loss: 0.7872 - accuracy: 0.7512 - precision: 0.9255 - recall: 0.5540 - val_loss: 1.0559 - val_accuracy: 0.5986 - val_precision: 0.7882 - val_recall: 0.4718\n",
      "Epoch 114/200\n",
      "426/426 - 1s - loss: 0.7937 - accuracy: 0.7535 - precision: 0.9112 - recall: 0.5540 - val_loss: 1.2471 - val_accuracy: 0.5423 - val_precision: 0.6386 - val_recall: 0.3732\n",
      "Epoch 115/200\n",
      "426/426 - 1s - loss: 0.8299 - accuracy: 0.7418 - precision: 0.8614 - recall: 0.5399 - val_loss: 1.0032 - val_accuracy: 0.6479 - val_precision: 0.8250 - val_recall: 0.4648\n",
      "Epoch 116/200\n",
      "426/426 - 1s - loss: 0.7584 - accuracy: 0.7606 - precision: 0.9094 - recall: 0.5892 - val_loss: 0.9666 - val_accuracy: 0.6549 - val_precision: 0.8312 - val_recall: 0.4507\n",
      "Epoch 117/200\n",
      "426/426 - 1s - loss: 0.7996 - accuracy: 0.7418 - precision: 0.8732 - recall: 0.5657 - val_loss: 1.0854 - val_accuracy: 0.6127 - val_precision: 0.7273 - val_recall: 0.4507\n",
      "Epoch 118/200\n",
      "426/426 - 1s - loss: 0.7897 - accuracy: 0.7324 - precision: 0.8759 - recall: 0.5634 - val_loss: 1.0179 - val_accuracy: 0.6127 - val_precision: 0.8333 - val_recall: 0.4577\n",
      "Epoch 119/200\n",
      "426/426 - 1s - loss: 0.7747 - accuracy: 0.7465 - precision: 0.8974 - recall: 0.5751 - val_loss: 1.0267 - val_accuracy: 0.6338 - val_precision: 0.8169 - val_recall: 0.4085\n",
      "Epoch 120/200\n",
      "426/426 - 1s - loss: 0.7759 - accuracy: 0.7441 - precision: 0.8782 - recall: 0.5587 - val_loss: 1.2660 - val_accuracy: 0.5493 - val_precision: 0.7209 - val_recall: 0.4366\n",
      "Epoch 121/200\n",
      "426/426 - 1s - loss: 0.7535 - accuracy: 0.7488 - precision: 0.8822 - recall: 0.6150 - val_loss: 1.0600 - val_accuracy: 0.6268 - val_precision: 0.8082 - val_recall: 0.4155\n",
      "Epoch 122/200\n",
      "426/426 - 1s - loss: 0.9173 - accuracy: 0.6808 - precision: 0.8898 - recall: 0.5117 - val_loss: 1.0402 - val_accuracy: 0.6268 - val_precision: 0.8026 - val_recall: 0.4296\n",
      "Epoch 123/200\n",
      "426/426 - 1s - loss: 0.7214 - accuracy: 0.7723 - precision: 0.9173 - recall: 0.5986 - val_loss: 1.2087 - val_accuracy: 0.6056 - val_precision: 0.6974 - val_recall: 0.3732\n",
      "Epoch 124/200\n",
      "426/426 - 1s - loss: 0.7144 - accuracy: 0.7840 - precision: 0.9146 - recall: 0.6033 - val_loss: 0.9656 - val_accuracy: 0.6197 - val_precision: 0.7841 - val_recall: 0.4859\n",
      "Epoch 125/200\n",
      "426/426 - 1s - loss: 0.7528 - accuracy: 0.7559 - precision: 0.9003 - recall: 0.6150 - val_loss: 1.1801 - val_accuracy: 0.5282 - val_precision: 0.6966 - val_recall: 0.4366\n",
      "Epoch 126/200\n",
      "426/426 - 1s - loss: 0.8115 - accuracy: 0.7160 - precision: 0.8804 - recall: 0.5704 - val_loss: 1.0754 - val_accuracy: 0.5704 - val_precision: 0.7419 - val_recall: 0.4859\n",
      "Epoch 127/200\n",
      "426/426 - 1s - loss: 0.7171 - accuracy: 0.7934 - precision: 0.9158 - recall: 0.6127 - val_loss: 0.9343 - val_accuracy: 0.6901 - val_precision: 0.8293 - val_recall: 0.4789\n",
      "Epoch 128/200\n",
      "426/426 - 1s - loss: 0.6575 - accuracy: 0.7981 - precision: 0.9175 - recall: 0.6268 - val_loss: 1.2816 - val_accuracy: 0.5000 - val_precision: 0.6429 - val_recall: 0.3803\n",
      "Epoch 129/200\n",
      "426/426 - 1s - loss: 0.7695 - accuracy: 0.7582 - precision: 0.8936 - recall: 0.5915 - val_loss: 0.9282 - val_accuracy: 0.7254 - val_precision: 0.8750 - val_recall: 0.4437\n",
      "Epoch 130/200\n",
      "426/426 - 1s - loss: 0.6620 - accuracy: 0.8005 - precision: 0.9317 - recall: 0.6408 - val_loss: 0.9828 - val_accuracy: 0.6549 - val_precision: 0.7449 - val_recall: 0.5141\n",
      "Epoch 131/200\n",
      "426/426 - 1s - loss: 0.6520 - accuracy: 0.8075 - precision: 0.9073 - recall: 0.6432 - val_loss: 0.8800 - val_accuracy: 0.7465 - val_precision: 0.8471 - val_recall: 0.5070\n",
      "Epoch 132/200\n",
      "426/426 - 1s - loss: 0.6532 - accuracy: 0.8052 - precision: 0.9295 - recall: 0.6502 - val_loss: 0.9028 - val_accuracy: 0.7183 - val_precision: 0.8202 - val_recall: 0.5141\n",
      "Epoch 133/200\n",
      "426/426 - 1s - loss: 0.6105 - accuracy: 0.8474 - precision: 0.9474 - recall: 0.6761 - val_loss: 0.9222 - val_accuracy: 0.6831 - val_precision: 0.7895 - val_recall: 0.5282\n",
      "Epoch 134/200\n",
      "426/426 - 1s - loss: 0.6289 - accuracy: 0.8263 - precision: 0.9279 - recall: 0.6643 - val_loss: 0.9202 - val_accuracy: 0.7042 - val_precision: 0.8276 - val_recall: 0.5070\n",
      "Epoch 135/200\n",
      "426/426 - 1s - loss: 0.5970 - accuracy: 0.8521 - precision: 0.9385 - recall: 0.6808 - val_loss: 0.8973 - val_accuracy: 0.7324 - val_precision: 0.8315 - val_recall: 0.5211\n",
      "Epoch 136/200\n",
      "426/426 - 1s - loss: 0.6264 - accuracy: 0.8380 - precision: 0.9243 - recall: 0.6878 - val_loss: 0.9843 - val_accuracy: 0.5915 - val_precision: 0.7396 - val_recall: 0.5000\n",
      "Epoch 137/200\n",
      "426/426 - 1s - loss: 0.6144 - accuracy: 0.8146 - precision: 0.9359 - recall: 0.6854 - val_loss: 0.8963 - val_accuracy: 0.7324 - val_precision: 0.8090 - val_recall: 0.5070\n",
      "Epoch 138/200\n",
      "426/426 - 1s - loss: 0.6462 - accuracy: 0.8005 - precision: 0.8931 - recall: 0.6667 - val_loss: 1.1767 - val_accuracy: 0.5423 - val_precision: 0.6842 - val_recall: 0.4577\n",
      "Epoch 139/200\n",
      "426/426 - 1s - loss: 0.6304 - accuracy: 0.8216 - precision: 0.9082 - recall: 0.6737 - val_loss: 0.9542 - val_accuracy: 0.6761 - val_precision: 0.7957 - val_recall: 0.5211\n",
      "Epoch 140/200\n",
      "426/426 - 1s - loss: 0.6180 - accuracy: 0.8310 - precision: 0.9102 - recall: 0.6901 - val_loss: 0.8754 - val_accuracy: 0.7254 - val_precision: 0.8444 - val_recall: 0.5352\n",
      "Epoch 141/200\n",
      "426/426 - 1s - loss: 0.6634 - accuracy: 0.7864 - precision: 0.9006 - recall: 0.6596 - val_loss: 0.8890 - val_accuracy: 0.7113 - val_precision: 0.8144 - val_recall: 0.5563\n",
      "Epoch 142/200\n",
      "426/426 - 1s - loss: 0.5839 - accuracy: 0.8451 - precision: 0.9157 - recall: 0.7136 - val_loss: 1.1266 - val_accuracy: 0.5704 - val_precision: 0.7347 - val_recall: 0.5070\n",
      "Epoch 143/200\n",
      "426/426 - 1s - loss: 0.6131 - accuracy: 0.8192 - precision: 0.9110 - recall: 0.6972 - val_loss: 0.8586 - val_accuracy: 0.7113 - val_precision: 0.8020 - val_recall: 0.5704\n",
      "Epoch 144/200\n",
      "426/426 - 1s - loss: 0.5470 - accuracy: 0.8638 - precision: 0.9292 - recall: 0.7394 - val_loss: 0.8617 - val_accuracy: 0.7324 - val_precision: 0.8058 - val_recall: 0.5845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "426/426 - 1s - loss: 0.5533 - accuracy: 0.8498 - precision: 0.9155 - recall: 0.7371 - val_loss: 0.8512 - val_accuracy: 0.7042 - val_precision: 0.8020 - val_recall: 0.5704\n",
      "Epoch 146/200\n",
      "426/426 - 1s - loss: 0.5312 - accuracy: 0.8709 - precision: 0.9304 - recall: 0.7535 - val_loss: 0.8384 - val_accuracy: 0.7254 - val_precision: 0.8252 - val_recall: 0.5986\n",
      "Epoch 147/200\n",
      "426/426 - 1s - loss: 0.5501 - accuracy: 0.8732 - precision: 0.9253 - recall: 0.7559 - val_loss: 0.9465 - val_accuracy: 0.6831 - val_precision: 0.8261 - val_recall: 0.5352\n",
      "Epoch 148/200\n",
      "426/426 - 1s - loss: 0.5831 - accuracy: 0.8451 - precision: 0.9189 - recall: 0.7183 - val_loss: 1.2159 - val_accuracy: 0.5986 - val_precision: 0.6500 - val_recall: 0.4577\n",
      "Epoch 149/200\n",
      "426/426 - 1s - loss: 0.6690 - accuracy: 0.8310 - precision: 0.8575 - recall: 0.7207 - val_loss: 0.9021 - val_accuracy: 0.7394 - val_precision: 0.7523 - val_recall: 0.5775\n",
      "Epoch 150/200\n",
      "426/426 - 1s - loss: 0.5599 - accuracy: 0.8521 - precision: 0.9080 - recall: 0.7418 - val_loss: 1.0256 - val_accuracy: 0.6408 - val_precision: 0.7596 - val_recall: 0.5563\n",
      "Epoch 151/200\n",
      "426/426 - 1s - loss: 0.5704 - accuracy: 0.8333 - precision: 0.9008 - recall: 0.7465 - val_loss: 0.8603 - val_accuracy: 0.7042 - val_precision: 0.8020 - val_recall: 0.5704\n",
      "Epoch 152/200\n",
      "426/426 - 1s - loss: 0.5305 - accuracy: 0.8662 - precision: 0.9040 - recall: 0.7512 - val_loss: 0.8284 - val_accuracy: 0.7606 - val_precision: 0.8198 - val_recall: 0.6408\n",
      "Epoch 153/200\n",
      "426/426 - 1s - loss: 0.5401 - accuracy: 0.8545 - precision: 0.9155 - recall: 0.7629 - val_loss: 0.9029 - val_accuracy: 0.6620 - val_precision: 0.7685 - val_recall: 0.5845\n",
      "Epoch 154/200\n",
      "426/426 - 1s - loss: 0.4966 - accuracy: 0.8756 - precision: 0.9382 - recall: 0.7840 - val_loss: 0.8909 - val_accuracy: 0.6901 - val_precision: 0.7521 - val_recall: 0.6197\n",
      "Epoch 155/200\n",
      "426/426 - 1s - loss: 0.5203 - accuracy: 0.8545 - precision: 0.9028 - recall: 0.7629 - val_loss: 0.9739 - val_accuracy: 0.6901 - val_precision: 0.7477 - val_recall: 0.5634\n",
      "Epoch 156/200\n",
      "426/426 - 1s - loss: 0.5101 - accuracy: 0.8732 - precision: 0.9053 - recall: 0.7629 - val_loss: 0.8378 - val_accuracy: 0.7394 - val_precision: 0.8018 - val_recall: 0.6268\n",
      "Epoch 157/200\n",
      "426/426 - 1s - loss: 0.5061 - accuracy: 0.8709 - precision: 0.9286 - recall: 0.7629 - val_loss: 1.0354 - val_accuracy: 0.6268 - val_precision: 0.7455 - val_recall: 0.5775\n",
      "Epoch 158/200\n",
      "426/426 - 1s - loss: 0.5774 - accuracy: 0.8427 - precision: 0.9034 - recall: 0.7465 - val_loss: 0.8370 - val_accuracy: 0.7465 - val_precision: 0.8036 - val_recall: 0.6338\n",
      "Epoch 159/200\n",
      "426/426 - 1s - loss: 0.4806 - accuracy: 0.8803 - precision: 0.9111 - recall: 0.7934 - val_loss: 1.1819 - val_accuracy: 0.5704 - val_precision: 0.6667 - val_recall: 0.4930\n",
      "Epoch 160/200\n",
      "426/426 - 1s - loss: 0.5226 - accuracy: 0.8474 - precision: 0.9061 - recall: 0.7700 - val_loss: 1.1669 - val_accuracy: 0.5563 - val_precision: 0.6435 - val_recall: 0.5211\n",
      "Epoch 161/200\n",
      "426/426 - 1s - loss: 0.5155 - accuracy: 0.8474 - precision: 0.9116 - recall: 0.7746 - val_loss: 0.8605 - val_accuracy: 0.7394 - val_precision: 0.7982 - val_recall: 0.6408\n",
      "Epoch 162/200\n",
      "426/426 - 1s - loss: 0.4853 - accuracy: 0.8873 - precision: 0.9178 - recall: 0.7864 - val_loss: 0.8214 - val_accuracy: 0.7324 - val_precision: 0.8108 - val_recall: 0.6338\n",
      "Epoch 163/200\n",
      "426/426 - 1s - loss: 0.4522 - accuracy: 0.8826 - precision: 0.9342 - recall: 0.8005 - val_loss: 0.8768 - val_accuracy: 0.7254 - val_precision: 0.7739 - val_recall: 0.6268\n",
      "Epoch 164/200\n",
      "426/426 - 1s - loss: 0.4974 - accuracy: 0.8545 - precision: 0.9088 - recall: 0.7958 - val_loss: 0.8663 - val_accuracy: 0.6831 - val_precision: 0.7712 - val_recall: 0.6408\n",
      "Epoch 165/200\n",
      "426/426 - 1s - loss: 0.5115 - accuracy: 0.8380 - precision: 0.9076 - recall: 0.7840 - val_loss: 0.8542 - val_accuracy: 0.7254 - val_precision: 0.7667 - val_recall: 0.6479\n",
      "Epoch 166/200\n",
      "426/426 - 1s - loss: 0.4778 - accuracy: 0.8779 - precision: 0.9264 - recall: 0.7981 - val_loss: 0.8639 - val_accuracy: 0.7113 - val_precision: 0.7731 - val_recall: 0.6479\n",
      "Epoch 167/200\n",
      "426/426 - 1s - loss: 0.4644 - accuracy: 0.8920 - precision: 0.9342 - recall: 0.8005 - val_loss: 0.9184 - val_accuracy: 0.7113 - val_precision: 0.7436 - val_recall: 0.6127\n",
      "Epoch 168/200\n",
      "426/426 - 1s - loss: 0.5453 - accuracy: 0.8380 - precision: 0.9061 - recall: 0.7700 - val_loss: 1.1157 - val_accuracy: 0.6479 - val_precision: 0.7043 - val_recall: 0.5704\n",
      "Epoch 169/200\n",
      "426/426 - 1s - loss: 0.4880 - accuracy: 0.8709 - precision: 0.9069 - recall: 0.8005 - val_loss: 0.8164 - val_accuracy: 0.7183 - val_precision: 0.7583 - val_recall: 0.6408\n",
      "Epoch 170/200\n",
      "426/426 - 1s - loss: 0.4231 - accuracy: 0.8967 - precision: 0.9418 - recall: 0.8357 - val_loss: 0.8379 - val_accuracy: 0.7183 - val_precision: 0.8070 - val_recall: 0.6479\n",
      "Epoch 171/200\n",
      "426/426 - 1s - loss: 0.4864 - accuracy: 0.8638 - precision: 0.9210 - recall: 0.7934 - val_loss: 0.9089 - val_accuracy: 0.6972 - val_precision: 0.7647 - val_recall: 0.6408\n",
      "Epoch 172/200\n",
      "426/426 - 1s - loss: 0.4233 - accuracy: 0.9038 - precision: 0.9396 - recall: 0.8404 - val_loss: 0.8173 - val_accuracy: 0.7113 - val_precision: 0.7913 - val_recall: 0.6408\n",
      "Epoch 173/200\n",
      "426/426 - 1s - loss: 0.4205 - accuracy: 0.8991 - precision: 0.9396 - recall: 0.8404 - val_loss: 0.9431 - val_accuracy: 0.6831 - val_precision: 0.7561 - val_recall: 0.6549\n",
      "Epoch 174/200\n",
      "426/426 - 1s - loss: 0.4040 - accuracy: 0.9038 - precision: 0.9342 - recall: 0.8662 - val_loss: 0.9031 - val_accuracy: 0.6901 - val_precision: 0.7360 - val_recall: 0.6479\n",
      "Epoch 175/200\n",
      "426/426 - 1s - loss: 0.4560 - accuracy: 0.8803 - precision: 0.9162 - recall: 0.8474 - val_loss: 1.0948 - val_accuracy: 0.5915 - val_precision: 0.6667 - val_recall: 0.5775\n",
      "Epoch 176/200\n",
      "426/426 - 1s - loss: 0.4638 - accuracy: 0.8662 - precision: 0.9039 - recall: 0.8169 - val_loss: 0.8408 - val_accuracy: 0.7254 - val_precision: 0.7983 - val_recall: 0.6690\n",
      "Epoch 177/200\n",
      "426/426 - 1s - loss: 0.4619 - accuracy: 0.8592 - precision: 0.9062 - recall: 0.8169 - val_loss: 0.8432 - val_accuracy: 0.7042 - val_precision: 0.7913 - val_recall: 0.6408\n",
      "Epoch 178/200\n",
      "426/426 - 1s - loss: 0.3994 - accuracy: 0.9061 - precision: 0.9440 - recall: 0.8709 - val_loss: 0.8461 - val_accuracy: 0.7324 - val_precision: 0.7934 - val_recall: 0.6761\n",
      "Epoch 179/200\n",
      "426/426 - 1s - loss: 0.3854 - accuracy: 0.9131 - precision: 0.9442 - recall: 0.8732 - val_loss: 0.8929 - val_accuracy: 0.7183 - val_precision: 0.7833 - val_recall: 0.6620\n",
      "Epoch 180/200\n",
      "426/426 - 1s - loss: 0.3745 - accuracy: 0.9108 - precision: 0.9468 - recall: 0.8779 - val_loss: 0.8104 - val_accuracy: 0.7465 - val_precision: 0.8000 - val_recall: 0.6761\n",
      "Epoch 181/200\n",
      "426/426 - 1s - loss: 0.3647 - accuracy: 0.9272 - precision: 0.9521 - recall: 0.8873 - val_loss: 0.8165 - val_accuracy: 0.7254 - val_precision: 0.7795 - val_recall: 0.6972\n",
      "Epoch 182/200\n",
      "426/426 - 1s - loss: 0.4059 - accuracy: 0.8967 - precision: 0.9333 - recall: 0.8545 - val_loss: 0.9673 - val_accuracy: 0.6831 - val_precision: 0.7541 - val_recall: 0.6479\n",
      "Epoch 183/200\n",
      "426/426 - 1s - loss: 0.4304 - accuracy: 0.8920 - precision: 0.9196 - recall: 0.8592 - val_loss: 1.3334 - val_accuracy: 0.5423 - val_precision: 0.5794 - val_recall: 0.5141\n",
      "Epoch 184/200\n",
      "426/426 - 1s - loss: 0.5058 - accuracy: 0.8615 - precision: 0.9026 - recall: 0.8263 - val_loss: 0.9060 - val_accuracy: 0.6761 - val_precision: 0.7561 - val_recall: 0.6549\n",
      "Epoch 185/200\n",
      "426/426 - 1s - loss: 0.3886 - accuracy: 0.8991 - precision: 0.9275 - recall: 0.8709 - val_loss: 0.8228 - val_accuracy: 0.7465 - val_precision: 0.7886 - val_recall: 0.6831\n",
      "Epoch 186/200\n",
      "426/426 - 1s - loss: 0.3971 - accuracy: 0.8944 - precision: 0.9309 - recall: 0.8545 - val_loss: 1.1154 - val_accuracy: 0.6338 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 187/200\n",
      "426/426 - 1s - loss: 0.5127 - accuracy: 0.8310 - precision: 0.8930 - recall: 0.7840 - val_loss: 0.8211 - val_accuracy: 0.7324 - val_precision: 0.7698 - val_recall: 0.6831\n",
      "Epoch 188/200\n",
      "426/426 - 1s - loss: 0.3738 - accuracy: 0.9202 - precision: 0.9428 - recall: 0.8897 - val_loss: 0.8015 - val_accuracy: 0.7394 - val_precision: 0.7886 - val_recall: 0.6831\n",
      "Epoch 189/200\n",
      "426/426 - 1s - loss: 0.3778 - accuracy: 0.9085 - precision: 0.9450 - recall: 0.8873 - val_loss: 0.7894 - val_accuracy: 0.7465 - val_precision: 0.7886 - val_recall: 0.6831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/200\n",
      "426/426 - 1s - loss: 0.3620 - accuracy: 0.9155 - precision: 0.9451 - recall: 0.8897 - val_loss: 0.9229 - val_accuracy: 0.6972 - val_precision: 0.7712 - val_recall: 0.6408\n",
      "Epoch 191/200\n",
      "426/426 - 1s - loss: 0.4059 - accuracy: 0.8944 - precision: 0.9198 - recall: 0.8615 - val_loss: 0.8141 - val_accuracy: 0.7676 - val_precision: 0.8151 - val_recall: 0.6831\n",
      "Epoch 192/200\n",
      "426/426 - 1s - loss: 0.3663 - accuracy: 0.9131 - precision: 0.9378 - recall: 0.8850 - val_loss: 0.9212 - val_accuracy: 0.6690 - val_precision: 0.7373 - val_recall: 0.6127\n",
      "Epoch 193/200\n",
      "426/426 - 1s - loss: 0.4616 - accuracy: 0.8592 - precision: 0.9098 - recall: 0.8286 - val_loss: 0.7788 - val_accuracy: 0.7606 - val_precision: 0.8145 - val_recall: 0.7113\n",
      "Epoch 194/200\n",
      "426/426 - 1s - loss: 0.3413 - accuracy: 0.9272 - precision: 0.9553 - recall: 0.9038 - val_loss: 0.7834 - val_accuracy: 0.7676 - val_precision: 0.8065 - val_recall: 0.7042\n",
      "Epoch 195/200\n",
      "426/426 - 1s - loss: 0.3572 - accuracy: 0.9272 - precision: 0.9529 - recall: 0.9014 - val_loss: 1.1101 - val_accuracy: 0.6268 - val_precision: 0.6560 - val_recall: 0.5775\n",
      "Epoch 196/200\n",
      "426/426 - 1s - loss: 0.5001 - accuracy: 0.8498 - precision: 0.8886 - recall: 0.8239 - val_loss: 1.0585 - val_accuracy: 0.6197 - val_precision: 0.6721 - val_recall: 0.5775\n",
      "Epoch 197/200\n",
      "426/426 - 1s - loss: 0.4171 - accuracy: 0.8803 - precision: 0.9201 - recall: 0.8380 - val_loss: 0.8084 - val_accuracy: 0.7254 - val_precision: 0.7903 - val_recall: 0.6901\n",
      "Epoch 198/200\n",
      "426/426 - 1s - loss: 0.3445 - accuracy: 0.9202 - precision: 0.9439 - recall: 0.9085 - val_loss: 0.8117 - val_accuracy: 0.7183 - val_precision: 0.7857 - val_recall: 0.6972\n",
      "Epoch 199/200\n",
      "426/426 - 1s - loss: 0.3425 - accuracy: 0.9202 - precision: 0.9483 - recall: 0.9038 - val_loss: 0.7994 - val_accuracy: 0.7394 - val_precision: 0.7891 - val_recall: 0.7113\n",
      "Epoch 200/200\n",
      "426/426 - 1s - loss: 0.3724 - accuracy: 0.8991 - precision: 0.9298 - recall: 0.8709 - val_loss: 0.8568 - val_accuracy: 0.7254 - val_precision: 0.7833 - val_recall: 0.6620\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 256)          351232    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 128)          197120    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 128)          131584    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 64)           49408     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 763,148\n",
      "Trainable params: 763,148\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Adagrad\n",
      "\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/200\n",
      "426/426 - 10s - loss: 2.3694 - accuracy: 0.1408 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.2108 - val_accuracy: 0.1831 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      "426/426 - 1s - loss: 2.0455 - accuracy: 0.2277 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9792 - val_accuracy: 0.2113 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/200\n",
      "426/426 - 1s - loss: 1.9434 - accuracy: 0.2324 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9085 - val_accuracy: 0.2042 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/200\n",
      "426/426 - 1s - loss: 1.9068 - accuracy: 0.2700 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8785 - val_accuracy: 0.2042 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/200\n",
      "426/426 - 1s - loss: 1.8732 - accuracy: 0.2582 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3488 - val_accuracy: 0.1972 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/200\n",
      "426/426 - 1s - loss: 1.8989 - accuracy: 0.2723 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8491 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/200\n",
      "426/426 - 1s - loss: 1.8230 - accuracy: 0.2676 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8549 - val_accuracy: 0.2465 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/200\n",
      "426/426 - 1s - loss: 1.7963 - accuracy: 0.2653 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8301 - val_accuracy: 0.2394 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/200\n",
      "426/426 - 1s - loss: 1.7915 - accuracy: 0.2629 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7824 - val_accuracy: 0.2465 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/200\n",
      "426/426 - 1s - loss: 1.7635 - accuracy: 0.2911 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7921 - val_accuracy: 0.2606 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/200\n",
      "426/426 - 1s - loss: 1.7382 - accuracy: 0.3169 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7692 - val_accuracy: 0.3099 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/200\n",
      "426/426 - 1s - loss: 1.7532 - accuracy: 0.2840 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8099 - val_accuracy: 0.2817 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/200\n",
      "426/426 - 1s - loss: 1.7019 - accuracy: 0.3286 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7650 - val_accuracy: 0.2465 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/200\n",
      "426/426 - 1s - loss: 1.6975 - accuracy: 0.3286 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.6792 - val_accuracy: 0.3380 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/200\n",
      "426/426 - 1s - loss: 1.6976 - accuracy: 0.3451 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.7209 - val_accuracy: 0.2746 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/200\n",
      "426/426 - 1s - loss: 1.6851 - accuracy: 0.3286 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8177 - val_accuracy: 0.2606 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/200\n",
      "426/426 - 1s - loss: 1.6712 - accuracy: 0.3333 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.6881 - val_accuracy: 0.3169 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/200\n",
      "426/426 - 1s - loss: 1.6561 - accuracy: 0.3357 - precision: 0.8889 - recall: 0.0188 - val_loss: 1.6551 - val_accuracy: 0.3310 - val_precision: 1.0000 - val_recall: 0.0070\n",
      "Epoch 19/200\n",
      "426/426 - 1s - loss: 1.6083 - accuracy: 0.3873 - precision: 0.9091 - recall: 0.0235 - val_loss: 1.7707 - val_accuracy: 0.3310 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 20/200\n",
      "426/426 - 1s - loss: 1.6320 - accuracy: 0.3638 - precision: 0.9091 - recall: 0.0235 - val_loss: 1.6542 - val_accuracy: 0.3099 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 21/200\n",
      "426/426 - 1s - loss: 1.5864 - accuracy: 0.3897 - precision: 0.9091 - recall: 0.0235 - val_loss: 1.6133 - val_accuracy: 0.3310 - val_precision: 1.0000 - val_recall: 0.0070\n",
      "Epoch 22/200\n",
      "426/426 - 1s - loss: 1.5765 - accuracy: 0.3967 - precision: 0.7273 - recall: 0.0376 - val_loss: 1.6353 - val_accuracy: 0.3451 - val_precision: 0.7500 - val_recall: 0.0845\n",
      "Epoch 23/200\n",
      "426/426 - 1s - loss: 1.5734 - accuracy: 0.3944 - precision: 0.6923 - recall: 0.0634 - val_loss: 1.5673 - val_accuracy: 0.4014 - val_precision: 0.8000 - val_recall: 0.0845\n",
      "Epoch 24/200\n",
      "426/426 - 1s - loss: 1.5411 - accuracy: 0.4108 - precision: 0.6905 - recall: 0.0681 - val_loss: 1.6349 - val_accuracy: 0.3662 - val_precision: 0.7857 - val_recall: 0.0775\n",
      "Epoch 25/200\n",
      "426/426 - 1s - loss: 1.5194 - accuracy: 0.4061 - precision: 0.7619 - recall: 0.0751 - val_loss: 1.5138 - val_accuracy: 0.4155 - val_precision: 0.7895 - val_recall: 0.1056\n",
      "Epoch 26/200\n",
      "426/426 - 1s - loss: 1.5049 - accuracy: 0.4296 - precision: 0.8571 - recall: 0.0986 - val_loss: 1.6100 - val_accuracy: 0.3380 - val_precision: 0.5357 - val_recall: 0.1056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200\n",
      "426/426 - 1s - loss: 1.5304 - accuracy: 0.3967 - precision: 0.6607 - recall: 0.0869 - val_loss: 1.5433 - val_accuracy: 0.4085 - val_precision: 0.7812 - val_recall: 0.1761\n",
      "Epoch 28/200\n",
      "426/426 - 1s - loss: 1.4969 - accuracy: 0.4413 - precision: 0.6742 - recall: 0.1408 - val_loss: 1.4800 - val_accuracy: 0.4366 - val_precision: 0.8929 - val_recall: 0.1761\n",
      "Epoch 29/200\n",
      "426/426 - 1s - loss: 1.5035 - accuracy: 0.4249 - precision: 0.6703 - recall: 0.1432 - val_loss: 1.4895 - val_accuracy: 0.4155 - val_precision: 0.8636 - val_recall: 0.1338\n",
      "Epoch 30/200\n",
      "426/426 - 1s - loss: 1.4685 - accuracy: 0.4366 - precision: 0.6867 - recall: 0.1338 - val_loss: 1.5094 - val_accuracy: 0.4225 - val_precision: 0.7059 - val_recall: 0.1690\n",
      "Epoch 31/200\n",
      "426/426 - 1s - loss: 1.4977 - accuracy: 0.4296 - precision: 0.6415 - recall: 0.1596 - val_loss: 1.5256 - val_accuracy: 0.3944 - val_precision: 0.8462 - val_recall: 0.1549\n",
      "Epoch 32/200\n",
      "426/426 - 1s - loss: 1.4556 - accuracy: 0.4390 - precision: 0.7030 - recall: 0.1667 - val_loss: 1.4528 - val_accuracy: 0.4366 - val_precision: 0.7931 - val_recall: 0.1620\n",
      "Epoch 33/200\n",
      "426/426 - 1s - loss: 1.4382 - accuracy: 0.4343 - precision: 0.6460 - recall: 0.1714 - val_loss: 1.4565 - val_accuracy: 0.3944 - val_precision: 0.8929 - val_recall: 0.1761\n",
      "Epoch 34/200\n",
      "426/426 - 1s - loss: 1.4447 - accuracy: 0.4319 - precision: 0.6900 - recall: 0.1620 - val_loss: 1.4155 - val_accuracy: 0.4366 - val_precision: 0.8182 - val_recall: 0.1901\n",
      "Epoch 35/200\n",
      "426/426 - 1s - loss: 1.4338 - accuracy: 0.4695 - precision: 0.7113 - recall: 0.1620 - val_loss: 1.5908 - val_accuracy: 0.3521 - val_precision: 0.7692 - val_recall: 0.1408\n",
      "Epoch 36/200\n",
      "426/426 - 1s - loss: 1.4942 - accuracy: 0.4319 - precision: 0.6809 - recall: 0.1502 - val_loss: 1.4908 - val_accuracy: 0.3873 - val_precision: 0.7895 - val_recall: 0.2113\n",
      "Epoch 37/200\n",
      "426/426 - 1s - loss: 1.4077 - accuracy: 0.4718 - precision: 0.7080 - recall: 0.1878 - val_loss: 1.4294 - val_accuracy: 0.4366 - val_precision: 0.8000 - val_recall: 0.1972\n",
      "Epoch 38/200\n",
      "426/426 - 1s - loss: 1.3852 - accuracy: 0.4742 - precision: 0.7054 - recall: 0.1854 - val_loss: 1.3913 - val_accuracy: 0.4366 - val_precision: 0.7250 - val_recall: 0.2042\n",
      "Epoch 39/200\n",
      "426/426 - 1s - loss: 1.4342 - accuracy: 0.4531 - precision: 0.6460 - recall: 0.1714 - val_loss: 1.5436 - val_accuracy: 0.3732 - val_precision: 0.8148 - val_recall: 0.1549\n",
      "Epoch 40/200\n",
      "426/426 - 1s - loss: 1.3925 - accuracy: 0.4648 - precision: 0.6923 - recall: 0.1690 - val_loss: 1.4365 - val_accuracy: 0.4014 - val_precision: 0.8235 - val_recall: 0.1972\n",
      "Epoch 41/200\n",
      "426/426 - 1s - loss: 1.3812 - accuracy: 0.4718 - precision: 0.6942 - recall: 0.1972 - val_loss: 1.4571 - val_accuracy: 0.4155 - val_precision: 0.7949 - val_recall: 0.2183\n",
      "Epoch 42/200\n",
      "426/426 - 1s - loss: 1.3526 - accuracy: 0.4883 - precision: 0.7143 - recall: 0.2113 - val_loss: 1.3796 - val_accuracy: 0.4648 - val_precision: 0.7561 - val_recall: 0.2183\n",
      "Epoch 43/200\n",
      "426/426 - 1s - loss: 1.3549 - accuracy: 0.4836 - precision: 0.7419 - recall: 0.2160 - val_loss: 1.4043 - val_accuracy: 0.3732 - val_precision: 0.7073 - val_recall: 0.2042\n",
      "Epoch 44/200\n",
      "426/426 - 1s - loss: 1.3438 - accuracy: 0.4695 - precision: 0.7521 - recall: 0.2136 - val_loss: 1.4037 - val_accuracy: 0.3873 - val_precision: 0.7273 - val_recall: 0.2254\n",
      "Epoch 45/200\n",
      "426/426 - 1s - loss: 1.3828 - accuracy: 0.4484 - precision: 0.7213 - recall: 0.2066 - val_loss: 1.4297 - val_accuracy: 0.4366 - val_precision: 0.8000 - val_recall: 0.1972\n",
      "Epoch 46/200\n",
      "426/426 - 1s - loss: 1.3207 - accuracy: 0.5305 - precision: 0.7724 - recall: 0.2230 - val_loss: 1.4296 - val_accuracy: 0.3380 - val_precision: 0.6200 - val_recall: 0.2183\n",
      "Epoch 47/200\n",
      "426/426 - 1s - loss: 1.3319 - accuracy: 0.5117 - precision: 0.7197 - recall: 0.2230 - val_loss: 1.3524 - val_accuracy: 0.4859 - val_precision: 0.7805 - val_recall: 0.2254\n",
      "Epoch 48/200\n",
      "426/426 - 1s - loss: 1.3143 - accuracy: 0.5305 - precision: 0.7353 - recall: 0.2347 - val_loss: 1.4359 - val_accuracy: 0.4085 - val_precision: 0.6818 - val_recall: 0.2113\n",
      "Epoch 49/200\n",
      "426/426 - 1s - loss: 1.3049 - accuracy: 0.5211 - precision: 0.7143 - recall: 0.2347 - val_loss: 1.4205 - val_accuracy: 0.3873 - val_precision: 0.7931 - val_recall: 0.1620\n",
      "Epoch 50/200\n",
      "426/426 - 1s - loss: 1.2988 - accuracy: 0.5211 - precision: 0.7402 - recall: 0.2207 - val_loss: 1.5825 - val_accuracy: 0.3732 - val_precision: 0.7632 - val_recall: 0.2042\n",
      "Epoch 51/200\n",
      "426/426 - 1s - loss: 1.2899 - accuracy: 0.5305 - precision: 0.7795 - recall: 0.2324 - val_loss: 1.2958 - val_accuracy: 0.4789 - val_precision: 0.7674 - val_recall: 0.2324\n",
      "Epoch 52/200\n",
      "426/426 - 1s - loss: 1.2649 - accuracy: 0.5493 - precision: 0.7778 - recall: 0.2465 - val_loss: 1.5857 - val_accuracy: 0.3592 - val_precision: 0.6750 - val_recall: 0.1901\n",
      "Epoch 53/200\n",
      "426/426 - 1s - loss: 1.2985 - accuracy: 0.4859 - precision: 0.7299 - recall: 0.2347 - val_loss: 1.3530 - val_accuracy: 0.4789 - val_precision: 0.7556 - val_recall: 0.2394\n",
      "Epoch 54/200\n",
      "426/426 - 1s - loss: 1.2664 - accuracy: 0.5399 - precision: 0.7761 - recall: 0.2441 - val_loss: 1.3299 - val_accuracy: 0.4648 - val_precision: 0.6863 - val_recall: 0.2465\n",
      "Epoch 55/200\n",
      "426/426 - 1s - loss: 1.2760 - accuracy: 0.5282 - precision: 0.7606 - recall: 0.2535 - val_loss: 1.3207 - val_accuracy: 0.4507 - val_precision: 0.6923 - val_recall: 0.2535\n",
      "Epoch 56/200\n",
      "426/426 - 1s - loss: 1.2600 - accuracy: 0.5540 - precision: 0.7568 - recall: 0.2629 - val_loss: 1.2656 - val_accuracy: 0.4648 - val_precision: 0.7347 - val_recall: 0.2535\n",
      "Epoch 57/200\n",
      "426/426 - 1s - loss: 1.2594 - accuracy: 0.5563 - precision: 0.7584 - recall: 0.2653 - val_loss: 1.3381 - val_accuracy: 0.4648 - val_precision: 0.8085 - val_recall: 0.2676\n",
      "Epoch 58/200\n",
      "426/426 - 1s - loss: 1.2406 - accuracy: 0.5634 - precision: 0.7895 - recall: 0.2817 - val_loss: 1.2643 - val_accuracy: 0.5141 - val_precision: 0.7660 - val_recall: 0.2535\n",
      "Epoch 59/200\n",
      "426/426 - 1s - loss: 1.2723 - accuracy: 0.5376 - precision: 0.7762 - recall: 0.2606 - val_loss: 1.3199 - val_accuracy: 0.4577 - val_precision: 0.8000 - val_recall: 0.2535\n",
      "Epoch 60/200\n",
      "426/426 - 1s - loss: 1.2221 - accuracy: 0.5446 - precision: 0.7628 - recall: 0.2793 - val_loss: 1.3911 - val_accuracy: 0.4789 - val_precision: 0.6885 - val_recall: 0.2958\n",
      "Epoch 61/200\n",
      "426/426 - 1s - loss: 1.2183 - accuracy: 0.5399 - precision: 0.7707 - recall: 0.2840 - val_loss: 1.2590 - val_accuracy: 0.4859 - val_precision: 0.8367 - val_recall: 0.2887\n",
      "Epoch 62/200\n",
      "426/426 - 1s - loss: 1.2021 - accuracy: 0.5869 - precision: 0.8049 - recall: 0.3099 - val_loss: 1.4308 - val_accuracy: 0.4225 - val_precision: 0.6735 - val_recall: 0.2324\n",
      "Epoch 63/200\n",
      "426/426 - 1s - loss: 1.1792 - accuracy: 0.5892 - precision: 0.8171 - recall: 0.3146 - val_loss: 1.3992 - val_accuracy: 0.4296 - val_precision: 0.6897 - val_recall: 0.2817\n",
      "Epoch 64/200\n",
      "426/426 - 1s - loss: 1.1783 - accuracy: 0.5962 - precision: 0.7939 - recall: 0.3075 - val_loss: 1.2495 - val_accuracy: 0.4930 - val_precision: 0.8039 - val_recall: 0.2887\n",
      "Epoch 65/200\n",
      "426/426 - 1s - loss: 1.1811 - accuracy: 0.5728 - precision: 0.8125 - recall: 0.3052 - val_loss: 1.2726 - val_accuracy: 0.5070 - val_precision: 0.8214 - val_recall: 0.3239\n",
      "Epoch 66/200\n",
      "426/426 - 1s - loss: 1.1747 - accuracy: 0.5892 - precision: 0.8129 - recall: 0.3263 - val_loss: 1.3025 - val_accuracy: 0.4859 - val_precision: 0.8148 - val_recall: 0.3099\n",
      "Epoch 67/200\n",
      "426/426 - 1s - loss: 1.1533 - accuracy: 0.5822 - precision: 0.8024 - recall: 0.3146 - val_loss: 1.2987 - val_accuracy: 0.4930 - val_precision: 0.7097 - val_recall: 0.3099\n",
      "Epoch 68/200\n",
      "426/426 - 1s - loss: 1.1526 - accuracy: 0.5915 - precision: 0.7989 - recall: 0.3357 - val_loss: 1.2388 - val_accuracy: 0.4859 - val_precision: 0.7833 - val_recall: 0.3310\n",
      "Epoch 69/200\n",
      "426/426 - 1s - loss: 1.1491 - accuracy: 0.5892 - precision: 0.8023 - recall: 0.3239 - val_loss: 1.4174 - val_accuracy: 0.4648 - val_precision: 0.7419 - val_recall: 0.3239\n",
      "Epoch 70/200\n",
      "426/426 - 1s - loss: 1.1390 - accuracy: 0.5775 - precision: 0.8161 - recall: 0.3333 - val_loss: 1.2557 - val_accuracy: 0.5070 - val_precision: 0.8197 - val_recall: 0.3521\n",
      "Epoch 71/200\n",
      "426/426 - 1s - loss: 1.1018 - accuracy: 0.6174 - precision: 0.8287 - recall: 0.3521 - val_loss: 1.3705 - val_accuracy: 0.4648 - val_precision: 0.7015 - val_recall: 0.3310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/200\n",
      "426/426 - 1s - loss: 1.1347 - accuracy: 0.5962 - precision: 0.8103 - recall: 0.3709 - val_loss: 1.3441 - val_accuracy: 0.5000 - val_precision: 0.7167 - val_recall: 0.3028\n",
      "Epoch 73/200\n",
      "426/426 - 1s - loss: 1.1520 - accuracy: 0.5939 - precision: 0.7937 - recall: 0.3521 - val_loss: 1.2096 - val_accuracy: 0.4648 - val_precision: 0.7460 - val_recall: 0.3310\n",
      "Epoch 74/200\n",
      "426/426 - 1s - loss: 1.0981 - accuracy: 0.6080 - precision: 0.8191 - recall: 0.3615 - val_loss: 1.1101 - val_accuracy: 0.5634 - val_precision: 0.8261 - val_recall: 0.4014\n",
      "Epoch 75/200\n",
      "426/426 - 1s - loss: 1.0743 - accuracy: 0.6127 - precision: 0.8213 - recall: 0.3991 - val_loss: 1.2939 - val_accuracy: 0.4648 - val_precision: 0.7333 - val_recall: 0.3873\n",
      "Epoch 76/200\n",
      "426/426 - 1s - loss: 1.0732 - accuracy: 0.6080 - precision: 0.8450 - recall: 0.3967 - val_loss: 1.2650 - val_accuracy: 0.4789 - val_precision: 0.7500 - val_recall: 0.3592\n",
      "Epoch 77/200\n",
      "426/426 - 1s - loss: 1.0805 - accuracy: 0.5986 - precision: 0.8095 - recall: 0.3991 - val_loss: 1.2547 - val_accuracy: 0.4507 - val_precision: 0.6885 - val_recall: 0.2958\n",
      "Epoch 78/200\n",
      "426/426 - 1s - loss: 1.0576 - accuracy: 0.6315 - precision: 0.8168 - recall: 0.3873 - val_loss: 1.1827 - val_accuracy: 0.5211 - val_precision: 0.7465 - val_recall: 0.3732\n",
      "Epoch 79/200\n",
      "426/426 - 1s - loss: 1.0438 - accuracy: 0.6244 - precision: 0.8483 - recall: 0.4202 - val_loss: 1.2884 - val_accuracy: 0.4789 - val_precision: 0.6765 - val_recall: 0.3239\n",
      "Epoch 80/200\n",
      "426/426 - 1s - loss: 1.0700 - accuracy: 0.6291 - precision: 0.8480 - recall: 0.4061 - val_loss: 1.2544 - val_accuracy: 0.5211 - val_precision: 0.6901 - val_recall: 0.3451\n",
      "Epoch 81/200\n",
      "426/426 - 1s - loss: 1.0493 - accuracy: 0.6103 - precision: 0.8244 - recall: 0.3967 - val_loss: 1.1002 - val_accuracy: 0.5423 - val_precision: 0.8000 - val_recall: 0.3944\n",
      "Epoch 82/200\n",
      "426/426 - 1s - loss: 1.0731 - accuracy: 0.6150 - precision: 0.8066 - recall: 0.4014 - val_loss: 1.0818 - val_accuracy: 0.5775 - val_precision: 0.8333 - val_recall: 0.4225\n",
      "Epoch 83/200\n",
      "426/426 - 1s - loss: 1.0117 - accuracy: 0.6362 - precision: 0.8440 - recall: 0.4319 - val_loss: 1.1850 - val_accuracy: 0.5000 - val_precision: 0.7606 - val_recall: 0.3803\n",
      "Epoch 84/200\n",
      "426/426 - 1s - loss: 1.0044 - accuracy: 0.6362 - precision: 0.8626 - recall: 0.4272 - val_loss: 1.1303 - val_accuracy: 0.5704 - val_precision: 0.8082 - val_recall: 0.4155\n",
      "Epoch 85/200\n",
      "426/426 - 1s - loss: 0.9895 - accuracy: 0.6385 - precision: 0.8657 - recall: 0.4390 - val_loss: 1.0873 - val_accuracy: 0.6197 - val_precision: 0.8026 - val_recall: 0.4296\n",
      "Epoch 86/200\n",
      "426/426 - 1s - loss: 0.9985 - accuracy: 0.6408 - precision: 0.8664 - recall: 0.4413 - val_loss: 1.1179 - val_accuracy: 0.5845 - val_precision: 0.7361 - val_recall: 0.3732\n",
      "Epoch 87/200\n",
      "426/426 - 1s - loss: 0.9687 - accuracy: 0.6761 - precision: 0.8559 - recall: 0.4601 - val_loss: 1.0670 - val_accuracy: 0.5704 - val_precision: 0.8243 - val_recall: 0.4296\n",
      "Epoch 88/200\n",
      "426/426 - 1s - loss: 0.9934 - accuracy: 0.6549 - precision: 0.8540 - recall: 0.4531 - val_loss: 1.1235 - val_accuracy: 0.5634 - val_precision: 0.7763 - val_recall: 0.4155\n",
      "Epoch 89/200\n",
      "426/426 - 1s - loss: 1.0042 - accuracy: 0.6479 - precision: 0.8069 - recall: 0.4413 - val_loss: 1.1838 - val_accuracy: 0.4859 - val_precision: 0.6829 - val_recall: 0.3944\n",
      "Epoch 90/200\n",
      "426/426 - 1s - loss: 1.0255 - accuracy: 0.6338 - precision: 0.8190 - recall: 0.4460 - val_loss: 1.1493 - val_accuracy: 0.5282 - val_precision: 0.7349 - val_recall: 0.4296\n",
      "Epoch 91/200\n",
      "426/426 - 1s - loss: 0.9805 - accuracy: 0.6502 - precision: 0.8250 - recall: 0.4648 - val_loss: 1.0876 - val_accuracy: 0.5704 - val_precision: 0.7778 - val_recall: 0.4437\n",
      "Epoch 92/200\n",
      "426/426 - 1s - loss: 0.9333 - accuracy: 0.7089 - precision: 0.8683 - recall: 0.4953 - val_loss: 1.0538 - val_accuracy: 0.5775 - val_precision: 0.7949 - val_recall: 0.4366\n",
      "Epoch 93/200\n",
      "426/426 - 1s - loss: 0.9145 - accuracy: 0.6948 - precision: 0.8807 - recall: 0.5023 - val_loss: 1.1820 - val_accuracy: 0.5352 - val_precision: 0.7500 - val_recall: 0.4014\n",
      "Epoch 94/200\n",
      "426/426 - 1s - loss: 0.9235 - accuracy: 0.7089 - precision: 0.8765 - recall: 0.5000 - val_loss: 1.1354 - val_accuracy: 0.5493 - val_precision: 0.7927 - val_recall: 0.4577\n",
      "Epoch 95/200\n",
      "426/426 - 1s - loss: 0.8967 - accuracy: 0.6925 - precision: 0.8996 - recall: 0.5258 - val_loss: 1.0440 - val_accuracy: 0.6197 - val_precision: 0.8072 - val_recall: 0.4718\n",
      "Epoch 96/200\n",
      "426/426 - 1s - loss: 0.8858 - accuracy: 0.7183 - precision: 0.8851 - recall: 0.5423 - val_loss: 1.3177 - val_accuracy: 0.5423 - val_precision: 0.6286 - val_recall: 0.4648\n",
      "Epoch 97/200\n",
      "426/426 - 1s - loss: 0.9089 - accuracy: 0.7183 - precision: 0.8447 - recall: 0.5235 - val_loss: 1.0154 - val_accuracy: 0.6197 - val_precision: 0.8118 - val_recall: 0.4859\n",
      "Epoch 98/200\n",
      "426/426 - 1s - loss: 0.8530 - accuracy: 0.7394 - precision: 0.9027 - recall: 0.5446 - val_loss: 1.0345 - val_accuracy: 0.6056 - val_precision: 0.7802 - val_recall: 0.5000\n",
      "Epoch 99/200\n",
      "426/426 - 1s - loss: 0.8372 - accuracy: 0.7512 - precision: 0.8955 - recall: 0.5634 - val_loss: 1.0792 - val_accuracy: 0.5986 - val_precision: 0.8161 - val_recall: 0.5000\n",
      "Epoch 100/200\n",
      "426/426 - 1s - loss: 0.8428 - accuracy: 0.7277 - precision: 0.8881 - recall: 0.5587 - val_loss: 1.0678 - val_accuracy: 0.5845 - val_precision: 0.7692 - val_recall: 0.4930\n",
      "Epoch 101/200\n",
      "426/426 - 1s - loss: 0.8682 - accuracy: 0.7230 - precision: 0.8885 - recall: 0.5610 - val_loss: 1.0648 - val_accuracy: 0.5775 - val_precision: 0.7640 - val_recall: 0.4789\n",
      "Epoch 102/200\n",
      "426/426 - 1s - loss: 0.8112 - accuracy: 0.7653 - precision: 0.8982 - recall: 0.5798 - val_loss: 0.9913 - val_accuracy: 0.6268 - val_precision: 0.8276 - val_recall: 0.5070\n",
      "Epoch 103/200\n",
      "426/426 - 1s - loss: 0.7863 - accuracy: 0.7746 - precision: 0.8857 - recall: 0.5822 - val_loss: 1.0224 - val_accuracy: 0.6197 - val_precision: 0.7629 - val_recall: 0.5211\n",
      "Epoch 104/200\n",
      "426/426 - 1s - loss: 0.8379 - accuracy: 0.7371 - precision: 0.8897 - recall: 0.5681 - val_loss: 1.0158 - val_accuracy: 0.6408 - val_precision: 0.8132 - val_recall: 0.5211\n",
      "Epoch 105/200\n",
      "426/426 - 1s - loss: 0.8827 - accuracy: 0.7089 - precision: 0.8561 - recall: 0.5305 - val_loss: 0.9196 - val_accuracy: 0.6549 - val_precision: 0.8452 - val_recall: 0.5000\n",
      "Epoch 106/200\n",
      "426/426 - 1s - loss: 0.8467 - accuracy: 0.7183 - precision: 0.8407 - recall: 0.5329 - val_loss: 0.9340 - val_accuracy: 0.6338 - val_precision: 0.8571 - val_recall: 0.5070\n",
      "Epoch 107/200\n",
      "426/426 - 1s - loss: 0.7975 - accuracy: 0.7418 - precision: 0.8993 - recall: 0.5657 - val_loss: 0.9121 - val_accuracy: 0.6620 - val_precision: 0.8556 - val_recall: 0.5423\n",
      "Epoch 108/200\n",
      "426/426 - 1s - loss: 0.8036 - accuracy: 0.7441 - precision: 0.8974 - recall: 0.5751 - val_loss: 1.0732 - val_accuracy: 0.6197 - val_precision: 0.7955 - val_recall: 0.4930\n",
      "Epoch 109/200\n",
      "426/426 - 1s - loss: 0.8199 - accuracy: 0.7254 - precision: 0.8836 - recall: 0.5704 - val_loss: 1.1849 - val_accuracy: 0.5493 - val_precision: 0.6893 - val_recall: 0.5000\n",
      "Epoch 110/200\n",
      "426/426 - 1s - loss: 0.7664 - accuracy: 0.7559 - precision: 0.9085 - recall: 0.6056 - val_loss: 0.9078 - val_accuracy: 0.6901 - val_precision: 0.8144 - val_recall: 0.5563\n",
      "Epoch 111/200\n",
      "426/426 - 1s - loss: 0.8151 - accuracy: 0.7700 - precision: 0.8885 - recall: 0.5798 - val_loss: 0.9546 - val_accuracy: 0.6761 - val_precision: 0.8280 - val_recall: 0.5423\n",
      "Epoch 112/200\n",
      "426/426 - 1s - loss: 0.7321 - accuracy: 0.7770 - precision: 0.8800 - recall: 0.6197 - val_loss: 0.8925 - val_accuracy: 0.6620 - val_precision: 0.8636 - val_recall: 0.5352\n",
      "Epoch 113/200\n",
      "426/426 - 1s - loss: 0.7222 - accuracy: 0.7746 - precision: 0.9175 - recall: 0.6268 - val_loss: 0.9209 - val_accuracy: 0.6690 - val_precision: 0.8152 - val_recall: 0.5282\n",
      "Epoch 114/200\n",
      "426/426 - 1s - loss: 0.7474 - accuracy: 0.7770 - precision: 0.8926 - recall: 0.6244 - val_loss: 0.9243 - val_accuracy: 0.6690 - val_precision: 0.8085 - val_recall: 0.5352\n",
      "Epoch 115/200\n",
      "426/426 - 1s - loss: 0.7488 - accuracy: 0.7723 - precision: 0.8841 - recall: 0.6268 - val_loss: 0.9534 - val_accuracy: 0.6479 - val_precision: 0.8021 - val_recall: 0.5423\n",
      "Epoch 116/200\n",
      "426/426 - 1s - loss: 0.7198 - accuracy: 0.7887 - precision: 0.8856 - recall: 0.6362 - val_loss: 0.9522 - val_accuracy: 0.6408 - val_precision: 0.8229 - val_recall: 0.5563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/200\n",
      "426/426 - 1s - loss: 0.7140 - accuracy: 0.7676 - precision: 0.9037 - recall: 0.6385 - val_loss: 0.9177 - val_accuracy: 0.6761 - val_precision: 0.8172 - val_recall: 0.5352\n",
      "Epoch 118/200\n",
      "426/426 - 1s - loss: 0.7268 - accuracy: 0.7723 - precision: 0.8951 - recall: 0.6408 - val_loss: 0.8980 - val_accuracy: 0.6761 - val_precision: 0.8247 - val_recall: 0.5634\n",
      "Epoch 119/200\n",
      "426/426 - 1s - loss: 0.6909 - accuracy: 0.7887 - precision: 0.9003 - recall: 0.6573 - val_loss: 0.9832 - val_accuracy: 0.6620 - val_precision: 0.7451 - val_recall: 0.5352\n",
      "Epoch 120/200\n",
      "426/426 - 1s - loss: 0.7265 - accuracy: 0.7700 - precision: 0.8900 - recall: 0.6455 - val_loss: 0.9926 - val_accuracy: 0.6338 - val_precision: 0.8000 - val_recall: 0.5070\n",
      "Epoch 121/200\n",
      "426/426 - 1s - loss: 0.7082 - accuracy: 0.7887 - precision: 0.9061 - recall: 0.6573 - val_loss: 0.9650 - val_accuracy: 0.6268 - val_precision: 0.7849 - val_recall: 0.5141\n",
      "Epoch 122/200\n",
      "426/426 - 1s - loss: 0.7141 - accuracy: 0.7817 - precision: 0.8942 - recall: 0.6549 - val_loss: 1.7393 - val_accuracy: 0.4437 - val_precision: 0.6235 - val_recall: 0.3732\n",
      "Epoch 123/200\n",
      "426/426 - 1s - loss: 1.1527 - accuracy: 0.6150 - precision: 0.7985 - recall: 0.4930 - val_loss: 1.3243 - val_accuracy: 0.5282 - val_precision: 0.6531 - val_recall: 0.4507\n",
      "Epoch 124/200\n",
      "426/426 - 1s - loss: 0.9571 - accuracy: 0.6948 - precision: 0.8357 - recall: 0.5610 - val_loss: 1.0570 - val_accuracy: 0.6056 - val_precision: 0.7528 - val_recall: 0.4718\n",
      "Epoch 125/200\n",
      "426/426 - 1s - loss: 0.9496 - accuracy: 0.6878 - precision: 0.8000 - recall: 0.5540 - val_loss: 1.1145 - val_accuracy: 0.5563 - val_precision: 0.7416 - val_recall: 0.4648\n",
      "Epoch 126/200\n",
      "426/426 - 1s - loss: 0.8859 - accuracy: 0.6878 - precision: 0.8375 - recall: 0.5446 - val_loss: 0.9232 - val_accuracy: 0.6690 - val_precision: 0.8132 - val_recall: 0.5211\n",
      "Epoch 127/200\n",
      "426/426 - 1s - loss: 0.7653 - accuracy: 0.7512 - precision: 0.8905 - recall: 0.5915 - val_loss: 1.3164 - val_accuracy: 0.5634 - val_precision: 0.6759 - val_recall: 0.5141\n",
      "Epoch 128/200\n",
      "426/426 - 1s - loss: 0.8059 - accuracy: 0.7347 - precision: 0.8828 - recall: 0.6009 - val_loss: 0.9957 - val_accuracy: 0.6268 - val_precision: 0.7766 - val_recall: 0.5141\n",
      "Epoch 129/200\n",
      "426/426 - 1s - loss: 0.7128 - accuracy: 0.7746 - precision: 0.8882 - recall: 0.6338 - val_loss: 0.9783 - val_accuracy: 0.6268 - val_precision: 0.7889 - val_recall: 0.5000\n",
      "Epoch 130/200\n",
      "426/426 - 1s - loss: 0.7139 - accuracy: 0.7770 - precision: 0.8770 - recall: 0.6362 - val_loss: 0.9542 - val_accuracy: 0.6549 - val_precision: 0.7789 - val_recall: 0.5211\n",
      "Epoch 131/200\n",
      "426/426 - 1s - loss: 0.7039 - accuracy: 0.7723 - precision: 0.8750 - recall: 0.6408 - val_loss: 0.8946 - val_accuracy: 0.6690 - val_precision: 0.8333 - val_recall: 0.5634\n",
      "Epoch 132/200\n",
      "426/426 - 1s - loss: 0.6549 - accuracy: 0.7958 - precision: 0.9122 - recall: 0.6831 - val_loss: 0.8636 - val_accuracy: 0.7042 - val_precision: 0.8173 - val_recall: 0.5986\n",
      "Epoch 133/200\n",
      "426/426 - 1s - loss: 0.6686 - accuracy: 0.7864 - precision: 0.9054 - recall: 0.6737 - val_loss: 1.0132 - val_accuracy: 0.6620 - val_precision: 0.7364 - val_recall: 0.5704\n",
      "Epoch 134/200\n",
      "426/426 - 1s - loss: 0.6490 - accuracy: 0.8146 - precision: 0.9077 - recall: 0.6925 - val_loss: 0.9413 - val_accuracy: 0.6761 - val_precision: 0.7455 - val_recall: 0.5775\n",
      "Epoch 135/200\n",
      "426/426 - 1s - loss: 0.7233 - accuracy: 0.7629 - precision: 0.8523 - recall: 0.6502 - val_loss: 0.8737 - val_accuracy: 0.6901 - val_precision: 0.8020 - val_recall: 0.5704\n",
      "Epoch 136/200\n",
      "426/426 - 1s - loss: 0.7345 - accuracy: 0.7559 - precision: 0.8549 - recall: 0.6502 - val_loss: 0.9505 - val_accuracy: 0.6197 - val_precision: 0.7474 - val_recall: 0.5000\n",
      "Epoch 137/200\n",
      "426/426 - 1s - loss: 0.6758 - accuracy: 0.7981 - precision: 0.9003 - recall: 0.6784 - val_loss: 0.8577 - val_accuracy: 0.7042 - val_precision: 0.7736 - val_recall: 0.5775\n",
      "Epoch 138/200\n",
      "426/426 - 1s - loss: 0.6226 - accuracy: 0.8028 - precision: 0.8968 - recall: 0.7136 - val_loss: 0.8744 - val_accuracy: 0.6901 - val_precision: 0.8081 - val_recall: 0.5634\n",
      "Epoch 139/200\n",
      "426/426 - 1s - loss: 0.6210 - accuracy: 0.8005 - precision: 0.9052 - recall: 0.6948 - val_loss: 0.8686 - val_accuracy: 0.6690 - val_precision: 0.8077 - val_recall: 0.5915\n",
      "Epoch 140/200\n",
      "426/426 - 1s - loss: 0.6294 - accuracy: 0.8005 - precision: 0.8909 - recall: 0.7089 - val_loss: 0.9148 - val_accuracy: 0.6690 - val_precision: 0.7736 - val_recall: 0.5775\n",
      "Epoch 141/200\n",
      "426/426 - 1s - loss: 0.6629 - accuracy: 0.8005 - precision: 0.8869 - recall: 0.6808 - val_loss: 0.8717 - val_accuracy: 0.6690 - val_precision: 0.8367 - val_recall: 0.5775\n",
      "Epoch 142/200\n",
      "426/426 - 1s - loss: 0.5934 - accuracy: 0.8239 - precision: 0.9210 - recall: 0.7113 - val_loss: 0.8464 - val_accuracy: 0.6620 - val_precision: 0.8252 - val_recall: 0.5986\n",
      "Epoch 143/200\n",
      "426/426 - 1s - loss: 0.5902 - accuracy: 0.8286 - precision: 0.9137 - recall: 0.7207 - val_loss: 0.8444 - val_accuracy: 0.7254 - val_precision: 0.8137 - val_recall: 0.5845\n",
      "Epoch 144/200\n",
      "426/426 - 1s - loss: 0.6249 - accuracy: 0.8028 - precision: 0.9072 - recall: 0.7113 - val_loss: 0.8236 - val_accuracy: 0.7183 - val_precision: 0.8632 - val_recall: 0.5775\n",
      "Epoch 145/200\n",
      "426/426 - 1s - loss: 0.5954 - accuracy: 0.8099 - precision: 0.9184 - recall: 0.7136 - val_loss: 0.8120 - val_accuracy: 0.7254 - val_precision: 0.8351 - val_recall: 0.5704\n",
      "Epoch 146/200\n",
      "426/426 - 1s - loss: 0.5968 - accuracy: 0.8357 - precision: 0.9104 - recall: 0.7160 - val_loss: 0.8233 - val_accuracy: 0.6972 - val_precision: 0.8400 - val_recall: 0.5915\n",
      "Epoch 147/200\n",
      "426/426 - 1s - loss: 0.5693 - accuracy: 0.8333 - precision: 0.9107 - recall: 0.7183 - val_loss: 0.9042 - val_accuracy: 0.6831 - val_precision: 0.7636 - val_recall: 0.5915\n",
      "Epoch 148/200\n",
      "426/426 - 1s - loss: 0.5897 - accuracy: 0.8286 - precision: 0.9145 - recall: 0.7277 - val_loss: 0.7759 - val_accuracy: 0.7535 - val_precision: 0.8673 - val_recall: 0.5986\n",
      "Epoch 149/200\n",
      "426/426 - 1s - loss: 0.5881 - accuracy: 0.8239 - precision: 0.9107 - recall: 0.7183 - val_loss: 0.8551 - val_accuracy: 0.6972 - val_precision: 0.8182 - val_recall: 0.5704\n",
      "Epoch 150/200\n",
      "426/426 - 1s - loss: 0.5644 - accuracy: 0.8474 - precision: 0.9220 - recall: 0.7488 - val_loss: 0.9833 - val_accuracy: 0.6197 - val_precision: 0.7255 - val_recall: 0.5211\n",
      "Epoch 151/200\n",
      "426/426 - 1s - loss: 0.5813 - accuracy: 0.8286 - precision: 0.9172 - recall: 0.7019 - val_loss: 0.8483 - val_accuracy: 0.7254 - val_precision: 0.8019 - val_recall: 0.5986\n",
      "Epoch 152/200\n",
      "426/426 - 1s - loss: 0.5608 - accuracy: 0.8451 - precision: 0.9174 - recall: 0.7300 - val_loss: 0.8357 - val_accuracy: 0.6761 - val_precision: 0.8137 - val_recall: 0.5845\n",
      "Epoch 153/200\n",
      "426/426 - 1s - loss: 0.5627 - accuracy: 0.8239 - precision: 0.9133 - recall: 0.7418 - val_loss: 0.8520 - val_accuracy: 0.6620 - val_precision: 0.8000 - val_recall: 0.5915\n",
      "Epoch 154/200\n",
      "426/426 - 1s - loss: 0.5605 - accuracy: 0.8263 - precision: 0.9012 - recall: 0.7277 - val_loss: 0.8118 - val_accuracy: 0.6901 - val_precision: 0.8469 - val_recall: 0.5845\n",
      "Epoch 155/200\n",
      "426/426 - 1s - loss: 0.5444 - accuracy: 0.8404 - precision: 0.9318 - recall: 0.7371 - val_loss: 1.2076 - val_accuracy: 0.5986 - val_precision: 0.6535 - val_recall: 0.5845\n",
      "Epoch 156/200\n",
      "426/426 - 1s - loss: 0.6474 - accuracy: 0.8028 - precision: 0.8853 - recall: 0.7066 - val_loss: 0.8191 - val_accuracy: 0.7042 - val_precision: 0.8077 - val_recall: 0.5915\n",
      "Epoch 157/200\n",
      "426/426 - 1s - loss: 0.5731 - accuracy: 0.8169 - precision: 0.9062 - recall: 0.7254 - val_loss: 0.8711 - val_accuracy: 0.6831 - val_precision: 0.8462 - val_recall: 0.5423\n",
      "Epoch 158/200\n",
      "426/426 - 1s - loss: 0.6111 - accuracy: 0.8052 - precision: 0.9133 - recall: 0.6925 - val_loss: 0.7920 - val_accuracy: 0.7606 - val_precision: 0.8696 - val_recall: 0.5634\n",
      "Epoch 159/200\n",
      "426/426 - 1s - loss: 0.5361 - accuracy: 0.8592 - precision: 0.9271 - recall: 0.7465 - val_loss: 0.8556 - val_accuracy: 0.6901 - val_precision: 0.8173 - val_recall: 0.5986\n",
      "Epoch 160/200\n",
      "426/426 - 1s - loss: 0.5332 - accuracy: 0.8427 - precision: 0.9171 - recall: 0.7535 - val_loss: 0.8126 - val_accuracy: 0.7254 - val_precision: 0.8190 - val_recall: 0.6056\n",
      "Epoch 161/200\n",
      "426/426 - 1s - loss: 0.5417 - accuracy: 0.8474 - precision: 0.9042 - recall: 0.7535 - val_loss: 0.7722 - val_accuracy: 0.7324 - val_precision: 0.8333 - val_recall: 0.5986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/200\n",
      "426/426 - 1s - loss: 0.5071 - accuracy: 0.8638 - precision: 0.9277 - recall: 0.7535 - val_loss: 0.7729 - val_accuracy: 0.7606 - val_precision: 0.8462 - val_recall: 0.6197\n",
      "Epoch 163/200\n",
      "426/426 - 1s - loss: 0.5001 - accuracy: 0.8638 - precision: 0.9337 - recall: 0.7606 - val_loss: 0.7924 - val_accuracy: 0.7324 - val_precision: 0.8190 - val_recall: 0.6056\n",
      "Epoch 164/200\n",
      "426/426 - 1s - loss: 0.5294 - accuracy: 0.8615 - precision: 0.9130 - recall: 0.7394 - val_loss: 0.7579 - val_accuracy: 0.7676 - val_precision: 0.8600 - val_recall: 0.6056\n",
      "Epoch 165/200\n",
      "426/426 - 1s - loss: 0.4901 - accuracy: 0.8756 - precision: 0.9370 - recall: 0.7676 - val_loss: 0.7709 - val_accuracy: 0.7535 - val_precision: 0.8302 - val_recall: 0.6197\n",
      "Epoch 166/200\n",
      "426/426 - 1s - loss: 0.5060 - accuracy: 0.8662 - precision: 0.9176 - recall: 0.7582 - val_loss: 0.7537 - val_accuracy: 0.7324 - val_precision: 0.8349 - val_recall: 0.6408\n",
      "Epoch 167/200\n",
      "426/426 - 1s - loss: 0.5520 - accuracy: 0.8286 - precision: 0.9075 - recall: 0.7371 - val_loss: 0.7608 - val_accuracy: 0.7113 - val_precision: 0.8431 - val_recall: 0.6056\n",
      "Epoch 168/200\n",
      "426/426 - 1s - loss: 0.5756 - accuracy: 0.8357 - precision: 0.8819 - recall: 0.7535 - val_loss: 0.7835 - val_accuracy: 0.7394 - val_precision: 0.8073 - val_recall: 0.6197\n",
      "Epoch 169/200\n",
      "426/426 - 1s - loss: 0.5274 - accuracy: 0.8357 - precision: 0.9106 - recall: 0.7653 - val_loss: 0.7817 - val_accuracy: 0.7113 - val_precision: 0.7963 - val_recall: 0.6056\n",
      "Epoch 170/200\n",
      "426/426 - 1s - loss: 0.4924 - accuracy: 0.8615 - precision: 0.9192 - recall: 0.7746 - val_loss: 0.8364 - val_accuracy: 0.6761 - val_precision: 0.7757 - val_recall: 0.5845\n",
      "Epoch 171/200\n",
      "426/426 - 1s - loss: 0.5619 - accuracy: 0.8333 - precision: 0.8914 - recall: 0.7324 - val_loss: 0.8228 - val_accuracy: 0.6972 - val_precision: 0.7826 - val_recall: 0.6338\n",
      "Epoch 172/200\n",
      "426/426 - 1s - loss: 0.4994 - accuracy: 0.8732 - precision: 0.9128 - recall: 0.7864 - val_loss: 0.7603 - val_accuracy: 0.7113 - val_precision: 0.8224 - val_recall: 0.6197\n",
      "Epoch 173/200\n",
      "426/426 - 1s - loss: 0.4876 - accuracy: 0.8732 - precision: 0.9174 - recall: 0.7817 - val_loss: 0.7168 - val_accuracy: 0.7746 - val_precision: 0.8532 - val_recall: 0.6549\n",
      "Epoch 174/200\n",
      "426/426 - 1s - loss: 0.4611 - accuracy: 0.8873 - precision: 0.9290 - recall: 0.7981 - val_loss: 0.7436 - val_accuracy: 0.7183 - val_precision: 0.8073 - val_recall: 0.6197\n",
      "Epoch 175/200\n",
      "426/426 - 1s - loss: 0.4486 - accuracy: 0.8873 - precision: 0.9326 - recall: 0.8122 - val_loss: 0.7931 - val_accuracy: 0.7324 - val_precision: 0.8125 - val_recall: 0.6408\n",
      "Epoch 176/200\n",
      "426/426 - 1s - loss: 0.4999 - accuracy: 0.8498 - precision: 0.9043 - recall: 0.7981 - val_loss: 0.6996 - val_accuracy: 0.7887 - val_precision: 0.8679 - val_recall: 0.6479\n",
      "Epoch 177/200\n",
      "426/426 - 1s - loss: 0.4542 - accuracy: 0.8920 - precision: 0.9375 - recall: 0.8099 - val_loss: 1.0135 - val_accuracy: 0.6549 - val_precision: 0.7040 - val_recall: 0.6197\n",
      "Epoch 178/200\n",
      "426/426 - 1s - loss: 0.5257 - accuracy: 0.8216 - precision: 0.9088 - recall: 0.7723 - val_loss: 0.6922 - val_accuracy: 0.7535 - val_precision: 0.8440 - val_recall: 0.6479\n",
      "Epoch 179/200\n",
      "426/426 - 1s - loss: 0.5003 - accuracy: 0.8568 - precision: 0.9126 - recall: 0.7840 - val_loss: 0.7369 - val_accuracy: 0.7606 - val_precision: 0.8455 - val_recall: 0.6549\n",
      "Epoch 180/200\n",
      "426/426 - 1s - loss: 0.4490 - accuracy: 0.8873 - precision: 0.9322 - recall: 0.8075 - val_loss: 0.7707 - val_accuracy: 0.7606 - val_precision: 0.8125 - val_recall: 0.6408\n",
      "Epoch 181/200\n",
      "426/426 - 1s - loss: 0.4489 - accuracy: 0.8803 - precision: 0.9223 - recall: 0.8075 - val_loss: 0.7301 - val_accuracy: 0.7606 - val_precision: 0.8333 - val_recall: 0.6338\n",
      "Epoch 182/200\n",
      "426/426 - 1s - loss: 0.4279 - accuracy: 0.8873 - precision: 0.9395 - recall: 0.8380 - val_loss: 0.7552 - val_accuracy: 0.7606 - val_precision: 0.8205 - val_recall: 0.6761\n",
      "Epoch 183/200\n",
      "426/426 - 1s - loss: 0.4411 - accuracy: 0.8779 - precision: 0.9357 - recall: 0.8192 - val_loss: 0.7173 - val_accuracy: 0.7535 - val_precision: 0.8785 - val_recall: 0.6620\n",
      "Epoch 184/200\n",
      "426/426 - 1s - loss: 0.4194 - accuracy: 0.8991 - precision: 0.9468 - recall: 0.8357 - val_loss: 0.7466 - val_accuracy: 0.7394 - val_precision: 0.8378 - val_recall: 0.6549\n",
      "Epoch 185/200\n",
      "426/426 - 1s - loss: 0.4399 - accuracy: 0.8826 - precision: 0.9335 - recall: 0.8239 - val_loss: 0.7327 - val_accuracy: 0.7324 - val_precision: 0.8220 - val_recall: 0.6831\n",
      "Epoch 186/200\n",
      "426/426 - 1s - loss: 0.4301 - accuracy: 0.8920 - precision: 0.9393 - recall: 0.8357 - val_loss: 0.7324 - val_accuracy: 0.7324 - val_precision: 0.8190 - val_recall: 0.6690\n",
      "Epoch 187/200\n",
      "426/426 - 1s - loss: 0.3920 - accuracy: 0.9108 - precision: 0.9528 - recall: 0.8521 - val_loss: 0.7504 - val_accuracy: 0.7606 - val_precision: 0.8362 - val_recall: 0.6831\n",
      "Epoch 188/200\n",
      "426/426 - 1s - loss: 0.5092 - accuracy: 0.8615 - precision: 0.8942 - recall: 0.7934 - val_loss: 0.7458 - val_accuracy: 0.7535 - val_precision: 0.8205 - val_recall: 0.6761\n",
      "Epoch 189/200\n",
      "426/426 - 1s - loss: 0.4566 - accuracy: 0.8873 - precision: 0.9241 - recall: 0.8286 - val_loss: 0.7291 - val_accuracy: 0.7394 - val_precision: 0.8205 - val_recall: 0.6761\n",
      "Epoch 190/200\n",
      "426/426 - 1s - loss: 0.4214 - accuracy: 0.8850 - precision: 0.9539 - recall: 0.8263 - val_loss: 0.7763 - val_accuracy: 0.6972 - val_precision: 0.7949 - val_recall: 0.6549\n",
      "Epoch 191/200\n",
      "426/426 - 1s - loss: 0.4116 - accuracy: 0.8991 - precision: 0.9378 - recall: 0.8498 - val_loss: 0.6575 - val_accuracy: 0.7817 - val_precision: 0.8403 - val_recall: 0.7042\n",
      "Epoch 192/200\n",
      "426/426 - 1s - loss: 0.4231 - accuracy: 0.8803 - precision: 0.9275 - recall: 0.8404 - val_loss: 0.7460 - val_accuracy: 0.7465 - val_precision: 0.8120 - val_recall: 0.6690\n",
      "Epoch 193/200\n",
      "426/426 - 1s - loss: 0.4051 - accuracy: 0.8991 - precision: 0.9326 - recall: 0.8451 - val_loss: 0.6539 - val_accuracy: 0.7746 - val_precision: 0.8403 - val_recall: 0.7042\n",
      "Epoch 194/200\n",
      "426/426 - 1s - loss: 0.3753 - accuracy: 0.9202 - precision: 0.9488 - recall: 0.8709 - val_loss: 0.6965 - val_accuracy: 0.7606 - val_precision: 0.8522 - val_recall: 0.6901\n",
      "Epoch 195/200\n",
      "426/426 - 1s - loss: 0.3803 - accuracy: 0.9178 - precision: 0.9564 - recall: 0.8756 - val_loss: 0.6652 - val_accuracy: 0.7535 - val_precision: 0.8319 - val_recall: 0.6972\n",
      "Epoch 196/200\n",
      "426/426 - 1s - loss: 0.3604 - accuracy: 0.9202 - precision: 0.9520 - recall: 0.8850 - val_loss: 0.7630 - val_accuracy: 0.7394 - val_precision: 0.7851 - val_recall: 0.6690\n",
      "Epoch 197/200\n",
      "426/426 - 1s - loss: 0.4341 - accuracy: 0.8850 - precision: 0.9227 - recall: 0.8404 - val_loss: 0.8241 - val_accuracy: 0.7324 - val_precision: 0.7966 - val_recall: 0.6620\n",
      "Epoch 198/200\n",
      "426/426 - 1s - loss: 0.3742 - accuracy: 0.9131 - precision: 0.9468 - recall: 0.8779 - val_loss: 0.6727 - val_accuracy: 0.7606 - val_precision: 0.8673 - val_recall: 0.6901\n",
      "Epoch 199/200\n",
      "426/426 - 1s - loss: 0.3862 - accuracy: 0.9131 - precision: 0.9508 - recall: 0.8615 - val_loss: 0.7070 - val_accuracy: 0.7817 - val_precision: 0.8673 - val_recall: 0.6901\n",
      "Epoch 200/200\n",
      "426/426 - 1s - loss: 0.3975 - accuracy: 0.8873 - precision: 0.9347 - recall: 0.8404 - val_loss: 0.6864 - val_accuracy: 0.7817 - val_precision: 0.8279 - val_recall: 0.7113\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 442de4ecfab311efee97ef64a88bc6e4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7957746386528015</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_1_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_2_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_End: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_input: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-optimizer: Adagrad</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 192)          214272    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 128)          164352    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 192)          246528    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 128)          164352    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 96)                86400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1164      \n",
      "=================================================================\n",
      "Total params: 877,068\n",
      "Trainable params: 877,068\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "RMSprop\n",
      "\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/200\n",
      "426/426 - 15s - loss: 2.4604 - accuracy: 0.1033 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.3735 - val_accuracy: 0.1127 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      "426/426 - 1s - loss: 2.2231 - accuracy: 0.2089 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9448 - val_accuracy: 0.2042 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/200\n",
      "426/426 - 1s - loss: 1.9680 - accuracy: 0.2418 - precision: 0.3333 - recall: 0.0047 - val_loss: 1.9025 - val_accuracy: 0.1831 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/200\n",
      "426/426 - 1s - loss: 1.9054 - accuracy: 0.2347 - precision: 0.2500 - recall: 0.0070 - val_loss: 1.9573 - val_accuracy: 0.1690 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/200\n",
      "426/426 - 1s - loss: 1.9298 - accuracy: 0.2160 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9367 - val_accuracy: 0.1901 - val_precision: 0.4333 - val_recall: 0.0915\n",
      "Epoch 6/200\n",
      "426/426 - 1s - loss: 1.9107 - accuracy: 0.2347 - precision: 0.3333 - recall: 0.0117 - val_loss: 1.8792 - val_accuracy: 0.1831 - val_precision: 0.2174 - val_recall: 0.0352\n",
      "Epoch 7/200\n",
      "426/426 - 1s - loss: 1.8494 - accuracy: 0.2324 - precision: 0.4615 - recall: 0.0141 - val_loss: 1.8109 - val_accuracy: 0.2113 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/200\n",
      "426/426 - 1s - loss: 1.8024 - accuracy: 0.2559 - precision: 0.5000 - recall: 0.0094 - val_loss: 1.8145 - val_accuracy: 0.2394 - val_precision: 0.6667 - val_recall: 0.0282\n",
      "Epoch 9/200\n",
      "426/426 - 1s - loss: 1.8030 - accuracy: 0.2559 - precision: 0.3889 - recall: 0.0164 - val_loss: 1.7905 - val_accuracy: 0.2535 - val_precision: 0.6364 - val_recall: 0.0493\n",
      "Epoch 10/200\n",
      "426/426 - 1s - loss: 1.8065 - accuracy: 0.2629 - precision: 0.1429 - recall: 0.0023 - val_loss: 1.7711 - val_accuracy: 0.2183 - val_precision: 0.6667 - val_recall: 0.0282\n",
      "Epoch 11/200\n",
      "426/426 - 1s - loss: 1.8251 - accuracy: 0.2676 - precision: 0.4167 - recall: 0.0117 - val_loss: 1.7736 - val_accuracy: 0.2465 - val_precision: 0.8000 - val_recall: 0.0282\n",
      "Epoch 12/200\n",
      "426/426 - 1s - loss: 1.7630 - accuracy: 0.3005 - precision: 0.6190 - recall: 0.0305 - val_loss: 1.8105 - val_accuracy: 0.2394 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/200\n",
      "426/426 - 1s - loss: 1.7745 - accuracy: 0.2676 - precision: 0.4706 - recall: 0.0188 - val_loss: 1.7496 - val_accuracy: 0.2254 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 14/200\n",
      "426/426 - 1s - loss: 1.9649 - accuracy: 0.2629 - precision: 0.5000 - recall: 0.0258 - val_loss: 2.5737 - val_accuracy: 0.1056 - val_precision: 1.0000 - val_recall: 0.0070\n",
      "Epoch 15/200\n",
      "426/426 - 1s - loss: 1.8646 - accuracy: 0.2676 - precision: 0.5500 - recall: 0.0258 - val_loss: 1.7382 - val_accuracy: 0.2535 - val_precision: 0.6667 - val_recall: 0.0423\n",
      "Epoch 16/200\n",
      "426/426 - 1s - loss: 1.7715 - accuracy: 0.2723 - precision: 0.4800 - recall: 0.0282 - val_loss: 2.1371 - val_accuracy: 0.1972 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/200\n",
      "426/426 - 1s - loss: 1.7791 - accuracy: 0.2746 - precision: 0.6667 - recall: 0.0188 - val_loss: 1.7915 - val_accuracy: 0.2394 - val_precision: 1.0000 - val_recall: 0.0282\n",
      "Epoch 18/200\n",
      "426/426 - 1s - loss: 1.7521 - accuracy: 0.2958 - precision: 0.5000 - recall: 0.0352 - val_loss: 1.7337 - val_accuracy: 0.2606 - val_precision: 0.5000 - val_recall: 0.0141\n",
      "Epoch 19/200\n",
      "426/426 - 1s - loss: 1.7177 - accuracy: 0.2887 - precision: 0.4000 - recall: 0.0141 - val_loss: 1.7462 - val_accuracy: 0.2606 - val_precision: 0.5000 - val_recall: 0.0211\n",
      "Epoch 20/200\n",
      "426/426 - 1s - loss: 1.6659 - accuracy: 0.3333 - precision: 0.5263 - recall: 0.0235 - val_loss: 1.6626 - val_accuracy: 0.3521 - val_precision: 0.6000 - val_recall: 0.0634\n",
      "Epoch 21/200\n",
      "426/426 - 1s - loss: 1.7454 - accuracy: 0.2934 - precision: 0.4390 - recall: 0.0423 - val_loss: 1.9155 - val_accuracy: 0.2606 - val_precision: 0.4242 - val_recall: 0.0986\n",
      "Epoch 22/200\n",
      "426/426 - 1s - loss: 1.7078 - accuracy: 0.2793 - precision: 0.6316 - recall: 0.0563 - val_loss: 1.6543 - val_accuracy: 0.3451 - val_precision: 0.6364 - val_recall: 0.0493\n",
      "Epoch 23/200\n",
      "426/426 - 1s - loss: 1.6765 - accuracy: 0.3592 - precision: 0.5714 - recall: 0.0469 - val_loss: 1.6222 - val_accuracy: 0.2817 - val_precision: 0.6667 - val_recall: 0.0282\n",
      "Epoch 24/200\n",
      "426/426 - 1s - loss: 1.6103 - accuracy: 0.3545 - precision: 0.5385 - recall: 0.0822 - val_loss: 1.8752 - val_accuracy: 0.2676 - val_precision: 0.8000 - val_recall: 0.0282\n",
      "Epoch 25/200\n",
      "426/426 - 1s - loss: 1.6297 - accuracy: 0.3239 - precision: 0.6341 - recall: 0.0610 - val_loss: 1.5685 - val_accuracy: 0.3169 - val_precision: 0.9167 - val_recall: 0.0775\n",
      "Epoch 26/200\n",
      "426/426 - 1s - loss: 1.6462 - accuracy: 0.3451 - precision: 0.4821 - recall: 0.0634 - val_loss: 1.5780 - val_accuracy: 0.3803 - val_precision: 1.0000 - val_recall: 0.0986\n",
      "Epoch 27/200\n",
      "426/426 - 1s - loss: 1.5221 - accuracy: 0.3850 - precision: 0.7167 - recall: 0.1009 - val_loss: 1.6589 - val_accuracy: 0.3169 - val_precision: 0.9167 - val_recall: 0.0775\n",
      "Epoch 28/200\n",
      "426/426 - 1s - loss: 1.5927 - accuracy: 0.3146 - precision: 0.6512 - recall: 0.0657 - val_loss: 1.6763 - val_accuracy: 0.3592 - val_precision: 0.5250 - val_recall: 0.1479\n",
      "Epoch 29/200\n",
      "426/426 - 1s - loss: 1.6589 - accuracy: 0.3451 - precision: 0.5714 - recall: 0.1033 - val_loss: 1.5757 - val_accuracy: 0.3662 - val_precision: 0.6552 - val_recall: 0.1338\n",
      "Epoch 30/200\n",
      "426/426 - 1s - loss: 1.5241 - accuracy: 0.3662 - precision: 0.6000 - recall: 0.1197 - val_loss: 1.7487 - val_accuracy: 0.3169 - val_precision: 0.7308 - val_recall: 0.1338\n",
      "Epoch 31/200\n",
      "426/426 - 1s - loss: 1.5483 - accuracy: 0.3732 - precision: 0.5556 - recall: 0.1056 - val_loss: 1.5213 - val_accuracy: 0.3239 - val_precision: 0.6207 - val_recall: 0.1268\n",
      "Epoch 32/200\n",
      "426/426 - 1s - loss: 1.5272 - accuracy: 0.3545 - precision: 0.6812 - recall: 0.1103 - val_loss: 1.5685 - val_accuracy: 0.3521 - val_precision: 1.0000 - val_recall: 0.1127\n",
      "Epoch 33/200\n",
      "426/426 - 1s - loss: 1.4483 - accuracy: 0.3779 - precision: 0.6806 - recall: 0.1150 - val_loss: 1.5195 - val_accuracy: 0.3592 - val_precision: 0.7600 - val_recall: 0.1338\n",
      "Epoch 34/200\n",
      "426/426 - 1s - loss: 1.5660 - accuracy: 0.3498 - precision: 0.5429 - recall: 0.0892 - val_loss: 1.4586 - val_accuracy: 0.3732 - val_precision: 0.8500 - val_recall: 0.1197\n",
      "Epoch 35/200\n",
      "426/426 - 1s - loss: 1.5177 - accuracy: 0.3944 - precision: 0.6716 - recall: 0.1056 - val_loss: 1.5545 - val_accuracy: 0.3521 - val_precision: 0.8000 - val_recall: 0.1127\n",
      "Epoch 36/200\n",
      "426/426 - 1s - loss: 1.4733 - accuracy: 0.3920 - precision: 0.6970 - recall: 0.1080 - val_loss: 1.5646 - val_accuracy: 0.3239 - val_precision: 0.5938 - val_recall: 0.1338\n",
      "Epoch 37/200\n",
      "426/426 - 1s - loss: 1.7312 - accuracy: 0.3427 - precision: 0.7031 - recall: 0.1056 - val_loss: 2.4783 - val_accuracy: 0.2254 - val_precision: 0.6207 - val_recall: 0.1268\n",
      "Epoch 38/200\n",
      "426/426 - 1s - loss: 1.6971 - accuracy: 0.3333 - precision: 0.5493 - recall: 0.0915 - val_loss: 1.5887 - val_accuracy: 0.3239 - val_precision: 0.9444 - val_recall: 0.1197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200\n",
      "426/426 - 1s - loss: 1.5070 - accuracy: 0.3803 - precision: 0.7368 - recall: 0.0986 - val_loss: 1.5274 - val_accuracy: 0.3873 - val_precision: 0.8824 - val_recall: 0.1056\n",
      "Epoch 40/200\n",
      "426/426 - 1s - loss: 1.4345 - accuracy: 0.4085 - precision: 0.7705 - recall: 0.1103 - val_loss: 1.6635 - val_accuracy: 0.3099 - val_precision: 0.7500 - val_recall: 0.0423\n",
      "Epoch 41/200\n",
      "426/426 - 1s - loss: 1.4852 - accuracy: 0.3897 - precision: 0.7500 - recall: 0.1127 - val_loss: 1.5381 - val_accuracy: 0.3521 - val_precision: 0.8095 - val_recall: 0.1197\n",
      "Epoch 42/200\n",
      "426/426 - 1s - loss: 1.4467 - accuracy: 0.4085 - precision: 0.6979 - recall: 0.1573 - val_loss: 1.9522 - val_accuracy: 0.2535 - val_precision: 0.4000 - val_recall: 0.1408\n",
      "Epoch 43/200\n",
      "426/426 - 1s - loss: 1.5331 - accuracy: 0.4155 - precision: 0.5729 - recall: 0.1291 - val_loss: 1.5577 - val_accuracy: 0.3592 - val_precision: 0.5263 - val_recall: 0.1408\n",
      "Epoch 44/200\n",
      "426/426 - 1s - loss: 1.4454 - accuracy: 0.4178 - precision: 0.6306 - recall: 0.1643 - val_loss: 1.7342 - val_accuracy: 0.2746 - val_precision: 0.5263 - val_recall: 0.1408\n",
      "Epoch 45/200\n",
      "426/426 - 1s - loss: 1.4523 - accuracy: 0.3967 - precision: 0.6837 - recall: 0.1573 - val_loss: 1.4787 - val_accuracy: 0.3662 - val_precision: 0.7812 - val_recall: 0.1761\n",
      "Epoch 46/200\n",
      "426/426 - 1s - loss: 1.5558 - accuracy: 0.4014 - precision: 0.6747 - recall: 0.1315 - val_loss: 1.5722 - val_accuracy: 0.3239 - val_precision: 0.7273 - val_recall: 0.1127\n",
      "Epoch 47/200\n",
      "426/426 - 1s - loss: 1.4200 - accuracy: 0.4484 - precision: 0.6822 - recall: 0.1714 - val_loss: 1.7837 - val_accuracy: 0.2817 - val_precision: 0.4773 - val_recall: 0.1479\n",
      "Epoch 48/200\n",
      "426/426 - 1s - loss: 1.3571 - accuracy: 0.4695 - precision: 0.6864 - recall: 0.1901 - val_loss: 1.8868 - val_accuracy: 0.3028 - val_precision: 0.3382 - val_recall: 0.1620\n",
      "Epoch 49/200\n",
      "426/426 - 1s - loss: 1.4082 - accuracy: 0.4742 - precision: 0.6433 - recall: 0.2582 - val_loss: 1.9388 - val_accuracy: 0.3028 - val_precision: 0.4237 - val_recall: 0.1761\n",
      "Epoch 50/200\n",
      "426/426 - 1s - loss: 1.4699 - accuracy: 0.4437 - precision: 0.6306 - recall: 0.2324 - val_loss: 1.8855 - val_accuracy: 0.3028 - val_precision: 0.4074 - val_recall: 0.1549\n",
      "Epoch 51/200\n",
      "426/426 - 1s - loss: 1.4655 - accuracy: 0.4601 - precision: 0.7188 - recall: 0.2160 - val_loss: 1.8405 - val_accuracy: 0.2958 - val_precision: 0.7037 - val_recall: 0.1338\n",
      "Epoch 52/200\n",
      "426/426 - 1s - loss: 1.4021 - accuracy: 0.4648 - precision: 0.7857 - recall: 0.2324 - val_loss: 1.6705 - val_accuracy: 0.3803 - val_precision: 0.5102 - val_recall: 0.1761\n",
      "Epoch 53/200\n",
      "426/426 - 1s - loss: 1.3550 - accuracy: 0.4718 - precision: 0.6966 - recall: 0.2371 - val_loss: 1.4323 - val_accuracy: 0.4296 - val_precision: 0.6200 - val_recall: 0.2183\n",
      "Epoch 54/200\n",
      "426/426 - 1s - loss: 1.3033 - accuracy: 0.4836 - precision: 0.7099 - recall: 0.2700 - val_loss: 1.4139 - val_accuracy: 0.4085 - val_precision: 0.5849 - val_recall: 0.2183\n",
      "Epoch 55/200\n",
      "426/426 - 1s - loss: 1.3505 - accuracy: 0.4859 - precision: 0.7244 - recall: 0.2653 - val_loss: 2.0529 - val_accuracy: 0.2676 - val_precision: 0.4839 - val_recall: 0.1056\n",
      "Epoch 56/200\n",
      "426/426 - 1s - loss: 1.6169 - accuracy: 0.3920 - precision: 0.6333 - recall: 0.1338 - val_loss: 1.9009 - val_accuracy: 0.3380 - val_precision: 0.5455 - val_recall: 0.1268\n",
      "Epoch 57/200\n",
      "426/426 - 1s - loss: 1.4352 - accuracy: 0.4390 - precision: 0.7176 - recall: 0.1432 - val_loss: 1.5705 - val_accuracy: 0.3803 - val_precision: 0.5882 - val_recall: 0.1408\n",
      "Epoch 58/200\n",
      "426/426 - 1s - loss: 1.3150 - accuracy: 0.4601 - precision: 0.7478 - recall: 0.2019 - val_loss: 1.5248 - val_accuracy: 0.3944 - val_precision: 0.5400 - val_recall: 0.1901\n",
      "Epoch 59/200\n",
      "426/426 - 1s - loss: 1.3908 - accuracy: 0.4671 - precision: 0.6850 - recall: 0.2042 - val_loss: 1.6283 - val_accuracy: 0.3380 - val_precision: 0.5333 - val_recall: 0.1127\n",
      "Epoch 60/200\n",
      "426/426 - 1s - loss: 1.3694 - accuracy: 0.4437 - precision: 0.6385 - recall: 0.1948 - val_loss: 1.4944 - val_accuracy: 0.3732 - val_precision: 0.5385 - val_recall: 0.1479\n",
      "Epoch 61/200\n",
      "426/426 - 1s - loss: 1.2101 - accuracy: 0.4953 - precision: 0.7355 - recall: 0.2089 - val_loss: 1.9887 - val_accuracy: 0.2746 - val_precision: 0.3871 - val_recall: 0.0845\n",
      "Epoch 62/200\n",
      "426/426 - 1s - loss: 1.3905 - accuracy: 0.4437 - precision: 0.6358 - recall: 0.2254 - val_loss: 1.5770 - val_accuracy: 0.3592 - val_precision: 0.5094 - val_recall: 0.1901\n",
      "Epoch 63/200\n",
      "426/426 - 1s - loss: 1.2060 - accuracy: 0.5211 - precision: 0.7152 - recall: 0.2770 - val_loss: 1.3836 - val_accuracy: 0.4577 - val_precision: 0.5932 - val_recall: 0.2465\n",
      "Epoch 64/200\n",
      "426/426 - 1s - loss: 1.3249 - accuracy: 0.4413 - precision: 0.6398 - recall: 0.2418 - val_loss: 1.3365 - val_accuracy: 0.4014 - val_precision: 0.6512 - val_recall: 0.1972\n",
      "Epoch 65/200\n",
      "426/426 - 1s - loss: 1.2263 - accuracy: 0.4930 - precision: 0.7091 - recall: 0.2746 - val_loss: 1.3563 - val_accuracy: 0.3944 - val_precision: 0.6000 - val_recall: 0.2324\n",
      "Epoch 66/200\n",
      "426/426 - 1s - loss: 1.3023 - accuracy: 0.4906 - precision: 0.6987 - recall: 0.2559 - val_loss: 1.3145 - val_accuracy: 0.4437 - val_precision: 0.6667 - val_recall: 0.2394\n",
      "Epoch 67/200\n",
      "426/426 - 1s - loss: 1.2092 - accuracy: 0.5094 - precision: 0.6743 - recall: 0.2770 - val_loss: 1.3410 - val_accuracy: 0.4648 - val_precision: 0.6341 - val_recall: 0.1831\n",
      "Epoch 68/200\n",
      "426/426 - 1s - loss: 1.3710 - accuracy: 0.4812 - precision: 0.6391 - recall: 0.2535 - val_loss: 1.5459 - val_accuracy: 0.4085 - val_precision: 0.4545 - val_recall: 0.2113\n",
      "Epoch 69/200\n",
      "426/426 - 1s - loss: 1.1307 - accuracy: 0.5563 - precision: 0.7433 - recall: 0.3263 - val_loss: 1.3676 - val_accuracy: 0.4366 - val_precision: 0.5714 - val_recall: 0.2817\n",
      "Epoch 70/200\n",
      "426/426 - 1s - loss: 1.0569 - accuracy: 0.5399 - precision: 0.7413 - recall: 0.3498 - val_loss: 1.3418 - val_accuracy: 0.4507 - val_precision: 0.5522 - val_recall: 0.2606\n",
      "Epoch 71/200\n",
      "426/426 - 1s - loss: 1.1623 - accuracy: 0.5399 - precision: 0.6589 - recall: 0.3310 - val_loss: 1.3850 - val_accuracy: 0.4296 - val_precision: 0.6800 - val_recall: 0.2394\n",
      "Epoch 72/200\n",
      "426/426 - 1s - loss: 1.1244 - accuracy: 0.5634 - precision: 0.6952 - recall: 0.3427 - val_loss: 1.3866 - val_accuracy: 0.4225 - val_precision: 0.5190 - val_recall: 0.2887\n",
      "Epoch 73/200\n",
      "426/426 - 1s - loss: 1.0798 - accuracy: 0.5657 - precision: 0.7059 - recall: 0.3662 - val_loss: 1.3308 - val_accuracy: 0.4789 - val_precision: 0.6379 - val_recall: 0.2606\n",
      "Epoch 74/200\n",
      "426/426 - 1s - loss: 1.0801 - accuracy: 0.5634 - precision: 0.7111 - recall: 0.3756 - val_loss: 1.3958 - val_accuracy: 0.4507 - val_precision: 0.5429 - val_recall: 0.2676\n",
      "Epoch 75/200\n",
      "426/426 - 1s - loss: 1.0840 - accuracy: 0.5728 - precision: 0.7342 - recall: 0.3826 - val_loss: 1.2528 - val_accuracy: 0.5070 - val_precision: 0.6379 - val_recall: 0.2606\n",
      "Epoch 76/200\n",
      "426/426 - 1s - loss: 1.0110 - accuracy: 0.6174 - precision: 0.7541 - recall: 0.4319 - val_loss: 1.2946 - val_accuracy: 0.4789 - val_precision: 0.5634 - val_recall: 0.2817\n",
      "Epoch 77/200\n",
      "426/426 - 1s - loss: 1.0279 - accuracy: 0.5892 - precision: 0.7468 - recall: 0.4085 - val_loss: 1.3079 - val_accuracy: 0.5000 - val_precision: 0.5789 - val_recall: 0.3099\n",
      "Epoch 78/200\n",
      "426/426 - 1s - loss: 1.0495 - accuracy: 0.5939 - precision: 0.6988 - recall: 0.4085 - val_loss: 1.6461 - val_accuracy: 0.4225 - val_precision: 0.4348 - val_recall: 0.2817\n",
      "Epoch 79/200\n",
      "426/426 - 1s - loss: 1.0483 - accuracy: 0.5939 - precision: 0.6882 - recall: 0.4249 - val_loss: 1.4329 - val_accuracy: 0.4155 - val_precision: 0.4828 - val_recall: 0.2958\n",
      "Epoch 80/200\n",
      "426/426 - 1s - loss: 1.0962 - accuracy: 0.5751 - precision: 0.6667 - recall: 0.3991 - val_loss: 1.2262 - val_accuracy: 0.4859 - val_precision: 0.5978 - val_recall: 0.3873\n",
      "Epoch 81/200\n",
      "426/426 - 1s - loss: 1.0733 - accuracy: 0.6033 - precision: 0.7082 - recall: 0.4272 - val_loss: 1.1598 - val_accuracy: 0.4718 - val_precision: 0.5647 - val_recall: 0.3380\n",
      "Epoch 82/200\n",
      "426/426 - 1s - loss: 0.9215 - accuracy: 0.6479 - precision: 0.7482 - recall: 0.4883 - val_loss: 1.5070 - val_accuracy: 0.4225 - val_precision: 0.4845 - val_recall: 0.3310\n",
      "Epoch 83/200\n",
      "426/426 - 1s - loss: 0.9189 - accuracy: 0.6385 - precision: 0.7368 - recall: 0.4930 - val_loss: 1.5078 - val_accuracy: 0.4296 - val_precision: 0.4839 - val_recall: 0.3169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/200\n",
      "426/426 - 1s - loss: 0.9321 - accuracy: 0.6268 - precision: 0.7299 - recall: 0.4695 - val_loss: 1.6370 - val_accuracy: 0.4437 - val_precision: 0.4433 - val_recall: 0.3028\n",
      "Epoch 85/200\n",
      "426/426 - 1s - loss: 1.0155 - accuracy: 0.5986 - precision: 0.7393 - recall: 0.4460 - val_loss: 1.0910 - val_accuracy: 0.5282 - val_precision: 0.7027 - val_recall: 0.3662\n",
      "Epoch 86/200\n",
      "426/426 - 1s - loss: 0.8817 - accuracy: 0.6502 - precision: 0.7579 - recall: 0.5070 - val_loss: 1.0845 - val_accuracy: 0.5282 - val_precision: 0.6875 - val_recall: 0.3873\n",
      "Epoch 87/200\n",
      "426/426 - 1s - loss: 0.8871 - accuracy: 0.6690 - precision: 0.7855 - recall: 0.5070 - val_loss: 1.1852 - val_accuracy: 0.5563 - val_precision: 0.6447 - val_recall: 0.3451\n",
      "Epoch 88/200\n",
      "426/426 - 1s - loss: 0.8741 - accuracy: 0.6408 - precision: 0.7849 - recall: 0.5141 - val_loss: 1.5231 - val_accuracy: 0.4225 - val_precision: 0.4563 - val_recall: 0.3310\n",
      "Epoch 89/200\n",
      "426/426 - 1s - loss: 0.8573 - accuracy: 0.6690 - precision: 0.7452 - recall: 0.5493 - val_loss: 1.0431 - val_accuracy: 0.5775 - val_precision: 0.7011 - val_recall: 0.4296\n",
      "Epoch 90/200\n",
      "426/426 - 1s - loss: 0.8056 - accuracy: 0.6831 - precision: 0.7595 - recall: 0.5634 - val_loss: 1.5020 - val_accuracy: 0.4507 - val_precision: 0.4956 - val_recall: 0.3944\n",
      "Epoch 91/200\n",
      "426/426 - 1s - loss: 0.8671 - accuracy: 0.6455 - precision: 0.7763 - recall: 0.5376 - val_loss: 1.1402 - val_accuracy: 0.5775 - val_precision: 0.6737 - val_recall: 0.4507\n",
      "Epoch 92/200\n",
      "426/426 - 1s - loss: 0.9713 - accuracy: 0.6408 - precision: 0.7129 - recall: 0.5188 - val_loss: 1.1706 - val_accuracy: 0.5352 - val_precision: 0.5913 - val_recall: 0.4789\n",
      "Epoch 93/200\n",
      "426/426 - 1s - loss: 0.7657 - accuracy: 0.7066 - precision: 0.7838 - recall: 0.6127 - val_loss: 1.3633 - val_accuracy: 0.4789 - val_precision: 0.5429 - val_recall: 0.4014\n",
      "Epoch 94/200\n",
      "426/426 - 1s - loss: 0.8346 - accuracy: 0.6596 - precision: 0.7763 - recall: 0.5540 - val_loss: 1.1062 - val_accuracy: 0.5211 - val_precision: 0.6854 - val_recall: 0.4296\n",
      "Epoch 95/200\n",
      "426/426 - 1s - loss: 0.7964 - accuracy: 0.6690 - precision: 0.8060 - recall: 0.5657 - val_loss: 1.2415 - val_accuracy: 0.5000 - val_precision: 0.6122 - val_recall: 0.4225\n",
      "Epoch 96/200\n",
      "426/426 - 1s - loss: 0.8144 - accuracy: 0.6737 - precision: 0.7763 - recall: 0.5540 - val_loss: 1.6414 - val_accuracy: 0.4155 - val_precision: 0.6308 - val_recall: 0.2887\n",
      "Epoch 97/200\n",
      "426/426 - 1s - loss: 0.8508 - accuracy: 0.6573 - precision: 0.8231 - recall: 0.5352 - val_loss: 1.1248 - val_accuracy: 0.5634 - val_precision: 0.6875 - val_recall: 0.4648\n",
      "Epoch 98/200\n",
      "426/426 - 1s - loss: 0.8306 - accuracy: 0.6690 - precision: 0.7781 - recall: 0.5845 - val_loss: 1.2222 - val_accuracy: 0.5634 - val_precision: 0.6020 - val_recall: 0.4155\n",
      "Epoch 99/200\n",
      "426/426 - 1s - loss: 0.7364 - accuracy: 0.6925 - precision: 0.7857 - recall: 0.6197 - val_loss: 1.5110 - val_accuracy: 0.5070 - val_precision: 0.5682 - val_recall: 0.3521\n",
      "Epoch 100/200\n",
      "426/426 - 1s - loss: 0.9192 - accuracy: 0.6479 - precision: 0.7384 - recall: 0.5235 - val_loss: 1.0932 - val_accuracy: 0.5704 - val_precision: 0.6809 - val_recall: 0.4507\n",
      "Epoch 101/200\n",
      "426/426 - 1s - loss: 0.7175 - accuracy: 0.6948 - precision: 0.8077 - recall: 0.5915 - val_loss: 1.2032 - val_accuracy: 0.5141 - val_precision: 0.5833 - val_recall: 0.4437\n",
      "Epoch 102/200\n",
      "426/426 - 1s - loss: 0.7583 - accuracy: 0.7254 - precision: 0.7923 - recall: 0.6268 - val_loss: 1.2178 - val_accuracy: 0.5211 - val_precision: 0.5727 - val_recall: 0.4437\n",
      "Epoch 103/200\n",
      "426/426 - 1s - loss: 0.7606 - accuracy: 0.7207 - precision: 0.7625 - recall: 0.6103 - val_loss: 1.1036 - val_accuracy: 0.5563 - val_precision: 0.5826 - val_recall: 0.4718\n",
      "Epoch 104/200\n",
      "426/426 - 1s - loss: 0.7263 - accuracy: 0.7136 - precision: 0.7756 - recall: 0.6408 - val_loss: 1.3456 - val_accuracy: 0.5070 - val_precision: 0.6211 - val_recall: 0.4155\n",
      "Epoch 105/200\n",
      "426/426 - 1s - loss: 0.7558 - accuracy: 0.7160 - precision: 0.7825 - recall: 0.6080 - val_loss: 1.1630 - val_accuracy: 0.5563 - val_precision: 0.6190 - val_recall: 0.4577\n",
      "Epoch 106/200\n",
      "426/426 - 1s - loss: 0.7277 - accuracy: 0.7324 - precision: 0.7861 - recall: 0.6643 - val_loss: 1.5333 - val_accuracy: 0.4930 - val_precision: 0.5130 - val_recall: 0.4155\n",
      "Epoch 107/200\n",
      "426/426 - 1s - loss: 0.6642 - accuracy: 0.7512 - precision: 0.8222 - recall: 0.6948 - val_loss: 1.0393 - val_accuracy: 0.5915 - val_precision: 0.7075 - val_recall: 0.5282\n",
      "Epoch 108/200\n",
      "426/426 - 1s - loss: 0.6495 - accuracy: 0.7465 - precision: 0.8085 - recall: 0.6737 - val_loss: 1.1917 - val_accuracy: 0.5845 - val_precision: 0.6337 - val_recall: 0.4507\n",
      "Epoch 109/200\n",
      "426/426 - 1s - loss: 0.6545 - accuracy: 0.7371 - precision: 0.8333 - recall: 0.6573 - val_loss: 1.1351 - val_accuracy: 0.5563 - val_precision: 0.6571 - val_recall: 0.4859\n",
      "Epoch 110/200\n",
      "426/426 - 1s - loss: 0.7446 - accuracy: 0.7207 - precision: 0.7918 - recall: 0.6338 - val_loss: 1.1223 - val_accuracy: 0.5915 - val_precision: 0.6569 - val_recall: 0.4718\n",
      "Epoch 111/200\n",
      "426/426 - 1s - loss: 0.6323 - accuracy: 0.7559 - precision: 0.8424 - recall: 0.6901 - val_loss: 1.1028 - val_accuracy: 0.5704 - val_precision: 0.6796 - val_recall: 0.4930\n",
      "Epoch 112/200\n",
      "426/426 - 1s - loss: 0.6790 - accuracy: 0.7394 - precision: 0.8257 - recall: 0.6338 - val_loss: 1.2501 - val_accuracy: 0.5915 - val_precision: 0.6311 - val_recall: 0.5423\n",
      "Epoch 113/200\n",
      "426/426 - 1s - loss: 0.6370 - accuracy: 0.7488 - precision: 0.8064 - recall: 0.7136 - val_loss: 1.3138 - val_accuracy: 0.5211 - val_precision: 0.5645 - val_recall: 0.4930\n",
      "Epoch 114/200\n",
      "426/426 - 1s - loss: 0.6580 - accuracy: 0.7441 - precision: 0.8055 - recall: 0.6901 - val_loss: 1.0071 - val_accuracy: 0.6408 - val_precision: 0.6949 - val_recall: 0.5775\n",
      "Epoch 115/200\n",
      "426/426 - 1s - loss: 0.7476 - accuracy: 0.7254 - precision: 0.7867 - recall: 0.6667 - val_loss: 1.1939 - val_accuracy: 0.5493 - val_precision: 0.6126 - val_recall: 0.4789\n",
      "Epoch 116/200\n",
      "426/426 - 1s - loss: 0.6504 - accuracy: 0.7300 - precision: 0.7973 - recall: 0.6831 - val_loss: 1.0277 - val_accuracy: 0.5845 - val_precision: 0.6333 - val_recall: 0.5352\n",
      "Epoch 117/200\n",
      "426/426 - 1s - loss: 0.5464 - accuracy: 0.8075 - precision: 0.8432 - recall: 0.7324 - val_loss: 0.9960 - val_accuracy: 0.6549 - val_precision: 0.6807 - val_recall: 0.5704\n",
      "Epoch 118/200\n",
      "426/426 - 1s - loss: 0.4972 - accuracy: 0.8099 - precision: 0.8476 - recall: 0.7441 - val_loss: 1.0291 - val_accuracy: 0.6338 - val_precision: 0.7009 - val_recall: 0.5282\n",
      "Epoch 119/200\n",
      "426/426 - 1s - loss: 0.5262 - accuracy: 0.7770 - precision: 0.8346 - recall: 0.7465 - val_loss: 1.7799 - val_accuracy: 0.5282 - val_precision: 0.5455 - val_recall: 0.4648\n",
      "Epoch 120/200\n",
      "426/426 - 1s - loss: 0.6362 - accuracy: 0.7746 - precision: 0.8421 - recall: 0.7136 - val_loss: 0.9802 - val_accuracy: 0.6127 - val_precision: 0.6557 - val_recall: 0.5634\n",
      "Epoch 121/200\n",
      "426/426 - 1s - loss: 0.5808 - accuracy: 0.7793 - precision: 0.8368 - recall: 0.7465 - val_loss: 1.2136 - val_accuracy: 0.5563 - val_precision: 0.6379 - val_recall: 0.5211\n",
      "Epoch 122/200\n",
      "426/426 - 1s - loss: 0.5019 - accuracy: 0.7840 - precision: 0.8382 - recall: 0.7418 - val_loss: 1.1128 - val_accuracy: 0.5775 - val_precision: 0.5938 - val_recall: 0.5352\n",
      "Epoch 123/200\n",
      "426/426 - 1s - loss: 0.6028 - accuracy: 0.7676 - precision: 0.7959 - recall: 0.7324 - val_loss: 1.6030 - val_accuracy: 0.5000 - val_precision: 0.5221 - val_recall: 0.4155\n",
      "Epoch 124/200\n",
      "426/426 - 1s - loss: 0.8269 - accuracy: 0.7254 - precision: 0.7636 - recall: 0.6596 - val_loss: 0.9988 - val_accuracy: 0.6408 - val_precision: 0.7037 - val_recall: 0.5352\n",
      "Epoch 125/200\n",
      "426/426 - 1s - loss: 0.5170 - accuracy: 0.7840 - precision: 0.8556 - recall: 0.7371 - val_loss: 1.2408 - val_accuracy: 0.5845 - val_precision: 0.6230 - val_recall: 0.5352\n",
      "Epoch 126/200\n",
      "426/426 - 1s - loss: 0.5470 - accuracy: 0.7864 - precision: 0.8351 - recall: 0.7488 - val_loss: 1.0202 - val_accuracy: 0.6620 - val_precision: 0.7025 - val_recall: 0.5986\n",
      "Epoch 127/200\n",
      "426/426 - 1s - loss: 0.5331 - accuracy: 0.8052 - precision: 0.8346 - recall: 0.7582 - val_loss: 1.3296 - val_accuracy: 0.5704 - val_precision: 0.6142 - val_recall: 0.5493\n",
      "Epoch 128/200\n",
      "426/426 - 1s - loss: 0.5038 - accuracy: 0.8005 - precision: 0.8228 - recall: 0.7629 - val_loss: 1.1938 - val_accuracy: 0.6268 - val_precision: 0.6613 - val_recall: 0.5775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/200\n",
      "426/426 - 1s - loss: 0.4854 - accuracy: 0.8286 - precision: 0.8651 - recall: 0.7981 - val_loss: 1.2575 - val_accuracy: 0.5493 - val_precision: 0.5656 - val_recall: 0.4859\n",
      "Epoch 130/200\n",
      "426/426 - 1s - loss: 0.5046 - accuracy: 0.8286 - precision: 0.8481 - recall: 0.7864 - val_loss: 1.1248 - val_accuracy: 0.6408 - val_precision: 0.6694 - val_recall: 0.5845\n",
      "Epoch 131/200\n",
      "426/426 - 1s - loss: 0.4021 - accuracy: 0.8474 - precision: 0.8830 - recall: 0.8146 - val_loss: 1.1216 - val_accuracy: 0.5915 - val_precision: 0.6124 - val_recall: 0.5563\n",
      "Epoch 132/200\n",
      "426/426 - 1s - loss: 0.5413 - accuracy: 0.8099 - precision: 0.8426 - recall: 0.7793 - val_loss: 2.1965 - val_accuracy: 0.4014 - val_precision: 0.4308 - val_recall: 0.3944\n",
      "Epoch 133/200\n",
      "426/426 - 1s - loss: 0.9231 - accuracy: 0.6901 - precision: 0.7880 - recall: 0.6455 - val_loss: 1.4708 - val_accuracy: 0.5282 - val_precision: 0.6327 - val_recall: 0.4366\n",
      "Epoch 134/200\n",
      "426/426 - 1s - loss: 0.5828 - accuracy: 0.7887 - precision: 0.8424 - recall: 0.6901 - val_loss: 1.4080 - val_accuracy: 0.5000 - val_precision: 0.5657 - val_recall: 0.3944\n",
      "Epoch 135/200\n",
      "426/426 - 1s - loss: 0.5618 - accuracy: 0.7817 - precision: 0.8383 - recall: 0.7300 - val_loss: 1.0895 - val_accuracy: 0.6268 - val_precision: 0.6783 - val_recall: 0.5493\n",
      "Epoch 136/200\n",
      "426/426 - 1s - loss: 0.3597 - accuracy: 0.8568 - precision: 0.8866 - recall: 0.8263 - val_loss: 1.5847 - val_accuracy: 0.5282 - val_precision: 0.5484 - val_recall: 0.4789\n",
      "Epoch 137/200\n",
      "426/426 - 1s - loss: 0.5484 - accuracy: 0.8357 - precision: 0.8568 - recall: 0.8146 - val_loss: 1.0567 - val_accuracy: 0.6549 - val_precision: 0.6929 - val_recall: 0.6197\n",
      "Epoch 138/200\n",
      "426/426 - 1s - loss: 0.6456 - accuracy: 0.7582 - precision: 0.7959 - recall: 0.7324 - val_loss: 1.3860 - val_accuracy: 0.5563 - val_precision: 0.6356 - val_recall: 0.5282\n",
      "Epoch 139/200\n",
      "426/426 - 1s - loss: 0.4947 - accuracy: 0.8122 - precision: 0.8575 - recall: 0.7911 - val_loss: 1.2375 - val_accuracy: 0.6338 - val_precision: 0.6746 - val_recall: 0.5986\n",
      "Epoch 140/200\n",
      "426/426 - 1s - loss: 0.4859 - accuracy: 0.8052 - precision: 0.8376 - recall: 0.7746 - val_loss: 1.1426 - val_accuracy: 0.6479 - val_precision: 0.6562 - val_recall: 0.5915\n",
      "Epoch 141/200\n",
      "426/426 - 1s - loss: 0.4106 - accuracy: 0.8498 - precision: 0.8628 - recall: 0.8122 - val_loss: 0.9888 - val_accuracy: 0.6901 - val_precision: 0.7167 - val_recall: 0.6056\n",
      "Epoch 142/200\n",
      "426/426 - 1s - loss: 0.4042 - accuracy: 0.8404 - precision: 0.8690 - recall: 0.8099 - val_loss: 1.4333 - val_accuracy: 0.5845 - val_precision: 0.5909 - val_recall: 0.5493\n",
      "Epoch 143/200\n",
      "426/426 - 1s - loss: 0.4263 - accuracy: 0.8521 - precision: 0.8750 - recall: 0.8380 - val_loss: 1.2996 - val_accuracy: 0.5915 - val_precision: 0.6441 - val_recall: 0.5352\n",
      "Epoch 144/200\n",
      "426/426 - 1s - loss: 0.4470 - accuracy: 0.8451 - precision: 0.8710 - recall: 0.8239 - val_loss: 1.0402 - val_accuracy: 0.6761 - val_precision: 0.6947 - val_recall: 0.6408\n",
      "Epoch 145/200\n",
      "426/426 - 1s - loss: 0.4006 - accuracy: 0.8357 - precision: 0.8589 - recall: 0.8146 - val_loss: 1.1207 - val_accuracy: 0.6690 - val_precision: 0.6905 - val_recall: 0.6127\n",
      "Epoch 146/200\n",
      "426/426 - 1s - loss: 0.3704 - accuracy: 0.8521 - precision: 0.8759 - recall: 0.8286 - val_loss: 1.1370 - val_accuracy: 0.6056 - val_precision: 0.6290 - val_recall: 0.5493\n",
      "Epoch 147/200\n",
      "426/426 - 1s - loss: 0.2874 - accuracy: 0.8944 - precision: 0.9095 - recall: 0.8732 - val_loss: 1.1420 - val_accuracy: 0.6972 - val_precision: 0.7029 - val_recall: 0.6831\n",
      "Epoch 148/200\n",
      "426/426 - 1s - loss: 0.4553 - accuracy: 0.8404 - precision: 0.8579 - recall: 0.8075 - val_loss: 0.9888 - val_accuracy: 0.7042 - val_precision: 0.7339 - val_recall: 0.6408\n",
      "Epoch 149/200\n",
      "426/426 - 1s - loss: 0.3291 - accuracy: 0.8732 - precision: 0.8873 - recall: 0.8685 - val_loss: 1.0901 - val_accuracy: 0.6761 - val_precision: 0.6929 - val_recall: 0.6197\n",
      "Epoch 150/200\n",
      "426/426 - 1s - loss: 0.4500 - accuracy: 0.8333 - precision: 0.8428 - recall: 0.8052 - val_loss: 1.0510 - val_accuracy: 0.6549 - val_precision: 0.6767 - val_recall: 0.6338\n",
      "Epoch 151/200\n",
      "426/426 - 1s - loss: 0.4306 - accuracy: 0.8404 - precision: 0.8512 - recall: 0.8192 - val_loss: 1.0659 - val_accuracy: 0.6620 - val_precision: 0.6593 - val_recall: 0.6268\n",
      "Epoch 152/200\n",
      "426/426 - 1s - loss: 0.3118 - accuracy: 0.8685 - precision: 0.8771 - recall: 0.8545 - val_loss: 1.3552 - val_accuracy: 0.6549 - val_precision: 0.6593 - val_recall: 0.6268\n",
      "Epoch 153/200\n",
      "426/426 - 1s - loss: 0.3898 - accuracy: 0.8709 - precision: 0.8848 - recall: 0.8474 - val_loss: 1.0830 - val_accuracy: 0.6901 - val_precision: 0.7121 - val_recall: 0.6620\n",
      "Epoch 154/200\n",
      "426/426 - 1s - loss: 0.2926 - accuracy: 0.9014 - precision: 0.9106 - recall: 0.8850 - val_loss: 1.2541 - val_accuracy: 0.6338 - val_precision: 0.6496 - val_recall: 0.6268\n",
      "Epoch 155/200\n",
      "426/426 - 1s - loss: 0.4723 - accuracy: 0.8263 - precision: 0.8386 - recall: 0.8052 - val_loss: 1.1910 - val_accuracy: 0.6761 - val_precision: 0.6912 - val_recall: 0.6620\n",
      "Epoch 156/200\n",
      "426/426 - 1s - loss: 0.3152 - accuracy: 0.8638 - precision: 0.8821 - recall: 0.8427 - val_loss: 1.1374 - val_accuracy: 0.6831 - val_precision: 0.6923 - val_recall: 0.6338\n",
      "Epoch 157/200\n",
      "426/426 - 1s - loss: 0.2598 - accuracy: 0.9014 - precision: 0.9153 - recall: 0.8873 - val_loss: 1.9332 - val_accuracy: 0.5352 - val_precision: 0.5530 - val_recall: 0.5141\n",
      "Epoch 158/200\n",
      "426/426 - 1s - loss: 0.5269 - accuracy: 0.8286 - precision: 0.8469 - recall: 0.8052 - val_loss: 1.3193 - val_accuracy: 0.6268 - val_precision: 0.6667 - val_recall: 0.6056\n",
      "Epoch 159/200\n",
      "426/426 - 1s - loss: 0.3650 - accuracy: 0.8850 - precision: 0.8924 - recall: 0.8568 - val_loss: 1.2437 - val_accuracy: 0.6127 - val_precision: 0.6194 - val_recall: 0.5845\n",
      "Epoch 160/200\n",
      "426/426 - 1s - loss: 0.2638 - accuracy: 0.9108 - precision: 0.9165 - recall: 0.9014 - val_loss: 1.2071 - val_accuracy: 0.6197 - val_precision: 0.6423 - val_recall: 0.6197\n",
      "Epoch 161/200\n",
      "426/426 - 1s - loss: 0.2741 - accuracy: 0.8967 - precision: 0.9019 - recall: 0.8850 - val_loss: 0.9991 - val_accuracy: 0.7183 - val_precision: 0.7111 - val_recall: 0.6761\n",
      "Epoch 162/200\n",
      "426/426 - 1s - loss: 0.4331 - accuracy: 0.8803 - precision: 0.8807 - recall: 0.8662 - val_loss: 1.3906 - val_accuracy: 0.5986 - val_precision: 0.6090 - val_recall: 0.5704\n",
      "Epoch 163/200\n",
      "426/426 - 1s - loss: 0.3232 - accuracy: 0.8873 - precision: 0.8947 - recall: 0.8779 - val_loss: 1.1609 - val_accuracy: 0.6549 - val_precision: 0.6667 - val_recall: 0.6338\n",
      "Epoch 164/200\n",
      "426/426 - 1s - loss: 0.2835 - accuracy: 0.9155 - precision: 0.9236 - recall: 0.9085 - val_loss: 1.2883 - val_accuracy: 0.6127 - val_precision: 0.6493 - val_recall: 0.6127\n",
      "Epoch 165/200\n",
      "426/426 - 1s - loss: 0.2745 - accuracy: 0.8991 - precision: 0.9091 - recall: 0.8920 - val_loss: 1.1705 - val_accuracy: 0.6408 - val_precision: 0.6444 - val_recall: 0.6127\n",
      "Epoch 166/200\n",
      "426/426 - 1s - loss: 0.3861 - accuracy: 0.8638 - precision: 0.8835 - recall: 0.8545 - val_loss: 1.0945 - val_accuracy: 0.6549 - val_precision: 0.6741 - val_recall: 0.6408\n",
      "Epoch 167/200\n",
      "426/426 - 1s - loss: 0.4170 - accuracy: 0.8638 - precision: 0.8744 - recall: 0.8498 - val_loss: 1.4942 - val_accuracy: 0.5986 - val_precision: 0.6074 - val_recall: 0.5775\n",
      "Epoch 168/200\n",
      "426/426 - 1s - loss: 0.2244 - accuracy: 0.9108 - precision: 0.9255 - recall: 0.9038 - val_loss: 1.0842 - val_accuracy: 0.7324 - val_precision: 0.7464 - val_recall: 0.7254\n",
      "Epoch 169/200\n",
      "426/426 - 1s - loss: 0.3246 - accuracy: 0.8826 - precision: 0.8876 - recall: 0.8709 - val_loss: 1.4164 - val_accuracy: 0.6338 - val_precision: 0.6418 - val_recall: 0.6056\n",
      "Epoch 170/200\n",
      "426/426 - 1s - loss: 0.2631 - accuracy: 0.9131 - precision: 0.9167 - recall: 0.9038 - val_loss: 1.4523 - val_accuracy: 0.5986 - val_precision: 0.6103 - val_recall: 0.5845\n",
      "Epoch 171/200\n",
      "426/426 - 1s - loss: 0.3111 - accuracy: 0.8944 - precision: 0.8998 - recall: 0.8850 - val_loss: 1.7090 - val_accuracy: 0.5282 - val_precision: 0.5407 - val_recall: 0.5141\n",
      "Epoch 172/200\n",
      "426/426 - 1s - loss: 0.5383 - accuracy: 0.8028 - precision: 0.8388 - recall: 0.7817 - val_loss: 1.5212 - val_accuracy: 0.5986 - val_precision: 0.6290 - val_recall: 0.5493\n",
      "Epoch 173/200\n",
      "426/426 - 1s - loss: 0.2487 - accuracy: 0.9061 - precision: 0.9380 - recall: 0.8873 - val_loss: 1.3384 - val_accuracy: 0.6620 - val_precision: 0.6642 - val_recall: 0.6268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/200\n",
      "426/426 - 1s - loss: 0.2074 - accuracy: 0.9343 - precision: 0.9349 - recall: 0.9108 - val_loss: 1.2248 - val_accuracy: 0.6690 - val_precision: 0.6812 - val_recall: 0.6620\n",
      "Epoch 175/200\n",
      "426/426 - 1s - loss: 0.2888 - accuracy: 0.9038 - precision: 0.9177 - recall: 0.8897 - val_loss: 1.0881 - val_accuracy: 0.6831 - val_precision: 0.7111 - val_recall: 0.6761\n",
      "Epoch 176/200\n",
      "426/426 - 1s - loss: 0.1771 - accuracy: 0.9366 - precision: 0.9381 - recall: 0.9249 - val_loss: 1.3312 - val_accuracy: 0.6338 - val_precision: 0.6617 - val_recall: 0.6197\n",
      "Epoch 177/200\n",
      "426/426 - 1s - loss: 0.3115 - accuracy: 0.9085 - precision: 0.9104 - recall: 0.9061 - val_loss: 1.1407 - val_accuracy: 0.6761 - val_precision: 0.7099 - val_recall: 0.6549\n",
      "Epoch 178/200\n",
      "426/426 - 1s - loss: 0.2895 - accuracy: 0.9038 - precision: 0.9139 - recall: 0.8967 - val_loss: 1.8818 - val_accuracy: 0.5070 - val_precision: 0.5037 - val_recall: 0.4789\n",
      "Epoch 179/200\n",
      "426/426 - 1s - loss: 0.3765 - accuracy: 0.8873 - precision: 0.8945 - recall: 0.8756 - val_loss: 1.2519 - val_accuracy: 0.6197 - val_precision: 0.6370 - val_recall: 0.6056\n",
      "Epoch 180/200\n",
      "426/426 - 1s - loss: 0.2010 - accuracy: 0.9343 - precision: 0.9384 - recall: 0.9296 - val_loss: 1.2192 - val_accuracy: 0.6338 - val_precision: 0.6565 - val_recall: 0.6056\n",
      "Epoch 181/200\n",
      "426/426 - 1s - loss: 0.1662 - accuracy: 0.9460 - precision: 0.9482 - recall: 0.9460 - val_loss: 1.2642 - val_accuracy: 0.6690 - val_precision: 0.6835 - val_recall: 0.6690\n",
      "Epoch 182/200\n",
      "426/426 - 1s - loss: 0.1413 - accuracy: 0.9531 - precision: 0.9595 - recall: 0.9460 - val_loss: 1.3294 - val_accuracy: 0.6338 - val_precision: 0.6496 - val_recall: 0.6268\n",
      "Epoch 183/200\n",
      "426/426 - 1s - loss: 0.3335 - accuracy: 0.8967 - precision: 0.9028 - recall: 0.8944 - val_loss: 1.3561 - val_accuracy: 0.6338 - val_precision: 0.6423 - val_recall: 0.6197\n",
      "Epoch 184/200\n",
      "426/426 - 1s - loss: 0.2160 - accuracy: 0.9249 - precision: 0.9356 - recall: 0.9202 - val_loss: 1.3631 - val_accuracy: 0.6549 - val_precision: 0.6767 - val_recall: 0.6338\n",
      "Epoch 185/200\n",
      "426/426 - 1s - loss: 0.1951 - accuracy: 0.9343 - precision: 0.9406 - recall: 0.9296 - val_loss: 1.4031 - val_accuracy: 0.5986 - val_precision: 0.6090 - val_recall: 0.5704\n",
      "Epoch 186/200\n",
      "426/426 - 1s - loss: 0.3697 - accuracy: 0.8756 - precision: 0.8886 - recall: 0.8615 - val_loss: 1.5460 - val_accuracy: 0.5845 - val_precision: 0.6029 - val_recall: 0.5775\n",
      "Epoch 187/200\n",
      "426/426 - 1s - loss: 0.2523 - accuracy: 0.9225 - precision: 0.9351 - recall: 0.9131 - val_loss: 1.2986 - val_accuracy: 0.6479 - val_precision: 0.6866 - val_recall: 0.6479\n",
      "Epoch 188/200\n",
      "426/426 - 1s - loss: 0.2940 - accuracy: 0.9061 - precision: 0.9119 - recall: 0.8991 - val_loss: 1.6485 - val_accuracy: 0.5845 - val_precision: 0.6136 - val_recall: 0.5704\n",
      "Epoch 189/200\n",
      "426/426 - 1s - loss: 0.2588 - accuracy: 0.8991 - precision: 0.9155 - recall: 0.8897 - val_loss: 1.3398 - val_accuracy: 0.6197 - val_precision: 0.6187 - val_recall: 0.6056\n",
      "Epoch 190/200\n",
      "426/426 - 1s - loss: 0.1421 - accuracy: 0.9554 - precision: 0.9619 - recall: 0.9484 - val_loss: 1.3681 - val_accuracy: 0.6690 - val_precision: 0.6739 - val_recall: 0.6549\n",
      "Epoch 191/200\n",
      "426/426 - 1s - loss: 0.2446 - accuracy: 0.9061 - precision: 0.9209 - recall: 0.9014 - val_loss: 1.2301 - val_accuracy: 0.6690 - val_precision: 0.6934 - val_recall: 0.6690\n",
      "Epoch 192/200\n",
      "426/426 - 1s - loss: 0.1865 - accuracy: 0.9319 - precision: 0.9338 - recall: 0.9272 - val_loss: 1.3320 - val_accuracy: 0.6761 - val_precision: 0.6934 - val_recall: 0.6690\n",
      "Epoch 193/200\n",
      "426/426 - 1s - loss: 0.2225 - accuracy: 0.9296 - precision: 0.9313 - recall: 0.9225 - val_loss: 1.5854 - val_accuracy: 0.5986 - val_precision: 0.6296 - val_recall: 0.5986\n",
      "Epoch 194/200\n",
      "426/426 - 1s - loss: 0.2219 - accuracy: 0.9249 - precision: 0.9314 - recall: 0.9249 - val_loss: 1.2987 - val_accuracy: 0.6479 - val_precision: 0.6691 - val_recall: 0.6408\n",
      "Epoch 195/200\n",
      "426/426 - 1s - loss: 0.2457 - accuracy: 0.9038 - precision: 0.9143 - recall: 0.9014 - val_loss: 1.3051 - val_accuracy: 0.6549 - val_precision: 0.6667 - val_recall: 0.6479\n",
      "Epoch 196/200\n",
      "426/426 - 1s - loss: 0.2862 - accuracy: 0.8991 - precision: 0.9084 - recall: 0.8850 - val_loss: 1.4266 - val_accuracy: 0.6338 - val_precision: 0.6350 - val_recall: 0.6127\n",
      "Epoch 197/200\n",
      "426/426 - 1s - loss: 0.1381 - accuracy: 0.9460 - precision: 0.9520 - recall: 0.9319 - val_loss: 1.6363 - val_accuracy: 0.5423 - val_precision: 0.5507 - val_recall: 0.5352\n",
      "Epoch 198/200\n",
      "426/426 - 1s - loss: 0.2353 - accuracy: 0.9178 - precision: 0.9240 - recall: 0.9131 - val_loss: 1.1723 - val_accuracy: 0.6972 - val_precision: 0.7174 - val_recall: 0.6972\n",
      "Epoch 199/200\n",
      "426/426 - 1s - loss: 0.2184 - accuracy: 0.9366 - precision: 0.9387 - recall: 0.9343 - val_loss: 1.3772 - val_accuracy: 0.6690 - val_precision: 0.6715 - val_recall: 0.6479\n",
      "Epoch 200/200\n",
      "426/426 - 1s - loss: 0.1150 - accuracy: 0.9554 - precision: 0.9598 - recall: 0.9531 - val_loss: 1.3891 - val_accuracy: 0.6268 - val_precision: 0.6286 - val_recall: 0.6197\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 192)          214272    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 128)          164352    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 192)          246528    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 128)          164352    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 96)                86400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1164      \n",
      "=================================================================\n",
      "Total params: 877,068\n",
      "Trainable params: 877,068\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "RMSprop\n",
      "\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/200\n",
      "426/426 - 17s - loss: 2.4183 - accuracy: 0.1385 - precision: 0.1667 - recall: 0.0070 - val_loss: 2.2758 - val_accuracy: 0.1549 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      "426/426 - 1s - loss: 2.1191 - accuracy: 0.1784 - precision: 0.1111 - recall: 0.0047 - val_loss: 2.3143 - val_accuracy: 0.1338 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/200\n",
      "426/426 - 1s - loss: 2.0814 - accuracy: 0.2066 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8260 - val_accuracy: 0.2817 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/200\n",
      "426/426 - 1s - loss: 1.9737 - accuracy: 0.2254 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9718 - val_accuracy: 0.2254 - val_precision: 0.7143 - val_recall: 0.0352\n",
      "Epoch 5/200\n",
      "426/426 - 1s - loss: 1.8897 - accuracy: 0.2371 - precision: 0.3333 - recall: 0.0047 - val_loss: 1.8648 - val_accuracy: 0.2254 - val_precision: 0.4667 - val_recall: 0.0493\n",
      "Epoch 6/200\n",
      "426/426 - 1s - loss: 1.8495 - accuracy: 0.2371 - precision: 0.5294 - recall: 0.0211 - val_loss: 1.8526 - val_accuracy: 0.2324 - val_precision: 0.2727 - val_recall: 0.0211\n",
      "Epoch 7/200\n",
      "426/426 - 1s - loss: 1.8301 - accuracy: 0.2418 - precision: 0.4615 - recall: 0.0141 - val_loss: 1.8081 - val_accuracy: 0.2676 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/200\n",
      "426/426 - 1s - loss: 1.8198 - accuracy: 0.2465 - precision: 0.5000 - recall: 0.0117 - val_loss: 1.7569 - val_accuracy: 0.2535 - val_precision: 0.5385 - val_recall: 0.0493\n",
      "Epoch 9/200\n",
      "426/426 - 1s - loss: 2.4603 - accuracy: 0.1362 - precision: 0.3333 - recall: 0.0047 - val_loss: 2.3947 - val_accuracy: 0.0915 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/200\n",
      "426/426 - 1s - loss: 2.1128 - accuracy: 0.1878 - precision: 0.2500 - recall: 0.0023 - val_loss: 1.8906 - val_accuracy: 0.1761 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/200\n",
      "426/426 - 1s - loss: 1.8373 - accuracy: 0.2207 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8360 - val_accuracy: 0.2042 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200\n",
      "426/426 - 1s - loss: 1.7944 - accuracy: 0.2981 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8430 - val_accuracy: 0.2042 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/200\n",
      "426/426 - 1s - loss: 1.7736 - accuracy: 0.2958 - precision: 0.4167 - recall: 0.0117 - val_loss: 2.0293 - val_accuracy: 0.2042 - val_precision: 1.0000 - val_recall: 0.0070\n",
      "Epoch 14/200\n",
      "426/426 - 1s - loss: 1.7635 - accuracy: 0.2958 - precision: 0.3571 - recall: 0.0235 - val_loss: 1.8822 - val_accuracy: 0.2676 - val_precision: 0.3333 - val_recall: 0.0141\n",
      "Epoch 15/200\n",
      "426/426 - 1s - loss: 1.7639 - accuracy: 0.2840 - precision: 0.2381 - recall: 0.0117 - val_loss: 2.0710 - val_accuracy: 0.1901 - val_precision: 0.1887 - val_recall: 0.0704\n",
      "Epoch 16/200\n",
      "426/426 - 1s - loss: 1.7741 - accuracy: 0.2653 - precision: 0.4706 - recall: 0.0376 - val_loss: 1.7466 - val_accuracy: 0.2394 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/200\n",
      "426/426 - 1s - loss: 1.7347 - accuracy: 0.2934 - precision: 0.2857 - recall: 0.0047 - val_loss: 1.8792 - val_accuracy: 0.2676 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/200\n",
      "426/426 - 1s - loss: 1.7405 - accuracy: 0.3122 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9523 - val_accuracy: 0.3028 - val_precision: 0.4667 - val_recall: 0.0493\n",
      "Epoch 19/200\n",
      "426/426 - 1s - loss: 1.7808 - accuracy: 0.2817 - precision: 0.4091 - recall: 0.0211 - val_loss: 1.6900 - val_accuracy: 0.3099 - val_precision: 0.6154 - val_recall: 0.0563\n",
      "Epoch 20/200\n",
      "426/426 - 1s - loss: 1.7613 - accuracy: 0.2488 - precision: 0.5714 - recall: 0.0188 - val_loss: 1.6881 - val_accuracy: 0.2958 - val_precision: 0.5714 - val_recall: 0.0845\n",
      "Epoch 21/200\n",
      "426/426 - 1s - loss: 1.7536 - accuracy: 0.2723 - precision: 0.4138 - recall: 0.0282 - val_loss: 1.7650 - val_accuracy: 0.2817 - val_precision: 0.3590 - val_recall: 0.0986\n",
      "Epoch 22/200\n",
      "426/426 - 1s - loss: 1.7096 - accuracy: 0.2770 - precision: 0.2647 - recall: 0.0211 - val_loss: 1.7442 - val_accuracy: 0.2394 - val_precision: 0.5455 - val_recall: 0.0845\n",
      "Epoch 23/200\n",
      "426/426 - 1s - loss: 1.6360 - accuracy: 0.3192 - precision: 0.4375 - recall: 0.0493 - val_loss: 1.7130 - val_accuracy: 0.3028 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/200\n",
      "426/426 - 1s - loss: 1.6737 - accuracy: 0.3028 - precision: 0.2500 - recall: 0.0070 - val_loss: 1.5723 - val_accuracy: 0.3310 - val_precision: 0.5385 - val_recall: 0.0986\n",
      "Epoch 25/200\n",
      "426/426 - 1s - loss: 1.6060 - accuracy: 0.3592 - precision: 0.5556 - recall: 0.0587 - val_loss: 1.7118 - val_accuracy: 0.3310 - val_precision: 0.5227 - val_recall: 0.1620\n",
      "Epoch 26/200\n",
      "426/426 - 1s - loss: 1.6260 - accuracy: 0.3310 - precision: 0.5571 - recall: 0.0915 - val_loss: 1.6421 - val_accuracy: 0.3099 - val_precision: 0.7333 - val_recall: 0.0775\n",
      "Epoch 27/200\n",
      "426/426 - 1s - loss: 1.5672 - accuracy: 0.3474 - precision: 0.6508 - recall: 0.0962 - val_loss: 1.7621 - val_accuracy: 0.3028 - val_precision: 1.0000 - val_recall: 0.0352\n",
      "Epoch 28/200\n",
      "426/426 - 1s - loss: 1.5307 - accuracy: 0.3592 - precision: 0.6071 - recall: 0.0798 - val_loss: 1.6453 - val_accuracy: 0.3451 - val_precision: 0.5769 - val_recall: 0.1056\n",
      "Epoch 29/200\n",
      "426/426 - 1s - loss: 1.5605 - accuracy: 0.3709 - precision: 0.5510 - recall: 0.1268 - val_loss: 2.0843 - val_accuracy: 0.2254 - val_precision: 0.3333 - val_recall: 0.0423\n",
      "Epoch 30/200\n",
      "426/426 - 1s - loss: 1.5579 - accuracy: 0.3803 - precision: 0.5432 - recall: 0.1033 - val_loss: 1.5447 - val_accuracy: 0.3662 - val_precision: 0.6562 - val_recall: 0.1479\n",
      "Epoch 31/200\n",
      "426/426 - 1s - loss: 1.5878 - accuracy: 0.3592 - precision: 0.5600 - recall: 0.0986 - val_loss: 1.5558 - val_accuracy: 0.3873 - val_precision: 0.8571 - val_recall: 0.0845\n",
      "Epoch 32/200\n",
      "426/426 - 1s - loss: 1.5393 - accuracy: 0.3732 - precision: 0.6029 - recall: 0.0962 - val_loss: 1.6931 - val_accuracy: 0.3451 - val_precision: 0.5938 - val_recall: 0.1338\n",
      "Epoch 33/200\n",
      "426/426 - 1s - loss: 1.6653 - accuracy: 0.3474 - precision: 0.4747 - recall: 0.1103 - val_loss: 1.6596 - val_accuracy: 0.2676 - val_precision: 0.4545 - val_recall: 0.0352\n",
      "Epoch 34/200\n",
      "426/426 - 1s - loss: 1.6657 - accuracy: 0.2770 - precision: 0.4412 - recall: 0.0352 - val_loss: 1.5717 - val_accuracy: 0.3592 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/200\n",
      "426/426 - 1s - loss: 1.6431 - accuracy: 0.3239 - precision: 0.5161 - recall: 0.0376 - val_loss: 1.8897 - val_accuracy: 0.1901 - val_precision: 0.4286 - val_recall: 0.0845\n",
      "Epoch 36/200\n",
      "426/426 - 1s - loss: 1.5864 - accuracy: 0.3592 - precision: 0.5000 - recall: 0.0587 - val_loss: 1.5603 - val_accuracy: 0.3592 - val_precision: 0.7143 - val_recall: 0.1408\n",
      "Epoch 37/200\n",
      "426/426 - 1s - loss: 1.5042 - accuracy: 0.3920 - precision: 0.6154 - recall: 0.1127 - val_loss: 1.4312 - val_accuracy: 0.3873 - val_precision: 0.7059 - val_recall: 0.1690\n",
      "Epoch 38/200\n",
      "426/426 - 1s - loss: 1.5538 - accuracy: 0.3779 - precision: 0.6023 - recall: 0.1244 - val_loss: 1.5002 - val_accuracy: 0.3873 - val_precision: 0.6000 - val_recall: 0.1268\n",
      "Epoch 39/200\n",
      "426/426 - 1s - loss: 1.5466 - accuracy: 0.3897 - precision: 0.5234 - recall: 0.1315 - val_loss: 1.4452 - val_accuracy: 0.4014 - val_precision: 0.6744 - val_recall: 0.2042\n",
      "Epoch 40/200\n",
      "426/426 - 1s - loss: 1.4851 - accuracy: 0.4108 - precision: 0.5319 - recall: 0.1174 - val_loss: 1.5473 - val_accuracy: 0.3662 - val_precision: 0.5500 - val_recall: 0.1549\n",
      "Epoch 41/200\n",
      "426/426 - 1s - loss: 1.5254 - accuracy: 0.3732 - precision: 0.5372 - recall: 0.1526 - val_loss: 1.7311 - val_accuracy: 0.3028 - val_precision: 0.4722 - val_recall: 0.1197\n",
      "Epoch 42/200\n",
      "426/426 - 1s - loss: 1.4438 - accuracy: 0.3991 - precision: 0.6092 - recall: 0.1244 - val_loss: 1.4565 - val_accuracy: 0.4225 - val_precision: 0.5833 - val_recall: 0.1972\n",
      "Epoch 43/200\n",
      "426/426 - 1s - loss: 1.4539 - accuracy: 0.4085 - precision: 0.6190 - recall: 0.1526 - val_loss: 1.7325 - val_accuracy: 0.2958 - val_precision: 0.5283 - val_recall: 0.1972\n",
      "Epoch 44/200\n",
      "426/426 - 1s - loss: 1.4495 - accuracy: 0.4131 - precision: 0.6047 - recall: 0.1831 - val_loss: 1.4266 - val_accuracy: 0.3803 - val_precision: 0.7083 - val_recall: 0.1197\n",
      "Epoch 45/200\n",
      "426/426 - 1s - loss: 1.4427 - accuracy: 0.3944 - precision: 0.6341 - recall: 0.1221 - val_loss: 1.4172 - val_accuracy: 0.4437 - val_precision: 0.6579 - val_recall: 0.1761\n",
      "Epoch 46/200\n",
      "426/426 - 1s - loss: 1.5431 - accuracy: 0.3944 - precision: 0.4095 - recall: 0.1009 - val_loss: 1.6407 - val_accuracy: 0.3662 - val_precision: 0.5278 - val_recall: 0.1338\n",
      "Epoch 47/200\n",
      "426/426 - 1s - loss: 1.4868 - accuracy: 0.4108 - precision: 0.6420 - recall: 0.1221 - val_loss: 1.5332 - val_accuracy: 0.3803 - val_precision: 0.6383 - val_recall: 0.2113\n",
      "Epoch 48/200\n",
      "426/426 - 1s - loss: 1.4225 - accuracy: 0.4366 - precision: 0.6412 - recall: 0.1972 - val_loss: 1.5576 - val_accuracy: 0.3944 - val_precision: 0.6316 - val_recall: 0.1690\n",
      "Epoch 49/200\n",
      "426/426 - 1s - loss: 1.4069 - accuracy: 0.4319 - precision: 0.6179 - recall: 0.1784 - val_loss: 1.5471 - val_accuracy: 0.3732 - val_precision: 0.6842 - val_recall: 0.0915\n",
      "Epoch 50/200\n",
      "426/426 - 1s - loss: 1.3634 - accuracy: 0.4577 - precision: 0.6729 - recall: 0.1690 - val_loss: 1.5428 - val_accuracy: 0.3521 - val_precision: 0.7391 - val_recall: 0.1197\n",
      "Epoch 51/200\n",
      "426/426 - 1s - loss: 1.3779 - accuracy: 0.4413 - precision: 0.6279 - recall: 0.1901 - val_loss: 1.7855 - val_accuracy: 0.2958 - val_precision: 0.5263 - val_recall: 0.1408\n",
      "Epoch 52/200\n",
      "426/426 - 1s - loss: 1.5015 - accuracy: 0.3967 - precision: 0.6371 - recall: 0.1854 - val_loss: 1.3648 - val_accuracy: 0.4437 - val_precision: 0.6724 - val_recall: 0.2746\n",
      "Epoch 53/200\n",
      "426/426 - 1s - loss: 1.3455 - accuracy: 0.4624 - precision: 0.6822 - recall: 0.2066 - val_loss: 1.5064 - val_accuracy: 0.4296 - val_precision: 0.6383 - val_recall: 0.2113\n",
      "Epoch 54/200\n",
      "426/426 - 1s - loss: 1.3363 - accuracy: 0.4718 - precision: 0.6667 - recall: 0.2019 - val_loss: 1.4830 - val_accuracy: 0.4507 - val_precision: 0.6383 - val_recall: 0.2113\n",
      "Epoch 55/200\n",
      "426/426 - 1s - loss: 1.2835 - accuracy: 0.4953 - precision: 0.6570 - recall: 0.2653 - val_loss: 1.6813 - val_accuracy: 0.3732 - val_precision: 0.5714 - val_recall: 0.2535\n",
      "Epoch 56/200\n",
      "426/426 - 1s - loss: 1.3998 - accuracy: 0.4577 - precision: 0.6154 - recall: 0.2254 - val_loss: 1.4589 - val_accuracy: 0.4437 - val_precision: 0.6444 - val_recall: 0.2042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "426/426 - 1s - loss: 1.2896 - accuracy: 0.4977 - precision: 0.6947 - recall: 0.2136 - val_loss: 1.6304 - val_accuracy: 0.3521 - val_precision: 0.5152 - val_recall: 0.1197\n",
      "Epoch 58/200\n",
      "426/426 - 1s - loss: 1.2245 - accuracy: 0.5282 - precision: 0.7192 - recall: 0.2465 - val_loss: 1.4826 - val_accuracy: 0.4366 - val_precision: 0.5806 - val_recall: 0.2535\n",
      "Epoch 59/200\n",
      "426/426 - 1s - loss: 1.3132 - accuracy: 0.4977 - precision: 0.6322 - recall: 0.2582 - val_loss: 1.4872 - val_accuracy: 0.3944 - val_precision: 0.5833 - val_recall: 0.1972\n",
      "Epoch 60/200\n",
      "426/426 - 1s - loss: 1.2389 - accuracy: 0.5070 - precision: 0.7133 - recall: 0.2512 - val_loss: 1.7804 - val_accuracy: 0.3592 - val_precision: 0.5079 - val_recall: 0.2254\n",
      "Epoch 61/200\n",
      "426/426 - 1s - loss: 1.2061 - accuracy: 0.5305 - precision: 0.6995 - recall: 0.3333 - val_loss: 1.3608 - val_accuracy: 0.4437 - val_precision: 0.5968 - val_recall: 0.2606\n",
      "Epoch 62/200\n",
      "426/426 - 1s - loss: 1.1821 - accuracy: 0.5610 - precision: 0.7173 - recall: 0.3216 - val_loss: 1.4526 - val_accuracy: 0.4577 - val_precision: 0.6029 - val_recall: 0.2887\n",
      "Epoch 63/200\n",
      "426/426 - 1s - loss: 1.3059 - accuracy: 0.5000 - precision: 0.6562 - recall: 0.2958 - val_loss: 1.4837 - val_accuracy: 0.4648 - val_precision: 0.6212 - val_recall: 0.2887\n",
      "Epoch 64/200\n",
      "426/426 - 1s - loss: 1.1678 - accuracy: 0.5446 - precision: 0.6847 - recall: 0.3568 - val_loss: 1.3205 - val_accuracy: 0.4930 - val_precision: 0.6375 - val_recall: 0.3592\n",
      "Epoch 65/200\n",
      "426/426 - 1s - loss: 1.1463 - accuracy: 0.5587 - precision: 0.7048 - recall: 0.3756 - val_loss: 1.7489 - val_accuracy: 0.2887 - val_precision: 0.4528 - val_recall: 0.1690\n",
      "Epoch 66/200\n",
      "426/426 - 1s - loss: 1.2101 - accuracy: 0.5164 - precision: 0.6869 - recall: 0.3192 - val_loss: 1.5378 - val_accuracy: 0.4155 - val_precision: 0.5000 - val_recall: 0.2183\n",
      "Epoch 67/200\n",
      "426/426 - 1s - loss: 1.2290 - accuracy: 0.5258 - precision: 0.7151 - recall: 0.3122 - val_loss: 1.6432 - val_accuracy: 0.3732 - val_precision: 0.5195 - val_recall: 0.2817\n",
      "Epoch 68/200\n",
      "426/426 - 1s - loss: 1.1285 - accuracy: 0.5563 - precision: 0.6598 - recall: 0.3779 - val_loss: 1.6734 - val_accuracy: 0.4085 - val_precision: 0.5333 - val_recall: 0.2254\n",
      "Epoch 69/200\n",
      "426/426 - 1s - loss: 1.1713 - accuracy: 0.5329 - precision: 0.6375 - recall: 0.3592 - val_loss: 1.4917 - val_accuracy: 0.4155 - val_precision: 0.5185 - val_recall: 0.2958\n",
      "Epoch 70/200\n",
      "426/426 - 1s - loss: 1.0966 - accuracy: 0.5563 - precision: 0.7257 - recall: 0.3850 - val_loss: 1.5789 - val_accuracy: 0.4507 - val_precision: 0.4951 - val_recall: 0.3592\n",
      "Epoch 71/200\n",
      "426/426 - 1s - loss: 1.0979 - accuracy: 0.5798 - precision: 0.7097 - recall: 0.4131 - val_loss: 1.3698 - val_accuracy: 0.4507 - val_precision: 0.5595 - val_recall: 0.3310\n",
      "Epoch 72/200\n",
      "426/426 - 1s - loss: 1.0156 - accuracy: 0.5869 - precision: 0.7023 - recall: 0.4319 - val_loss: 1.2631 - val_accuracy: 0.5211 - val_precision: 0.6250 - val_recall: 0.3873\n",
      "Epoch 73/200\n",
      "426/426 - 1s - loss: 1.1506 - accuracy: 0.5775 - precision: 0.6691 - recall: 0.4225 - val_loss: 1.3060 - val_accuracy: 0.5070 - val_precision: 0.6286 - val_recall: 0.3099\n",
      "Epoch 74/200\n",
      "426/426 - 1s - loss: 1.0627 - accuracy: 0.6033 - precision: 0.7184 - recall: 0.4131 - val_loss: 1.6334 - val_accuracy: 0.4225 - val_precision: 0.5000 - val_recall: 0.3380\n",
      "Epoch 75/200\n",
      "426/426 - 1s - loss: 1.0392 - accuracy: 0.5962 - precision: 0.7110 - recall: 0.4390 - val_loss: 1.3464 - val_accuracy: 0.4930 - val_precision: 0.5745 - val_recall: 0.3803\n",
      "Epoch 76/200\n",
      "426/426 - 1s - loss: 1.0118 - accuracy: 0.6009 - precision: 0.7089 - recall: 0.4859 - val_loss: 1.2455 - val_accuracy: 0.5070 - val_precision: 0.6452 - val_recall: 0.4225\n",
      "Epoch 77/200\n",
      "426/426 - 1s - loss: 1.1249 - accuracy: 0.5728 - precision: 0.6710 - recall: 0.4836 - val_loss: 1.5047 - val_accuracy: 0.4507 - val_precision: 0.5306 - val_recall: 0.3662\n",
      "Epoch 78/200\n",
      "426/426 - 1s - loss: 1.0305 - accuracy: 0.6009 - precision: 0.7528 - recall: 0.4789 - val_loss: 1.2959 - val_accuracy: 0.5352 - val_precision: 0.6203 - val_recall: 0.3451\n",
      "Epoch 79/200\n",
      "426/426 - 1s - loss: 1.0319 - accuracy: 0.6103 - precision: 0.7472 - recall: 0.4648 - val_loss: 1.2524 - val_accuracy: 0.5423 - val_precision: 0.5943 - val_recall: 0.4437\n",
      "Epoch 80/200\n",
      "426/426 - 1s - loss: 0.9756 - accuracy: 0.6127 - precision: 0.7167 - recall: 0.5047 - val_loss: 1.3343 - val_accuracy: 0.5282 - val_precision: 0.5876 - val_recall: 0.4014\n",
      "Epoch 81/200\n",
      "426/426 - 1s - loss: 0.9040 - accuracy: 0.6549 - precision: 0.7789 - recall: 0.5376 - val_loss: 1.2302 - val_accuracy: 0.5563 - val_precision: 0.6632 - val_recall: 0.4437\n",
      "Epoch 82/200\n",
      "426/426 - 1s - loss: 0.9737 - accuracy: 0.6009 - precision: 0.7092 - recall: 0.5094 - val_loss: 1.3793 - val_accuracy: 0.4648 - val_precision: 0.5870 - val_recall: 0.3803\n",
      "Epoch 83/200\n",
      "426/426 - 1s - loss: 0.9281 - accuracy: 0.6385 - precision: 0.7492 - recall: 0.5258 - val_loss: 1.3395 - val_accuracy: 0.4930 - val_precision: 0.5644 - val_recall: 0.4014\n",
      "Epoch 84/200\n",
      "426/426 - 1s - loss: 0.8428 - accuracy: 0.6737 - precision: 0.7616 - recall: 0.5775 - val_loss: 1.2410 - val_accuracy: 0.5000 - val_precision: 0.5789 - val_recall: 0.3873\n",
      "Epoch 85/200\n",
      "426/426 - 1s - loss: 0.8314 - accuracy: 0.6502 - precision: 0.7811 - recall: 0.5446 - val_loss: 1.2003 - val_accuracy: 0.5493 - val_precision: 0.6226 - val_recall: 0.4648\n",
      "Epoch 86/200\n",
      "426/426 - 1s - loss: 0.9271 - accuracy: 0.6221 - precision: 0.7217 - recall: 0.5235 - val_loss: 1.1894 - val_accuracy: 0.5000 - val_precision: 0.6196 - val_recall: 0.4014\n",
      "Epoch 87/200\n",
      "426/426 - 1s - loss: 0.8732 - accuracy: 0.6362 - precision: 0.7327 - recall: 0.5211 - val_loss: 1.1685 - val_accuracy: 0.5352 - val_precision: 0.6058 - val_recall: 0.4437\n",
      "Epoch 88/200\n",
      "426/426 - 1s - loss: 0.8603 - accuracy: 0.6737 - precision: 0.7680 - recall: 0.5516 - val_loss: 1.1577 - val_accuracy: 0.5634 - val_precision: 0.5826 - val_recall: 0.4718\n",
      "Epoch 89/200\n",
      "426/426 - 1s - loss: 0.8584 - accuracy: 0.6573 - precision: 0.7547 - recall: 0.5704 - val_loss: 1.3255 - val_accuracy: 0.5141 - val_precision: 0.5818 - val_recall: 0.4507\n",
      "Epoch 90/200\n",
      "426/426 - 1s - loss: 0.8424 - accuracy: 0.6901 - precision: 0.7784 - recall: 0.6268 - val_loss: 1.2916 - val_accuracy: 0.5423 - val_precision: 0.6222 - val_recall: 0.3944\n",
      "Epoch 91/200\n",
      "426/426 - 1s - loss: 0.8715 - accuracy: 0.6831 - precision: 0.7585 - recall: 0.5751 - val_loss: 1.3216 - val_accuracy: 0.4930 - val_precision: 0.6105 - val_recall: 0.4085\n",
      "Epoch 92/200\n",
      "426/426 - 1s - loss: 0.8456 - accuracy: 0.6831 - precision: 0.7660 - recall: 0.5610 - val_loss: 1.2401 - val_accuracy: 0.5423 - val_precision: 0.6531 - val_recall: 0.4507\n",
      "Epoch 93/200\n",
      "426/426 - 1s - loss: 0.7291 - accuracy: 0.7113 - precision: 0.7948 - recall: 0.6455 - val_loss: 1.2123 - val_accuracy: 0.6127 - val_precision: 0.6496 - val_recall: 0.5352\n",
      "Epoch 94/200\n",
      "426/426 - 1s - loss: 0.8695 - accuracy: 0.6737 - precision: 0.7768 - recall: 0.5962 - val_loss: 1.2038 - val_accuracy: 0.5775 - val_precision: 0.6505 - val_recall: 0.4718\n",
      "Epoch 95/200\n",
      "426/426 - 1s - loss: 0.7147 - accuracy: 0.7300 - precision: 0.7977 - recall: 0.6385 - val_loss: 1.7197 - val_accuracy: 0.4577 - val_precision: 0.5167 - val_recall: 0.4366\n",
      "Epoch 96/200\n",
      "426/426 - 1s - loss: 0.8370 - accuracy: 0.7042 - precision: 0.7562 - recall: 0.6408 - val_loss: 1.2999 - val_accuracy: 0.5704 - val_precision: 0.6316 - val_recall: 0.5070\n",
      "Epoch 97/200\n",
      "426/426 - 1s - loss: 0.7503 - accuracy: 0.7136 - precision: 0.7925 - recall: 0.6455 - val_loss: 1.1591 - val_accuracy: 0.5845 - val_precision: 0.6466 - val_recall: 0.5282\n",
      "Epoch 98/200\n",
      "426/426 - 1s - loss: 0.7479 - accuracy: 0.7136 - precision: 0.7966 - recall: 0.6526 - val_loss: 1.1588 - val_accuracy: 0.5563 - val_precision: 0.6449 - val_recall: 0.4859\n",
      "Epoch 99/200\n",
      "426/426 - 1s - loss: 0.6993 - accuracy: 0.7254 - precision: 0.8109 - recall: 0.6643 - val_loss: 1.2371 - val_accuracy: 0.5352 - val_precision: 0.5877 - val_recall: 0.4718\n",
      "Epoch 100/200\n",
      "426/426 - 1s - loss: 0.7360 - accuracy: 0.7160 - precision: 0.8047 - recall: 0.6479 - val_loss: 1.7879 - val_accuracy: 0.4859 - val_precision: 0.5000 - val_recall: 0.4366\n",
      "Epoch 101/200\n",
      "426/426 - 1s - loss: 0.8118 - accuracy: 0.7300 - precision: 0.7944 - recall: 0.6714 - val_loss: 1.2154 - val_accuracy: 0.6056 - val_precision: 0.6423 - val_recall: 0.5563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/200\n",
      "426/426 - 1s - loss: 0.6478 - accuracy: 0.7653 - precision: 0.8128 - recall: 0.6831 - val_loss: 1.2561 - val_accuracy: 0.5141 - val_precision: 0.5962 - val_recall: 0.4366\n",
      "Epoch 103/200\n",
      "426/426 - 1s - loss: 0.6942 - accuracy: 0.7300 - precision: 0.8045 - recall: 0.6761 - val_loss: 1.4462 - val_accuracy: 0.4789 - val_precision: 0.5607 - val_recall: 0.4225\n",
      "Epoch 104/200\n",
      "426/426 - 1s - loss: 0.6574 - accuracy: 0.7441 - precision: 0.8174 - recall: 0.6831 - val_loss: 1.4456 - val_accuracy: 0.5070 - val_precision: 0.5648 - val_recall: 0.4296\n",
      "Epoch 105/200\n",
      "426/426 - 1s - loss: 0.6594 - accuracy: 0.7394 - precision: 0.8179 - recall: 0.6643 - val_loss: 1.3165 - val_accuracy: 0.5070 - val_precision: 0.6036 - val_recall: 0.4718\n",
      "Epoch 106/200\n",
      "426/426 - 1s - loss: 0.7355 - accuracy: 0.7230 - precision: 0.8000 - recall: 0.6479 - val_loss: 1.1787 - val_accuracy: 0.5915 - val_precision: 0.6574 - val_recall: 0.5000\n",
      "Epoch 107/200\n",
      "426/426 - 1s - loss: 0.7479 - accuracy: 0.7394 - precision: 0.7983 - recall: 0.6784 - val_loss: 1.5319 - val_accuracy: 0.5070 - val_precision: 0.5431 - val_recall: 0.4437\n",
      "Epoch 108/200\n",
      "426/426 - 1s - loss: 0.7026 - accuracy: 0.7441 - precision: 0.8127 - recall: 0.6620 - val_loss: 1.0742 - val_accuracy: 0.6056 - val_precision: 0.7087 - val_recall: 0.5141\n",
      "Epoch 109/200\n",
      "426/426 - 1s - loss: 0.6294 - accuracy: 0.7840 - precision: 0.8376 - recall: 0.6901 - val_loss: 1.3099 - val_accuracy: 0.5775 - val_precision: 0.6087 - val_recall: 0.4930\n",
      "Epoch 110/200\n",
      "426/426 - 1s - loss: 0.5516 - accuracy: 0.7958 - precision: 0.8459 - recall: 0.7347 - val_loss: 1.0893 - val_accuracy: 0.5915 - val_precision: 0.6609 - val_recall: 0.5352\n",
      "Epoch 111/200\n",
      "426/426 - 1s - loss: 0.6875 - accuracy: 0.7629 - precision: 0.8194 - recall: 0.6925 - val_loss: 1.2480 - val_accuracy: 0.5423 - val_precision: 0.6283 - val_recall: 0.5000\n",
      "Epoch 112/200\n",
      "426/426 - 1s - loss: 0.6876 - accuracy: 0.7606 - precision: 0.8070 - recall: 0.7066 - val_loss: 1.1878 - val_accuracy: 0.5704 - val_precision: 0.6286 - val_recall: 0.4648\n",
      "Epoch 113/200\n",
      "426/426 - 1s - loss: 0.5080 - accuracy: 0.8075 - precision: 0.8537 - recall: 0.7394 - val_loss: 1.3978 - val_accuracy: 0.5986 - val_precision: 0.6210 - val_recall: 0.5423\n",
      "Epoch 114/200\n",
      "426/426 - 1s - loss: 0.5004 - accuracy: 0.8169 - precision: 0.8504 - recall: 0.7606 - val_loss: 1.2759 - val_accuracy: 0.5845 - val_precision: 0.5920 - val_recall: 0.5211\n",
      "Epoch 115/200\n",
      "426/426 - 1s - loss: 0.7703 - accuracy: 0.7418 - precision: 0.7739 - recall: 0.6831 - val_loss: 1.4382 - val_accuracy: 0.4859 - val_precision: 0.5446 - val_recall: 0.4296\n",
      "Epoch 116/200\n",
      "426/426 - 1s - loss: 0.7042 - accuracy: 0.7394 - precision: 0.8022 - recall: 0.6948 - val_loss: 1.2618 - val_accuracy: 0.5493 - val_precision: 0.6509 - val_recall: 0.4859\n",
      "Epoch 117/200\n",
      "426/426 - 1s - loss: 0.5431 - accuracy: 0.7934 - precision: 0.8254 - recall: 0.7324 - val_loss: 1.2326 - val_accuracy: 0.5845 - val_precision: 0.6283 - val_recall: 0.5000\n",
      "Epoch 118/200\n",
      "426/426 - 1s - loss: 0.6040 - accuracy: 0.7676 - precision: 0.8143 - recall: 0.7207 - val_loss: 1.8568 - val_accuracy: 0.4225 - val_precision: 0.4951 - val_recall: 0.3592\n",
      "Epoch 119/200\n",
      "426/426 - 1s - loss: 0.6422 - accuracy: 0.7746 - precision: 0.8384 - recall: 0.7066 - val_loss: 1.1573 - val_accuracy: 0.5845 - val_precision: 0.6667 - val_recall: 0.4930\n",
      "Epoch 120/200\n",
      "426/426 - 1s - loss: 0.5139 - accuracy: 0.8239 - precision: 0.8617 - recall: 0.7606 - val_loss: 1.4876 - val_accuracy: 0.5000 - val_precision: 0.5366 - val_recall: 0.4648\n",
      "Epoch 121/200\n",
      "426/426 - 1s - loss: 0.5602 - accuracy: 0.8005 - precision: 0.8360 - recall: 0.7418 - val_loss: 1.0975 - val_accuracy: 0.5775 - val_precision: 0.6441 - val_recall: 0.5352\n",
      "Epoch 122/200\n",
      "426/426 - 1s - loss: 0.4463 - accuracy: 0.8286 - precision: 0.8648 - recall: 0.7958 - val_loss: 1.3708 - val_accuracy: 0.5493 - val_precision: 0.5691 - val_recall: 0.4930\n",
      "Epoch 123/200\n",
      "426/426 - 1s - loss: 0.4654 - accuracy: 0.7934 - precision: 0.8367 - recall: 0.7700 - val_loss: 1.2464 - val_accuracy: 0.5986 - val_precision: 0.6333 - val_recall: 0.5352\n",
      "Epoch 124/200\n",
      "426/426 - 1s - loss: 0.4824 - accuracy: 0.8263 - precision: 0.8601 - recall: 0.7793 - val_loss: 1.4050 - val_accuracy: 0.5634 - val_precision: 0.6154 - val_recall: 0.5070\n",
      "Epoch 125/200\n",
      "426/426 - 1s - loss: 0.4684 - accuracy: 0.8286 - precision: 0.8553 - recall: 0.7770 - val_loss: 1.5834 - val_accuracy: 0.5282 - val_precision: 0.5763 - val_recall: 0.4789\n",
      "Epoch 126/200\n",
      "426/426 - 1s - loss: 0.5518 - accuracy: 0.8146 - precision: 0.8553 - recall: 0.7911 - val_loss: 1.2050 - val_accuracy: 0.6479 - val_precision: 0.6885 - val_recall: 0.5915\n",
      "Epoch 127/200\n",
      "426/426 - 1s - loss: 0.3702 - accuracy: 0.8615 - precision: 0.9023 - recall: 0.8239 - val_loss: 1.2837 - val_accuracy: 0.6127 - val_precision: 0.6610 - val_recall: 0.5493\n",
      "Epoch 128/200\n",
      "426/426 - 1s - loss: 0.4300 - accuracy: 0.8638 - precision: 0.8772 - recall: 0.8216 - val_loss: 1.6182 - val_accuracy: 0.5282 - val_precision: 0.5798 - val_recall: 0.4859\n",
      "Epoch 129/200\n",
      "426/426 - 1s - loss: 0.4559 - accuracy: 0.8239 - precision: 0.8485 - recall: 0.7887 - val_loss: 1.6628 - val_accuracy: 0.5000 - val_precision: 0.5308 - val_recall: 0.4859\n",
      "Epoch 130/200\n",
      "426/426 - 1s - loss: 0.4697 - accuracy: 0.8427 - precision: 0.8568 - recall: 0.8146 - val_loss: 1.7571 - val_accuracy: 0.4930 - val_precision: 0.5285 - val_recall: 0.4577\n",
      "Epoch 131/200\n",
      "426/426 - 1s - loss: 0.3972 - accuracy: 0.8545 - precision: 0.8753 - recall: 0.8239 - val_loss: 1.1962 - val_accuracy: 0.6268 - val_precision: 0.6508 - val_recall: 0.5775\n",
      "Epoch 132/200\n",
      "426/426 - 1s - loss: 0.4369 - accuracy: 0.8474 - precision: 0.8643 - recall: 0.8075 - val_loss: 1.2470 - val_accuracy: 0.6338 - val_precision: 0.6694 - val_recall: 0.5845\n",
      "Epoch 133/200\n",
      "426/426 - 1s - loss: 0.3883 - accuracy: 0.8662 - precision: 0.8878 - recall: 0.8357 - val_loss: 1.3488 - val_accuracy: 0.5986 - val_precision: 0.6423 - val_recall: 0.5563\n",
      "Epoch 134/200\n",
      "426/426 - 1s - loss: 0.4145 - accuracy: 0.8732 - precision: 0.8911 - recall: 0.8451 - val_loss: 1.4248 - val_accuracy: 0.5775 - val_precision: 0.6218 - val_recall: 0.5211\n",
      "Epoch 135/200\n",
      "426/426 - 1s - loss: 0.4271 - accuracy: 0.8498 - precision: 0.8722 - recall: 0.8169 - val_loss: 1.4471 - val_accuracy: 0.5704 - val_precision: 0.6111 - val_recall: 0.5423\n",
      "Epoch 136/200\n",
      "426/426 - 1s - loss: 0.4294 - accuracy: 0.8521 - precision: 0.8722 - recall: 0.8169 - val_loss: 1.2580 - val_accuracy: 0.6268 - val_precision: 0.6693 - val_recall: 0.5986\n",
      "Epoch 137/200\n",
      "426/426 - 1s - loss: 0.4297 - accuracy: 0.8592 - precision: 0.8734 - recall: 0.8263 - val_loss: 1.3451 - val_accuracy: 0.5634 - val_precision: 0.5669 - val_recall: 0.5070\n",
      "Epoch 138/200\n",
      "426/426 - 1s - loss: 0.3711 - accuracy: 0.8638 - precision: 0.8931 - recall: 0.8239 - val_loss: 1.3107 - val_accuracy: 0.6127 - val_precision: 0.6667 - val_recall: 0.5915\n",
      "Epoch 139/200\n",
      "426/426 - 1s - loss: 0.3669 - accuracy: 0.8732 - precision: 0.8966 - recall: 0.8545 - val_loss: 1.5738 - val_accuracy: 0.5563 - val_precision: 0.5878 - val_recall: 0.5423\n",
      "Epoch 140/200\n",
      "426/426 - 1s - loss: 0.3199 - accuracy: 0.8873 - precision: 0.9075 - recall: 0.8521 - val_loss: 1.8114 - val_accuracy: 0.5352 - val_precision: 0.5360 - val_recall: 0.4718\n",
      "Epoch 141/200\n",
      "426/426 - 1s - loss: 0.4343 - accuracy: 0.8521 - precision: 0.8691 - recall: 0.8263 - val_loss: 1.4131 - val_accuracy: 0.6127 - val_precision: 0.6250 - val_recall: 0.5634\n",
      "Epoch 142/200\n",
      "426/426 - 1s - loss: 0.2727 - accuracy: 0.9014 - precision: 0.9254 - recall: 0.8732 - val_loss: 1.6933 - val_accuracy: 0.5282 - val_precision: 0.5639 - val_recall: 0.5282\n",
      "Epoch 143/200\n",
      "426/426 - 1s - loss: 0.3812 - accuracy: 0.8592 - precision: 0.8861 - recall: 0.8404 - val_loss: 1.5562 - val_accuracy: 0.5845 - val_precision: 0.6220 - val_recall: 0.5563\n",
      "Epoch 144/200\n",
      "426/426 - 1s - loss: 0.2734 - accuracy: 0.9014 - precision: 0.9135 - recall: 0.8920 - val_loss: 1.3152 - val_accuracy: 0.5845 - val_precision: 0.6090 - val_recall: 0.5704\n",
      "Epoch 145/200\n",
      "426/426 - 1s - loss: 0.4368 - accuracy: 0.8474 - precision: 0.8713 - recall: 0.8263 - val_loss: 1.3121 - val_accuracy: 0.6056 - val_precision: 0.6452 - val_recall: 0.5634\n",
      "Epoch 146/200\n",
      "426/426 - 1s - loss: 0.2603 - accuracy: 0.9038 - precision: 0.9267 - recall: 0.8897 - val_loss: 1.4976 - val_accuracy: 0.5704 - val_precision: 0.6124 - val_recall: 0.5563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/200\n",
      "426/426 - 1s - loss: 0.3567 - accuracy: 0.8779 - precision: 0.8905 - recall: 0.8592 - val_loss: 1.2597 - val_accuracy: 0.6197 - val_precision: 0.6538 - val_recall: 0.5986\n",
      "Epoch 148/200\n",
      "426/426 - 1s - loss: 0.3385 - accuracy: 0.8850 - precision: 0.9134 - recall: 0.8662 - val_loss: 1.4854 - val_accuracy: 0.5915 - val_precision: 0.6045 - val_recall: 0.5704\n",
      "Epoch 149/200\n",
      "426/426 - 1s - loss: 0.2596 - accuracy: 0.9155 - precision: 0.9274 - recall: 0.8991 - val_loss: 1.5579 - val_accuracy: 0.5845 - val_precision: 0.6165 - val_recall: 0.5775\n",
      "Epoch 150/200\n",
      "426/426 - 1s - loss: 0.2300 - accuracy: 0.9202 - precision: 0.9308 - recall: 0.9155 - val_loss: 1.5880 - val_accuracy: 0.5915 - val_precision: 0.6061 - val_recall: 0.5634\n",
      "Epoch 151/200\n",
      "426/426 - 1s - loss: 0.3335 - accuracy: 0.8873 - precision: 0.9138 - recall: 0.8709 - val_loss: 1.5649 - val_accuracy: 0.5704 - val_precision: 0.5970 - val_recall: 0.5634\n",
      "Epoch 152/200\n",
      "426/426 - 1s - loss: 0.3401 - accuracy: 0.8756 - precision: 0.8849 - recall: 0.8662 - val_loss: 1.4970 - val_accuracy: 0.6338 - val_precision: 0.6471 - val_recall: 0.6197\n",
      "Epoch 153/200\n",
      "426/426 - 1s - loss: 0.2386 - accuracy: 0.9272 - precision: 0.9375 - recall: 0.9155 - val_loss: 1.3878 - val_accuracy: 0.6127 - val_precision: 0.6103 - val_recall: 0.5845\n",
      "Epoch 154/200\n",
      "426/426 - 1s - loss: 0.2742 - accuracy: 0.8991 - precision: 0.9157 - recall: 0.8920 - val_loss: 1.3914 - val_accuracy: 0.5986 - val_precision: 0.6090 - val_recall: 0.5704\n",
      "Epoch 155/200\n",
      "426/426 - 1s - loss: 0.2117 - accuracy: 0.9272 - precision: 0.9370 - recall: 0.9085 - val_loss: 1.3699 - val_accuracy: 0.5845 - val_precision: 0.5870 - val_recall: 0.5704\n",
      "Epoch 156/200\n",
      "426/426 - 1s - loss: 0.3115 - accuracy: 0.8944 - precision: 0.9041 - recall: 0.8850 - val_loss: 1.3511 - val_accuracy: 0.6620 - val_precision: 0.6788 - val_recall: 0.6549\n",
      "Epoch 157/200\n",
      "426/426 - 1s - loss: 0.3327 - accuracy: 0.8826 - precision: 0.8900 - recall: 0.8732 - val_loss: 1.4123 - val_accuracy: 0.6197 - val_precision: 0.6641 - val_recall: 0.5986\n",
      "Epoch 158/200\n",
      "426/426 - 1s - loss: 0.1709 - accuracy: 0.9390 - precision: 0.9448 - recall: 0.9249 - val_loss: 1.8097 - val_accuracy: 0.5282 - val_precision: 0.5625 - val_recall: 0.5070\n",
      "Epoch 159/200\n",
      "426/426 - 1s - loss: 0.2658 - accuracy: 0.9319 - precision: 0.9333 - recall: 0.9202 - val_loss: 1.6733 - val_accuracy: 0.5775 - val_precision: 0.5940 - val_recall: 0.5563\n",
      "Epoch 160/200\n",
      "426/426 - 1s - loss: 0.2175 - accuracy: 0.9225 - precision: 0.9330 - recall: 0.9155 - val_loss: 1.4513 - val_accuracy: 0.5986 - val_precision: 0.6058 - val_recall: 0.5845\n",
      "Epoch 161/200\n",
      "426/426 - 1s - loss: 0.2951 - accuracy: 0.9225 - precision: 0.9284 - recall: 0.9131 - val_loss: 1.4215 - val_accuracy: 0.6479 - val_precision: 0.6569 - val_recall: 0.6338\n",
      "Epoch 162/200\n",
      "426/426 - 1s - loss: 0.2377 - accuracy: 0.9225 - precision: 0.9286 - recall: 0.9155 - val_loss: 1.6766 - val_accuracy: 0.5352 - val_precision: 0.5649 - val_recall: 0.5211\n",
      "Epoch 163/200\n",
      "426/426 - 1s - loss: 0.2612 - accuracy: 0.9085 - precision: 0.9169 - recall: 0.9061 - val_loss: 1.5106 - val_accuracy: 0.6056 - val_precision: 0.6058 - val_recall: 0.5845\n",
      "Epoch 164/200\n",
      "426/426 - 1s - loss: 0.1544 - accuracy: 0.9507 - precision: 0.9550 - recall: 0.9460 - val_loss: 1.5617 - val_accuracy: 0.6056 - val_precision: 0.6131 - val_recall: 0.5915\n",
      "Epoch 165/200\n",
      "426/426 - 1s - loss: 0.2518 - accuracy: 0.9225 - precision: 0.9284 - recall: 0.9131 - val_loss: 1.8230 - val_accuracy: 0.5352 - val_precision: 0.5474 - val_recall: 0.5282\n",
      "Epoch 166/200\n",
      "426/426 - 1s - loss: 0.2752 - accuracy: 0.9131 - precision: 0.9253 - recall: 0.9014 - val_loss: 1.5907 - val_accuracy: 0.6127 - val_precision: 0.6316 - val_recall: 0.5915\n",
      "Epoch 167/200\n",
      "426/426 - 1s - loss: 0.3160 - accuracy: 0.8920 - precision: 0.8990 - recall: 0.8779 - val_loss: 1.6641 - val_accuracy: 0.5704 - val_precision: 0.6000 - val_recall: 0.5704\n",
      "Epoch 168/200\n",
      "426/426 - 1s - loss: 0.2573 - accuracy: 0.9155 - precision: 0.9258 - recall: 0.9085 - val_loss: 1.6704 - val_accuracy: 0.5915 - val_precision: 0.6029 - val_recall: 0.5775\n",
      "Epoch 169/200\n",
      "426/426 - 1s - loss: 0.2230 - accuracy: 0.9390 - precision: 0.9454 - recall: 0.9343 - val_loss: 1.6426 - val_accuracy: 0.6197 - val_precision: 0.6204 - val_recall: 0.5986\n",
      "Epoch 170/200\n",
      "426/426 - 1s - loss: 0.2619 - accuracy: 0.9108 - precision: 0.9231 - recall: 0.9014 - val_loss: 1.4601 - val_accuracy: 0.6620 - val_precision: 0.6691 - val_recall: 0.6408\n",
      "Epoch 171/200\n",
      "426/426 - 1s - loss: 0.1110 - accuracy: 0.9671 - precision: 0.9692 - recall: 0.9601 - val_loss: 1.6357 - val_accuracy: 0.5915 - val_precision: 0.6136 - val_recall: 0.5704\n",
      "Epoch 172/200\n",
      "426/426 - 1s - loss: 0.1205 - accuracy: 0.9601 - precision: 0.9624 - recall: 0.9601 - val_loss: 1.8764 - val_accuracy: 0.6127 - val_precision: 0.6187 - val_recall: 0.6056\n",
      "Epoch 173/200\n",
      "426/426 - 1s - loss: 0.2584 - accuracy: 0.9061 - precision: 0.9167 - recall: 0.9038 - val_loss: 1.7656 - val_accuracy: 0.5915 - val_precision: 0.6107 - val_recall: 0.5634\n",
      "Epoch 174/200\n",
      "426/426 - 1s - loss: 0.2305 - accuracy: 0.9272 - precision: 0.9420 - recall: 0.9155 - val_loss: 1.6964 - val_accuracy: 0.5845 - val_precision: 0.6015 - val_recall: 0.5634\n",
      "Epoch 175/200\n",
      "426/426 - 1s - loss: 0.1467 - accuracy: 0.9671 - precision: 0.9691 - recall: 0.9577 - val_loss: 2.0638 - val_accuracy: 0.5352 - val_precision: 0.5515 - val_recall: 0.5282\n",
      "Epoch 176/200\n",
      "426/426 - 1s - loss: 0.1826 - accuracy: 0.9296 - precision: 0.9382 - recall: 0.9272 - val_loss: 1.9019 - val_accuracy: 0.5704 - val_precision: 0.5693 - val_recall: 0.5493\n",
      "Epoch 177/200\n",
      "426/426 - 1s - loss: 0.3519 - accuracy: 0.8944 - precision: 0.9002 - recall: 0.8897 - val_loss: 1.9210 - val_accuracy: 0.5563 - val_precision: 0.5758 - val_recall: 0.5352\n",
      "Epoch 178/200\n",
      "426/426 - 1s - loss: 0.3174 - accuracy: 0.9061 - precision: 0.9141 - recall: 0.8991 - val_loss: 1.6433 - val_accuracy: 0.5986 - val_precision: 0.6194 - val_recall: 0.5845\n",
      "Epoch 179/200\n",
      "426/426 - 1s - loss: 0.2525 - accuracy: 0.9178 - precision: 0.9220 - recall: 0.9155 - val_loss: 1.9048 - val_accuracy: 0.5634 - val_precision: 0.5704 - val_recall: 0.5423\n",
      "Epoch 180/200\n",
      "426/426 - 1s - loss: 0.2288 - accuracy: 0.9178 - precision: 0.9262 - recall: 0.9131 - val_loss: 1.5489 - val_accuracy: 0.6338 - val_precision: 0.6544 - val_recall: 0.6268\n",
      "Epoch 181/200\n",
      "426/426 - 1s - loss: 0.2291 - accuracy: 0.9225 - precision: 0.9260 - recall: 0.9108 - val_loss: 1.5833 - val_accuracy: 0.6197 - val_precision: 0.6214 - val_recall: 0.6127\n",
      "Epoch 182/200\n",
      "426/426 - 1s - loss: 0.1609 - accuracy: 0.9624 - precision: 0.9646 - recall: 0.9601 - val_loss: 1.4159 - val_accuracy: 0.6479 - val_precision: 0.6667 - val_recall: 0.6197\n",
      "Epoch 183/200\n",
      "426/426 - 1s - loss: 0.1778 - accuracy: 0.9577 - precision: 0.9598 - recall: 0.9531 - val_loss: 1.4650 - val_accuracy: 0.6620 - val_precision: 0.6838 - val_recall: 0.6549\n",
      "Epoch 184/200\n",
      "426/426 - 1s - loss: 0.3279 - accuracy: 0.9038 - precision: 0.9048 - recall: 0.8920 - val_loss: 1.6349 - val_accuracy: 0.6127 - val_precision: 0.6212 - val_recall: 0.5775\n",
      "Epoch 185/200\n",
      "426/426 - 1s - loss: 0.1682 - accuracy: 0.9484 - precision: 0.9547 - recall: 0.9390 - val_loss: 1.8591 - val_accuracy: 0.5845 - val_precision: 0.6136 - val_recall: 0.5704\n",
      "Epoch 186/200\n",
      "426/426 - 1s - loss: 0.2172 - accuracy: 0.9366 - precision: 0.9406 - recall: 0.9296 - val_loss: 1.8591 - val_accuracy: 0.5493 - val_precision: 0.5620 - val_recall: 0.5423\n",
      "Epoch 187/200\n",
      "426/426 - 1s - loss: 0.1631 - accuracy: 0.9507 - precision: 0.9573 - recall: 0.9484 - val_loss: 2.2444 - val_accuracy: 0.4859 - val_precision: 0.5036 - val_recall: 0.4859\n",
      "Epoch 188/200\n",
      "426/426 - 1s - loss: 0.2287 - accuracy: 0.9413 - precision: 0.9410 - recall: 0.9366 - val_loss: 1.7864 - val_accuracy: 0.5915 - val_precision: 0.5956 - val_recall: 0.5704\n",
      "Epoch 189/200\n",
      "426/426 - 1s - loss: 0.1419 - accuracy: 0.9624 - precision: 0.9646 - recall: 0.9601 - val_loss: 1.4923 - val_accuracy: 0.6268 - val_precision: 0.6370 - val_recall: 0.6056\n",
      "Epoch 190/200\n",
      "426/426 - 1s - loss: 0.1459 - accuracy: 0.9554 - precision: 0.9575 - recall: 0.9531 - val_loss: 1.5070 - val_accuracy: 0.6408 - val_precision: 0.6429 - val_recall: 0.6338\n",
      "Epoch 191/200\n",
      "426/426 - 1s - loss: 0.0661 - accuracy: 0.9789 - precision: 0.9835 - recall: 0.9789 - val_loss: 1.6811 - val_accuracy: 0.6338 - val_precision: 0.6277 - val_recall: 0.6056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/200\n",
      "426/426 - 1s - loss: 0.2744 - accuracy: 0.9296 - precision: 0.9338 - recall: 0.9272 - val_loss: 1.4851 - val_accuracy: 0.6620 - val_precision: 0.6815 - val_recall: 0.6479\n",
      "Epoch 193/200\n",
      "426/426 - 1s - loss: 0.1748 - accuracy: 0.9460 - precision: 0.9502 - recall: 0.9413 - val_loss: 1.6615 - val_accuracy: 0.6197 - val_precision: 0.6350 - val_recall: 0.6127\n",
      "Epoch 194/200\n",
      "426/426 - 1s - loss: 0.1135 - accuracy: 0.9695 - precision: 0.9694 - recall: 0.9671 - val_loss: 2.0591 - val_accuracy: 0.5423 - val_precision: 0.5481 - val_recall: 0.5211\n",
      "Epoch 195/200\n",
      "426/426 - 1s - loss: 0.1994 - accuracy: 0.9343 - precision: 0.9387 - recall: 0.9343 - val_loss: 1.6363 - val_accuracy: 0.6268 - val_precision: 0.6304 - val_recall: 0.6127\n",
      "Epoch 196/200\n",
      "426/426 - 1s - loss: 0.0829 - accuracy: 0.9742 - precision: 0.9741 - recall: 0.9718 - val_loss: 1.6326 - val_accuracy: 0.6338 - val_precision: 0.6475 - val_recall: 0.6338\n",
      "Epoch 197/200\n",
      "426/426 - 1s - loss: 0.0769 - accuracy: 0.9742 - precision: 0.9742 - recall: 0.9742 - val_loss: 1.8357 - val_accuracy: 0.5775 - val_precision: 0.5912 - val_recall: 0.5704\n",
      "Epoch 198/200\n",
      "426/426 - 1s - loss: 0.2307 - accuracy: 0.9131 - precision: 0.9196 - recall: 0.9131 - val_loss: 1.8606 - val_accuracy: 0.5915 - val_precision: 0.6058 - val_recall: 0.5845\n",
      "Epoch 199/200\n",
      "426/426 - 1s - loss: 0.3088 - accuracy: 0.9108 - precision: 0.9171 - recall: 0.9085 - val_loss: 1.6444 - val_accuracy: 0.6197 - val_precision: 0.6444 - val_recall: 0.6127\n",
      "Epoch 200/200\n",
      "426/426 - 1s - loss: 0.0552 - accuracy: 0.9812 - precision: 0.9835 - recall: 0.9812 - val_loss: 1.5261 - val_accuracy: 0.6549 - val_precision: 0.6569 - val_recall: 0.6338\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 192)          214272    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 128)          164352    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 192)          246528    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 128)          164352    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 96)                86400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1164      \n",
      "=================================================================\n",
      "Total params: 877,068\n",
      "Trainable params: 877,068\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "RMSprop\n",
      "\n",
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/200\n",
      "426/426 - 14s - loss: 2.3713 - accuracy: 0.1197 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0118 - val_accuracy: 0.1620 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      "426/426 - 1s - loss: 2.0041 - accuracy: 0.1808 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0901 - val_accuracy: 0.2183 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/200\n",
      "426/426 - 1s - loss: 2.0172 - accuracy: 0.2089 - precision: 0.4286 - recall: 0.0070 - val_loss: 2.0297 - val_accuracy: 0.1620 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/200\n",
      "426/426 - 1s - loss: 1.9429 - accuracy: 0.1831 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8441 - val_accuracy: 0.2465 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/200\n",
      "426/426 - 1s - loss: 1.8845 - accuracy: 0.1948 - precision: 0.5000 - recall: 0.0047 - val_loss: 1.7853 - val_accuracy: 0.1972 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/200\n",
      "426/426 - 1s - loss: 1.8900 - accuracy: 0.2324 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8332 - val_accuracy: 0.1972 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/200\n",
      "426/426 - 1s - loss: 1.9207 - accuracy: 0.1948 - precision: 0.6667 - recall: 0.0094 - val_loss: 1.8050 - val_accuracy: 0.2183 - val_precision: 0.7143 - val_recall: 0.0352\n",
      "Epoch 8/200\n",
      "426/426 - 1s - loss: 1.8626 - accuracy: 0.2582 - precision: 0.5714 - recall: 0.0188 - val_loss: 1.7946 - val_accuracy: 0.2606 - val_precision: 0.5294 - val_recall: 0.0634\n",
      "Epoch 9/200\n",
      "426/426 - 1s - loss: 1.8306 - accuracy: 0.2653 - precision: 0.3529 - recall: 0.0141 - val_loss: 1.8959 - val_accuracy: 0.2394 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 10/200\n",
      "426/426 - 1s - loss: 1.9000 - accuracy: 0.2606 - precision: 0.3750 - recall: 0.0141 - val_loss: 1.8325 - val_accuracy: 0.2606 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/200\n",
      "426/426 - 1s - loss: 1.8373 - accuracy: 0.2535 - precision: 0.3333 - recall: 0.0047 - val_loss: 1.7413 - val_accuracy: 0.2746 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/200\n",
      "426/426 - 1s - loss: 1.7863 - accuracy: 0.2606 - precision: 0.3750 - recall: 0.0141 - val_loss: 1.7694 - val_accuracy: 0.1901 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/200\n",
      "426/426 - 1s - loss: 1.7927 - accuracy: 0.2582 - precision: 0.2857 - recall: 0.0047 - val_loss: 1.7648 - val_accuracy: 0.2254 - val_precision: 0.3636 - val_recall: 0.0282\n",
      "Epoch 14/200\n",
      "426/426 - 1s - loss: 1.7787 - accuracy: 0.2535 - precision: 0.4000 - recall: 0.0141 - val_loss: 1.7108 - val_accuracy: 0.2676 - val_precision: 0.7143 - val_recall: 0.0352\n",
      "Epoch 15/200\n",
      "426/426 - 1s - loss: 1.7642 - accuracy: 0.2981 - precision: 0.5000 - recall: 0.0070 - val_loss: 1.6874 - val_accuracy: 0.2606 - val_precision: 0.4643 - val_recall: 0.0915\n",
      "Epoch 16/200\n",
      "426/426 - 1s - loss: 1.7932 - accuracy: 0.2981 - precision: 0.4667 - recall: 0.0329 - val_loss: 1.6933 - val_accuracy: 0.2606 - val_precision: 0.5000 - val_recall: 0.1268\n",
      "Epoch 17/200\n",
      "426/426 - 1s - loss: 1.7632 - accuracy: 0.2746 - precision: 0.4464 - recall: 0.0587 - val_loss: 1.6982 - val_accuracy: 0.2746 - val_precision: 0.7143 - val_recall: 0.0704\n",
      "Epoch 18/200\n",
      "426/426 - 1s - loss: 1.7447 - accuracy: 0.3005 - precision: 0.4737 - recall: 0.0211 - val_loss: 1.8877 - val_accuracy: 0.2113 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 19/200\n",
      "426/426 - 1s - loss: 1.7350 - accuracy: 0.2817 - precision: 0.5385 - recall: 0.0164 - val_loss: 1.6694 - val_accuracy: 0.2746 - val_precision: 0.5806 - val_recall: 0.1268\n",
      "Epoch 20/200\n",
      "426/426 - 1s - loss: 1.7004 - accuracy: 0.3075 - precision: 0.5250 - recall: 0.0493 - val_loss: 1.7061 - val_accuracy: 0.2817 - val_precision: 0.5217 - val_recall: 0.0845\n",
      "Epoch 21/200\n",
      "426/426 - 1s - loss: 1.7105 - accuracy: 0.2911 - precision: 0.4889 - recall: 0.0516 - val_loss: 1.7013 - val_accuracy: 0.3099 - val_precision: 0.6000 - val_recall: 0.0423\n",
      "Epoch 22/200\n",
      "426/426 - 1s - loss: 1.6752 - accuracy: 0.3122 - precision: 0.4688 - recall: 0.0352 - val_loss: 1.8229 - val_accuracy: 0.3310 - val_precision: 0.6667 - val_recall: 0.0282\n",
      "Epoch 23/200\n",
      "426/426 - 1s - loss: 1.8574 - accuracy: 0.2700 - precision: 0.5500 - recall: 0.0258 - val_loss: 1.7341 - val_accuracy: 0.2535 - val_precision: 0.4286 - val_recall: 0.0423\n",
      "Epoch 24/200\n",
      "426/426 - 1s - loss: 1.7705 - accuracy: 0.2465 - precision: 0.3750 - recall: 0.0282 - val_loss: 1.6984 - val_accuracy: 0.2817 - val_precision: 0.5789 - val_recall: 0.0775\n",
      "Epoch 25/200\n",
      "426/426 - 1s - loss: 1.7047 - accuracy: 0.2958 - precision: 0.4000 - recall: 0.0235 - val_loss: 1.7780 - val_accuracy: 0.3380 - val_precision: 0.4375 - val_recall: 0.0493\n",
      "Epoch 26/200\n",
      "426/426 - 1s - loss: 1.6419 - accuracy: 0.3075 - precision: 0.5333 - recall: 0.0563 - val_loss: 1.6479 - val_accuracy: 0.3380 - val_precision: 0.6667 - val_recall: 0.0563\n",
      "Epoch 27/200\n",
      "426/426 - 1s - loss: 1.6290 - accuracy: 0.3380 - precision: 0.5000 - recall: 0.1103 - val_loss: 1.7080 - val_accuracy: 0.2465 - val_precision: 1.0000 - val_recall: 0.0282\n",
      "Epoch 28/200\n",
      "426/426 - 1s - loss: 1.6107 - accuracy: 0.3427 - precision: 0.5849 - recall: 0.0728 - val_loss: 1.5952 - val_accuracy: 0.3169 - val_precision: 0.6667 - val_recall: 0.1127\n",
      "Epoch 29/200\n",
      "426/426 - 1s - loss: 1.5820 - accuracy: 0.3826 - precision: 0.5405 - recall: 0.1408 - val_loss: 1.7463 - val_accuracy: 0.3169 - val_precision: 0.4634 - val_recall: 0.1338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200\n",
      "426/426 - 1s - loss: 1.5914 - accuracy: 0.3803 - precision: 0.4660 - recall: 0.1127 - val_loss: 1.5080 - val_accuracy: 0.3592 - val_precision: 0.8750 - val_recall: 0.0986\n",
      "Epoch 31/200\n",
      "426/426 - 1s - loss: 1.5821 - accuracy: 0.3662 - precision: 0.6410 - recall: 0.1174 - val_loss: 1.6345 - val_accuracy: 0.3169 - val_precision: 0.5319 - val_recall: 0.1761\n",
      "Epoch 32/200\n",
      "426/426 - 1s - loss: 1.6024 - accuracy: 0.3404 - precision: 0.4222 - recall: 0.0892 - val_loss: 1.4807 - val_accuracy: 0.4014 - val_precision: 0.6667 - val_recall: 0.2394\n",
      "Epoch 33/200\n",
      "426/426 - 1s - loss: 1.4899 - accuracy: 0.3920 - precision: 0.6392 - recall: 0.1455 - val_loss: 1.7509 - val_accuracy: 0.3451 - val_precision: 0.4286 - val_recall: 0.2113\n",
      "Epoch 34/200\n",
      "426/426 - 1s - loss: 1.5638 - accuracy: 0.3897 - precision: 0.5128 - recall: 0.1408 - val_loss: 1.4904 - val_accuracy: 0.3944 - val_precision: 0.6585 - val_recall: 0.1901\n",
      "Epoch 35/200\n",
      "426/426 - 1s - loss: 1.5468 - accuracy: 0.3967 - precision: 0.6484 - recall: 0.1385 - val_loss: 1.4505 - val_accuracy: 0.4296 - val_precision: 0.6596 - val_recall: 0.2183\n",
      "Epoch 36/200\n",
      "426/426 - 1s - loss: 1.5462 - accuracy: 0.3615 - precision: 0.5714 - recall: 0.1315 - val_loss: 1.5200 - val_accuracy: 0.3873 - val_precision: 0.6750 - val_recall: 0.1901\n",
      "Epoch 37/200\n",
      "426/426 - 1s - loss: 1.5622 - accuracy: 0.4014 - precision: 0.5905 - recall: 0.1455 - val_loss: 1.6719 - val_accuracy: 0.2676 - val_precision: 0.4286 - val_recall: 0.0845\n",
      "Epoch 38/200\n",
      "426/426 - 1s - loss: 1.6173 - accuracy: 0.3427 - precision: 0.5167 - recall: 0.0728 - val_loss: 1.7749 - val_accuracy: 0.2887 - val_precision: 0.5306 - val_recall: 0.1831\n",
      "Epoch 39/200\n",
      "426/426 - 1s - loss: 1.5444 - accuracy: 0.3897 - precision: 0.6207 - recall: 0.1268 - val_loss: 1.6519 - val_accuracy: 0.3310 - val_precision: 0.6250 - val_recall: 0.1408\n",
      "Epoch 40/200\n",
      "426/426 - 1s - loss: 1.5372 - accuracy: 0.3779 - precision: 0.6512 - recall: 0.1315 - val_loss: 1.7318 - val_accuracy: 0.3239 - val_precision: 0.4533 - val_recall: 0.2394\n",
      "Epoch 41/200\n",
      "426/426 - 1s - loss: 1.4721 - accuracy: 0.3897 - precision: 0.5470 - recall: 0.1502 - val_loss: 1.6784 - val_accuracy: 0.3099 - val_precision: 0.5652 - val_recall: 0.1831\n",
      "Epoch 42/200\n",
      "426/426 - 1s - loss: 1.5311 - accuracy: 0.4155 - precision: 0.5385 - recall: 0.1808 - val_loss: 1.6009 - val_accuracy: 0.3662 - val_precision: 0.8148 - val_recall: 0.1549\n",
      "Epoch 43/200\n",
      "426/426 - 1s - loss: 1.4670 - accuracy: 0.3991 - precision: 0.6442 - recall: 0.1573 - val_loss: 1.4712 - val_accuracy: 0.4014 - val_precision: 0.8095 - val_recall: 0.1197\n",
      "Epoch 44/200\n",
      "426/426 - 1s - loss: 1.4923 - accuracy: 0.4038 - precision: 0.6789 - recall: 0.1737 - val_loss: 1.5227 - val_accuracy: 0.3380 - val_precision: 0.7143 - val_recall: 0.1761\n",
      "Epoch 45/200\n",
      "426/426 - 1s - loss: 1.4141 - accuracy: 0.4554 - precision: 0.7692 - recall: 0.1643 - val_loss: 1.3947 - val_accuracy: 0.4437 - val_precision: 0.7381 - val_recall: 0.2183\n",
      "Epoch 46/200\n",
      "426/426 - 1s - loss: 1.3807 - accuracy: 0.4531 - precision: 0.6489 - recall: 0.1995 - val_loss: 1.4911 - val_accuracy: 0.4085 - val_precision: 0.6897 - val_recall: 0.1408\n",
      "Epoch 47/200\n",
      "426/426 - 1s - loss: 1.4483 - accuracy: 0.4131 - precision: 0.6250 - recall: 0.1526 - val_loss: 1.5596 - val_accuracy: 0.3521 - val_precision: 0.5938 - val_recall: 0.1338\n",
      "Epoch 48/200\n",
      "426/426 - 1s - loss: 1.3905 - accuracy: 0.4225 - precision: 0.6429 - recall: 0.1690 - val_loss: 1.3903 - val_accuracy: 0.4085 - val_precision: 0.7368 - val_recall: 0.1972\n",
      "Epoch 49/200\n",
      "426/426 - 1s - loss: 1.4357 - accuracy: 0.4554 - precision: 0.6479 - recall: 0.2160 - val_loss: 1.4574 - val_accuracy: 0.4085 - val_precision: 0.5909 - val_recall: 0.1831\n",
      "Epoch 50/200\n",
      "426/426 - 1s - loss: 1.3661 - accuracy: 0.4296 - precision: 0.6953 - recall: 0.2089 - val_loss: 1.5124 - val_accuracy: 0.3803 - val_precision: 0.7941 - val_recall: 0.1901\n",
      "Epoch 51/200\n",
      "426/426 - 1s - loss: 1.3446 - accuracy: 0.4531 - precision: 0.7290 - recall: 0.1831 - val_loss: 1.5454 - val_accuracy: 0.3944 - val_precision: 0.7000 - val_recall: 0.1972\n",
      "Epoch 52/200\n",
      "426/426 - 1s - loss: 1.4543 - accuracy: 0.4131 - precision: 0.5597 - recall: 0.2089 - val_loss: 1.8911 - val_accuracy: 0.2958 - val_precision: 0.3966 - val_recall: 0.1620\n",
      "Epoch 53/200\n",
      "426/426 - 1s - loss: 1.4586 - accuracy: 0.3991 - precision: 0.6452 - recall: 0.1408 - val_loss: 1.4790 - val_accuracy: 0.4437 - val_precision: 0.5714 - val_recall: 0.1690\n",
      "Epoch 54/200\n",
      "426/426 - 1s - loss: 1.3819 - accuracy: 0.4554 - precision: 0.7030 - recall: 0.1667 - val_loss: 1.5094 - val_accuracy: 0.4155 - val_precision: 0.6061 - val_recall: 0.2817\n",
      "Epoch 55/200\n",
      "426/426 - 1s - loss: 1.4055 - accuracy: 0.4859 - precision: 0.6532 - recall: 0.2653 - val_loss: 1.6322 - val_accuracy: 0.3662 - val_precision: 0.6905 - val_recall: 0.2042\n",
      "Epoch 56/200\n",
      "426/426 - 1s - loss: 1.4754 - accuracy: 0.4484 - precision: 0.5938 - recall: 0.1784 - val_loss: 1.4433 - val_accuracy: 0.4155 - val_precision: 0.6818 - val_recall: 0.2113\n",
      "Epoch 57/200\n",
      "426/426 - 1s - loss: 1.3223 - accuracy: 0.4624 - precision: 0.6582 - recall: 0.2441 - val_loss: 1.4432 - val_accuracy: 0.3732 - val_precision: 0.6557 - val_recall: 0.2817\n",
      "Epoch 58/200\n",
      "426/426 - 1s - loss: 1.3128 - accuracy: 0.4906 - precision: 0.6484 - recall: 0.2770 - val_loss: 1.8213 - val_accuracy: 0.3310 - val_precision: 0.3699 - val_recall: 0.1901\n",
      "Epoch 59/200\n",
      "426/426 - 1s - loss: 1.4015 - accuracy: 0.4507 - precision: 0.6486 - recall: 0.2254 - val_loss: 1.4293 - val_accuracy: 0.4225 - val_precision: 0.7778 - val_recall: 0.1972\n",
      "Epoch 60/200\n",
      "426/426 - 1s - loss: 1.2675 - accuracy: 0.5000 - precision: 0.7203 - recall: 0.2418 - val_loss: 1.3873 - val_accuracy: 0.4225 - val_precision: 0.7170 - val_recall: 0.2676\n",
      "Epoch 61/200\n",
      "426/426 - 1s - loss: 1.2872 - accuracy: 0.4812 - precision: 0.6630 - recall: 0.2817 - val_loss: 1.3237 - val_accuracy: 0.4577 - val_precision: 0.6613 - val_recall: 0.2887\n",
      "Epoch 62/200\n",
      "426/426 - 1s - loss: 1.2683 - accuracy: 0.4977 - precision: 0.6611 - recall: 0.2793 - val_loss: 1.4520 - val_accuracy: 0.4085 - val_precision: 0.6000 - val_recall: 0.2113\n",
      "Epoch 63/200\n",
      "426/426 - 1s - loss: 1.3779 - accuracy: 0.4789 - precision: 0.6140 - recall: 0.2465 - val_loss: 1.5742 - val_accuracy: 0.3944 - val_precision: 0.7045 - val_recall: 0.2183\n",
      "Epoch 64/200\n",
      "426/426 - 1s - loss: 1.3009 - accuracy: 0.4977 - precision: 0.6289 - recall: 0.2864 - val_loss: 1.3939 - val_accuracy: 0.4014 - val_precision: 0.7451 - val_recall: 0.2676\n",
      "Epoch 65/200\n",
      "426/426 - 1s - loss: 1.1890 - accuracy: 0.5423 - precision: 0.7310 - recall: 0.2934 - val_loss: 1.4287 - val_accuracy: 0.4155 - val_precision: 0.6667 - val_recall: 0.2676\n",
      "Epoch 66/200\n",
      "426/426 - 1s - loss: 1.1776 - accuracy: 0.5376 - precision: 0.7316 - recall: 0.3263 - val_loss: 1.3444 - val_accuracy: 0.4930 - val_precision: 0.6308 - val_recall: 0.2887\n",
      "Epoch 67/200\n",
      "426/426 - 1s - loss: 1.2616 - accuracy: 0.4953 - precision: 0.6735 - recall: 0.3099 - val_loss: 1.2814 - val_accuracy: 0.4577 - val_precision: 0.6897 - val_recall: 0.2817\n",
      "Epoch 68/200\n",
      "426/426 - 1s - loss: 1.1405 - accuracy: 0.5446 - precision: 0.8057 - recall: 0.3310 - val_loss: 1.6356 - val_accuracy: 0.3451 - val_precision: 0.6000 - val_recall: 0.2535\n",
      "Epoch 69/200\n",
      "426/426 - 1s - loss: 1.1951 - accuracy: 0.5258 - precision: 0.7416 - recall: 0.3099 - val_loss: 1.2916 - val_accuracy: 0.4577 - val_precision: 0.7547 - val_recall: 0.2817\n",
      "Epoch 70/200\n",
      "426/426 - 1s - loss: 1.1889 - accuracy: 0.5587 - precision: 0.6905 - recall: 0.3404 - val_loss: 1.3640 - val_accuracy: 0.4859 - val_precision: 0.6567 - val_recall: 0.3099\n",
      "Epoch 71/200\n",
      "426/426 - 1s - loss: 1.1391 - accuracy: 0.5775 - precision: 0.7241 - recall: 0.3944 - val_loss: 1.4025 - val_accuracy: 0.4789 - val_precision: 0.6420 - val_recall: 0.3662\n",
      "Epoch 72/200\n",
      "426/426 - 1s - loss: 1.1115 - accuracy: 0.5798 - precision: 0.6742 - recall: 0.4225 - val_loss: 1.4346 - val_accuracy: 0.4648 - val_precision: 0.5867 - val_recall: 0.3099\n",
      "Epoch 73/200\n",
      "426/426 - 1s - loss: 1.0807 - accuracy: 0.5681 - precision: 0.7190 - recall: 0.4085 - val_loss: 1.5618 - val_accuracy: 0.4225 - val_precision: 0.5500 - val_recall: 0.3873\n",
      "Epoch 74/200\n",
      "426/426 - 1s - loss: 1.0311 - accuracy: 0.6009 - precision: 0.7154 - recall: 0.4249 - val_loss: 1.2066 - val_accuracy: 0.5634 - val_precision: 0.6082 - val_recall: 0.4155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "426/426 - 1s - loss: 1.0781 - accuracy: 0.5681 - precision: 0.6642 - recall: 0.4178 - val_loss: 1.2133 - val_accuracy: 0.5704 - val_precision: 0.6196 - val_recall: 0.4014\n",
      "Epoch 76/200\n",
      "426/426 - 1s - loss: 1.0760 - accuracy: 0.5939 - precision: 0.6392 - recall: 0.4742 - val_loss: 1.3640 - val_accuracy: 0.4366 - val_precision: 0.5412 - val_recall: 0.3239\n",
      "Epoch 77/200\n",
      "426/426 - 1s - loss: 1.0554 - accuracy: 0.5845 - precision: 0.7055 - recall: 0.4554 - val_loss: 1.5196 - val_accuracy: 0.4155 - val_precision: 0.6197 - val_recall: 0.3099\n",
      "Epoch 78/200\n",
      "426/426 - 1s - loss: 0.9652 - accuracy: 0.6221 - precision: 0.7713 - recall: 0.4671 - val_loss: 1.2446 - val_accuracy: 0.5141 - val_precision: 0.6543 - val_recall: 0.3732\n",
      "Epoch 79/200\n",
      "426/426 - 1s - loss: 0.9752 - accuracy: 0.6315 - precision: 0.7361 - recall: 0.4977 - val_loss: 1.2215 - val_accuracy: 0.5493 - val_precision: 0.5865 - val_recall: 0.4296\n",
      "Epoch 80/200\n",
      "426/426 - 1s - loss: 1.0291 - accuracy: 0.6056 - precision: 0.7509 - recall: 0.4953 - val_loss: 1.4499 - val_accuracy: 0.4577 - val_precision: 0.5417 - val_recall: 0.3662\n",
      "Epoch 81/200\n",
      "426/426 - 1s - loss: 0.9720 - accuracy: 0.6338 - precision: 0.7116 - recall: 0.5329 - val_loss: 1.2196 - val_accuracy: 0.5211 - val_precision: 0.6224 - val_recall: 0.4296\n",
      "Epoch 82/200\n",
      "426/426 - 1s - loss: 0.9383 - accuracy: 0.6362 - precision: 0.7273 - recall: 0.5070 - val_loss: 1.2562 - val_accuracy: 0.5070 - val_precision: 0.6512 - val_recall: 0.3944\n",
      "Epoch 83/200\n",
      "426/426 - 1s - loss: 0.8632 - accuracy: 0.6549 - precision: 0.7852 - recall: 0.5493 - val_loss: 1.4051 - val_accuracy: 0.4648 - val_precision: 0.6087 - val_recall: 0.3944\n",
      "Epoch 84/200\n",
      "426/426 - 1s - loss: 0.9615 - accuracy: 0.6315 - precision: 0.7467 - recall: 0.5258 - val_loss: 1.5503 - val_accuracy: 0.4155 - val_precision: 0.5217 - val_recall: 0.3380\n",
      "Epoch 85/200\n",
      "426/426 - 1s - loss: 0.9298 - accuracy: 0.6338 - precision: 0.7452 - recall: 0.5423 - val_loss: 1.4001 - val_accuracy: 0.4648 - val_precision: 0.6296 - val_recall: 0.3592\n",
      "Epoch 86/200\n",
      "426/426 - 1s - loss: 0.8775 - accuracy: 0.6714 - precision: 0.7645 - recall: 0.5563 - val_loss: 1.0957 - val_accuracy: 0.6056 - val_precision: 0.6762 - val_recall: 0.5000\n",
      "Epoch 87/200\n",
      "426/426 - 1s - loss: 0.9392 - accuracy: 0.6385 - precision: 0.7308 - recall: 0.5352 - val_loss: 1.7540 - val_accuracy: 0.4155 - val_precision: 0.4717 - val_recall: 0.3521\n",
      "Epoch 88/200\n",
      "426/426 - 1s - loss: 0.8918 - accuracy: 0.6526 - precision: 0.7305 - recall: 0.5282 - val_loss: 1.0901 - val_accuracy: 0.5141 - val_precision: 0.6289 - val_recall: 0.4296\n",
      "Epoch 89/200\n",
      "426/426 - 1s - loss: 0.8585 - accuracy: 0.6643 - precision: 0.7508 - recall: 0.5516 - val_loss: 1.1010 - val_accuracy: 0.5563 - val_precision: 0.6863 - val_recall: 0.4930\n",
      "Epoch 90/200\n",
      "426/426 - 1s - loss: 0.8571 - accuracy: 0.6972 - precision: 0.7826 - recall: 0.5915 - val_loss: 1.2863 - val_accuracy: 0.5282 - val_precision: 0.6019 - val_recall: 0.4366\n",
      "Epoch 91/200\n",
      "426/426 - 1s - loss: 0.8299 - accuracy: 0.6878 - precision: 0.7727 - recall: 0.5986 - val_loss: 0.9881 - val_accuracy: 0.6197 - val_precision: 0.6697 - val_recall: 0.5141\n",
      "Epoch 92/200\n",
      "426/426 - 1s - loss: 0.8313 - accuracy: 0.6972 - precision: 0.7658 - recall: 0.5986 - val_loss: 1.1443 - val_accuracy: 0.5211 - val_precision: 0.6154 - val_recall: 0.4507\n",
      "Epoch 93/200\n",
      "426/426 - 1s - loss: 0.8577 - accuracy: 0.6854 - precision: 0.7551 - recall: 0.6080 - val_loss: 1.5258 - val_accuracy: 0.4930 - val_precision: 0.5392 - val_recall: 0.3873\n",
      "Epoch 94/200\n",
      "426/426 - 1s - loss: 0.8924 - accuracy: 0.6502 - precision: 0.7508 - recall: 0.5305 - val_loss: 1.3639 - val_accuracy: 0.5070 - val_precision: 0.5909 - val_recall: 0.3662\n",
      "Epoch 95/200\n",
      "426/426 - 1s - loss: 0.8065 - accuracy: 0.6925 - precision: 0.7882 - recall: 0.5939 - val_loss: 1.1220 - val_accuracy: 0.5141 - val_precision: 0.6304 - val_recall: 0.4085\n",
      "Epoch 96/200\n",
      "426/426 - 1s - loss: 0.8311 - accuracy: 0.6831 - precision: 0.7874 - recall: 0.6174 - val_loss: 1.2511 - val_accuracy: 0.5704 - val_precision: 0.5960 - val_recall: 0.4155\n",
      "Epoch 97/200\n",
      "426/426 - 1s - loss: 0.8427 - accuracy: 0.6808 - precision: 0.7548 - recall: 0.5563 - val_loss: 1.3518 - val_accuracy: 0.5070 - val_precision: 0.5900 - val_recall: 0.4155\n",
      "Epoch 98/200\n",
      "426/426 - 1s - loss: 0.8532 - accuracy: 0.6831 - precision: 0.7922 - recall: 0.5728 - val_loss: 1.2840 - val_accuracy: 0.5211 - val_precision: 0.6117 - val_recall: 0.4437\n",
      "Epoch 99/200\n",
      "426/426 - 1s - loss: 0.7330 - accuracy: 0.7254 - precision: 0.8198 - recall: 0.6408 - val_loss: 1.2981 - val_accuracy: 0.5282 - val_precision: 0.6321 - val_recall: 0.4718\n",
      "Epoch 100/200\n",
      "426/426 - 1s - loss: 0.9489 - accuracy: 0.6408 - precision: 0.7181 - recall: 0.5681 - val_loss: 1.0431 - val_accuracy: 0.5775 - val_precision: 0.6966 - val_recall: 0.4366\n",
      "Epoch 101/200\n",
      "426/426 - 1s - loss: 0.7151 - accuracy: 0.7254 - precision: 0.8188 - recall: 0.6150 - val_loss: 1.2492 - val_accuracy: 0.5352 - val_precision: 0.5702 - val_recall: 0.4577\n",
      "Epoch 102/200\n",
      "426/426 - 1s - loss: 0.7575 - accuracy: 0.6948 - precision: 0.7765 - recall: 0.6197 - val_loss: 1.1488 - val_accuracy: 0.5986 - val_precision: 0.6186 - val_recall: 0.5141\n",
      "Epoch 103/200\n",
      "426/426 - 1s - loss: 0.6986 - accuracy: 0.7324 - precision: 0.8070 - recall: 0.6479 - val_loss: 1.1254 - val_accuracy: 0.5563 - val_precision: 0.6321 - val_recall: 0.4718\n",
      "Epoch 104/200\n",
      "426/426 - 1s - loss: 0.6435 - accuracy: 0.7441 - precision: 0.8063 - recall: 0.6643 - val_loss: 1.1321 - val_accuracy: 0.5704 - val_precision: 0.6636 - val_recall: 0.5000\n",
      "Epoch 105/200\n",
      "426/426 - 1s - loss: 0.7192 - accuracy: 0.7113 - precision: 0.7971 - recall: 0.6362 - val_loss: 1.3960 - val_accuracy: 0.5070 - val_precision: 0.5780 - val_recall: 0.4437\n",
      "Epoch 106/200\n",
      "426/426 - 1s - loss: 0.6653 - accuracy: 0.7582 - precision: 0.8232 - recall: 0.6667 - val_loss: 1.5137 - val_accuracy: 0.4718 - val_precision: 0.5289 - val_recall: 0.4507\n",
      "Epoch 107/200\n",
      "426/426 - 1s - loss: 0.8236 - accuracy: 0.6854 - precision: 0.7611 - recall: 0.6056 - val_loss: 1.0249 - val_accuracy: 0.5986 - val_precision: 0.7103 - val_recall: 0.5352\n",
      "Epoch 108/200\n",
      "426/426 - 1s - loss: 0.6624 - accuracy: 0.7465 - precision: 0.8006 - recall: 0.6690 - val_loss: 1.0398 - val_accuracy: 0.6408 - val_precision: 0.6748 - val_recall: 0.5845\n",
      "Epoch 109/200\n",
      "426/426 - 1s - loss: 0.6178 - accuracy: 0.7606 - precision: 0.8167 - recall: 0.6901 - val_loss: 1.3476 - val_accuracy: 0.5704 - val_precision: 0.6226 - val_recall: 0.4648\n",
      "Epoch 110/200\n",
      "426/426 - 1s - loss: 0.7046 - accuracy: 0.7300 - precision: 0.8087 - recall: 0.6549 - val_loss: 1.0822 - val_accuracy: 0.5775 - val_precision: 0.6372 - val_recall: 0.5070\n",
      "Epoch 111/200\n",
      "426/426 - 1s - loss: 0.6370 - accuracy: 0.7512 - precision: 0.8324 - recall: 0.6878 - val_loss: 1.0632 - val_accuracy: 0.5845 - val_precision: 0.6792 - val_recall: 0.5070\n",
      "Epoch 112/200\n",
      "426/426 - 1s - loss: 0.6116 - accuracy: 0.7840 - precision: 0.8275 - recall: 0.7207 - val_loss: 2.0029 - val_accuracy: 0.4930 - val_precision: 0.5000 - val_recall: 0.4718\n",
      "Epoch 113/200\n",
      "426/426 - 1s - loss: 0.7598 - accuracy: 0.7465 - precision: 0.7795 - recall: 0.7136 - val_loss: 1.4437 - val_accuracy: 0.4648 - val_precision: 0.5046 - val_recall: 0.3873\n",
      "Epoch 114/200\n",
      "426/426 - 1s - loss: 0.6017 - accuracy: 0.7746 - precision: 0.8189 - recall: 0.7324 - val_loss: 1.4803 - val_accuracy: 0.4930 - val_precision: 0.5039 - val_recall: 0.4507\n",
      "Epoch 115/200\n",
      "426/426 - 1s - loss: 0.6233 - accuracy: 0.7746 - precision: 0.8202 - recall: 0.7066 - val_loss: 1.2077 - val_accuracy: 0.5563 - val_precision: 0.5917 - val_recall: 0.5000\n",
      "Epoch 116/200\n",
      "426/426 - 1s - loss: 0.6058 - accuracy: 0.7700 - precision: 0.8196 - recall: 0.7254 - val_loss: 1.0600 - val_accuracy: 0.6056 - val_precision: 0.6752 - val_recall: 0.5563\n",
      "Epoch 117/200\n",
      "426/426 - 1s - loss: 0.5455 - accuracy: 0.7887 - precision: 0.8478 - recall: 0.7324 - val_loss: 1.0520 - val_accuracy: 0.5845 - val_precision: 0.6786 - val_recall: 0.5352\n",
      "Epoch 118/200\n",
      "426/426 - 1s - loss: 0.6152 - accuracy: 0.7653 - precision: 0.8287 - recall: 0.7042 - val_loss: 1.1558 - val_accuracy: 0.5563 - val_precision: 0.6372 - val_recall: 0.5070\n",
      "Epoch 119/200\n",
      "426/426 - 1s - loss: 0.5916 - accuracy: 0.7559 - precision: 0.8159 - recall: 0.6972 - val_loss: 1.4143 - val_accuracy: 0.5141 - val_precision: 0.5909 - val_recall: 0.4577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200\n",
      "426/426 - 1s - loss: 0.5738 - accuracy: 0.7887 - precision: 0.8387 - recall: 0.7324 - val_loss: 1.2017 - val_accuracy: 0.6127 - val_precision: 0.6613 - val_recall: 0.5775\n",
      "Epoch 121/200\n",
      "426/426 - 1s - loss: 0.5659 - accuracy: 0.7934 - precision: 0.8385 - recall: 0.7559 - val_loss: 1.2371 - val_accuracy: 0.5986 - val_precision: 0.6696 - val_recall: 0.5423\n",
      "Epoch 122/200\n",
      "426/426 - 1s - loss: 0.5923 - accuracy: 0.7770 - precision: 0.8245 - recall: 0.7277 - val_loss: 1.1388 - val_accuracy: 0.6127 - val_precision: 0.6348 - val_recall: 0.5141\n",
      "Epoch 123/200\n",
      "426/426 - 1s - loss: 0.5768 - accuracy: 0.7817 - precision: 0.8436 - recall: 0.7089 - val_loss: 1.5625 - val_accuracy: 0.4859 - val_precision: 0.5167 - val_recall: 0.4366\n",
      "Epoch 124/200\n",
      "426/426 - 1s - loss: 0.5773 - accuracy: 0.7746 - precision: 0.8449 - recall: 0.7160 - val_loss: 1.2573 - val_accuracy: 0.5845 - val_precision: 0.6281 - val_recall: 0.5352\n",
      "Epoch 125/200\n",
      "426/426 - 1s - loss: 0.5684 - accuracy: 0.7723 - precision: 0.8306 - recall: 0.7254 - val_loss: 1.1575 - val_accuracy: 0.6056 - val_precision: 0.6466 - val_recall: 0.5282\n",
      "Epoch 126/200\n",
      "426/426 - 1s - loss: 0.6026 - accuracy: 0.7770 - precision: 0.8407 - recall: 0.7183 - val_loss: 1.4816 - val_accuracy: 0.5423 - val_precision: 0.5794 - val_recall: 0.5141\n",
      "Epoch 127/200\n",
      "426/426 - 1s - loss: 0.5089 - accuracy: 0.8005 - precision: 0.8696 - recall: 0.7512 - val_loss: 1.3816 - val_accuracy: 0.5352 - val_precision: 0.5772 - val_recall: 0.5000\n",
      "Epoch 128/200\n",
      "426/426 - 1s - loss: 0.4464 - accuracy: 0.8357 - precision: 0.8737 - recall: 0.7958 - val_loss: 1.3636 - val_accuracy: 0.5352 - val_precision: 0.6083 - val_recall: 0.5141\n",
      "Epoch 129/200\n",
      "426/426 - 1s - loss: 0.5930 - accuracy: 0.7864 - precision: 0.8455 - recall: 0.7324 - val_loss: 1.3232 - val_accuracy: 0.5423 - val_precision: 0.5893 - val_recall: 0.4648\n",
      "Epoch 130/200\n",
      "426/426 - 1s - loss: 0.5213 - accuracy: 0.7793 - precision: 0.8567 - recall: 0.7300 - val_loss: 1.1660 - val_accuracy: 0.6197 - val_precision: 0.6587 - val_recall: 0.5845\n",
      "Epoch 131/200\n",
      "426/426 - 1s - loss: 0.5331 - accuracy: 0.7934 - precision: 0.8342 - recall: 0.7441 - val_loss: 1.1067 - val_accuracy: 0.6127 - val_precision: 0.6780 - val_recall: 0.5634\n",
      "Epoch 132/200\n",
      "426/426 - 1s - loss: 0.5029 - accuracy: 0.8192 - precision: 0.8605 - recall: 0.7817 - val_loss: 1.3231 - val_accuracy: 0.5704 - val_precision: 0.6198 - val_recall: 0.5282\n",
      "Epoch 133/200\n",
      "426/426 - 1s - loss: 0.6076 - accuracy: 0.7512 - precision: 0.8037 - recall: 0.7207 - val_loss: 1.1318 - val_accuracy: 0.5845 - val_precision: 0.6393 - val_recall: 0.5493\n",
      "Epoch 134/200\n",
      "426/426 - 1s - loss: 0.3947 - accuracy: 0.8357 - precision: 0.8892 - recall: 0.7911 - val_loss: 1.1325 - val_accuracy: 0.5915 - val_precision: 0.6311 - val_recall: 0.5423\n",
      "Epoch 135/200\n",
      "426/426 - 1s - loss: 0.4561 - accuracy: 0.8333 - precision: 0.8589 - recall: 0.8005 - val_loss: 1.3470 - val_accuracy: 0.5704 - val_precision: 0.6111 - val_recall: 0.5423\n",
      "Epoch 136/200\n",
      "426/426 - 1s - loss: 0.4555 - accuracy: 0.8310 - precision: 0.8649 - recall: 0.7817 - val_loss: 1.3057 - val_accuracy: 0.5845 - val_precision: 0.6341 - val_recall: 0.5493\n",
      "Epoch 137/200\n",
      "426/426 - 1s - loss: 0.4735 - accuracy: 0.8169 - precision: 0.8550 - recall: 0.7887 - val_loss: 1.2147 - val_accuracy: 0.6127 - val_precision: 0.6667 - val_recall: 0.5775\n",
      "Epoch 138/200\n",
      "426/426 - 1s - loss: 0.4826 - accuracy: 0.8263 - precision: 0.8491 - recall: 0.7793 - val_loss: 1.3737 - val_accuracy: 0.5000 - val_precision: 0.5492 - val_recall: 0.4718\n",
      "Epoch 139/200\n",
      "426/426 - 1s - loss: 0.4640 - accuracy: 0.8005 - precision: 0.8440 - recall: 0.7746 - val_loss: 1.2507 - val_accuracy: 0.5775 - val_precision: 0.6446 - val_recall: 0.5493\n",
      "Epoch 140/200\n",
      "426/426 - 1s - loss: 0.4306 - accuracy: 0.8404 - precision: 0.8706 - recall: 0.8052 - val_loss: 1.1968 - val_accuracy: 0.6127 - val_precision: 0.6587 - val_recall: 0.5845\n",
      "Epoch 141/200\n",
      "426/426 - 1s - loss: 0.5347 - accuracy: 0.7887 - precision: 0.8503 - recall: 0.7465 - val_loss: 1.1048 - val_accuracy: 0.5986 - val_precision: 0.6983 - val_recall: 0.5704\n",
      "Epoch 142/200\n",
      "426/426 - 1s - loss: 0.4138 - accuracy: 0.8404 - precision: 0.8837 - recall: 0.8028 - val_loss: 1.3394 - val_accuracy: 0.5704 - val_precision: 0.6016 - val_recall: 0.5423\n",
      "Epoch 143/200\n",
      "426/426 - 1s - loss: 0.5051 - accuracy: 0.8075 - precision: 0.8587 - recall: 0.7559 - val_loss: 1.1951 - val_accuracy: 0.6549 - val_precision: 0.7040 - val_recall: 0.6197\n",
      "Epoch 144/200\n",
      "426/426 - 1s - loss: 0.3889 - accuracy: 0.8380 - precision: 0.8869 - recall: 0.8099 - val_loss: 1.1831 - val_accuracy: 0.6056 - val_precision: 0.6508 - val_recall: 0.5775\n",
      "Epoch 145/200\n",
      "426/426 - 1s - loss: 0.4375 - accuracy: 0.8239 - precision: 0.8655 - recall: 0.8005 - val_loss: 1.3844 - val_accuracy: 0.6056 - val_precision: 0.6504 - val_recall: 0.5634\n",
      "Epoch 146/200\n",
      "426/426 - 1s - loss: 0.4697 - accuracy: 0.8310 - precision: 0.8625 - recall: 0.8099 - val_loss: 1.3543 - val_accuracy: 0.5563 - val_precision: 0.6032 - val_recall: 0.5352\n",
      "Epoch 147/200\n",
      "426/426 - 1s - loss: 0.4085 - accuracy: 0.8357 - precision: 0.8912 - recall: 0.8075 - val_loss: 1.3787 - val_accuracy: 0.5704 - val_precision: 0.6239 - val_recall: 0.5141\n",
      "Epoch 148/200\n",
      "426/426 - 1s - loss: 0.4811 - accuracy: 0.8005 - precision: 0.8542 - recall: 0.7700 - val_loss: 1.1609 - val_accuracy: 0.6056 - val_precision: 0.7083 - val_recall: 0.5986\n",
      "Epoch 149/200\n",
      "426/426 - 1s - loss: 0.4059 - accuracy: 0.8521 - precision: 0.8866 - recall: 0.8075 - val_loss: 1.4948 - val_accuracy: 0.5634 - val_precision: 0.6048 - val_recall: 0.5282\n",
      "Epoch 150/200\n",
      "426/426 - 1s - loss: 0.5013 - accuracy: 0.8192 - precision: 0.8471 - recall: 0.7934 - val_loss: 1.1679 - val_accuracy: 0.6127 - val_precision: 0.6752 - val_recall: 0.5563\n",
      "Epoch 151/200\n",
      "426/426 - 1s - loss: 0.4090 - accuracy: 0.8498 - precision: 0.8766 - recall: 0.8169 - val_loss: 1.2606 - val_accuracy: 0.5915 - val_precision: 0.6452 - val_recall: 0.5634\n",
      "Epoch 152/200\n",
      "426/426 - 1s - loss: 0.4015 - accuracy: 0.8521 - precision: 0.8897 - recall: 0.8333 - val_loss: 1.8805 - val_accuracy: 0.5000 - val_precision: 0.5159 - val_recall: 0.4577\n",
      "Epoch 153/200\n",
      "426/426 - 1s - loss: 0.4423 - accuracy: 0.8380 - precision: 0.8668 - recall: 0.8099 - val_loss: 1.2096 - val_accuracy: 0.6268 - val_precision: 0.6535 - val_recall: 0.5845\n",
      "Epoch 154/200\n",
      "426/426 - 1s - loss: 0.3211 - accuracy: 0.8920 - precision: 0.9084 - recall: 0.8615 - val_loss: 1.4984 - val_accuracy: 0.5704 - val_precision: 0.6160 - val_recall: 0.5423\n",
      "Epoch 155/200\n",
      "426/426 - 1s - loss: 0.3545 - accuracy: 0.8756 - precision: 0.9035 - recall: 0.8568 - val_loss: 1.6116 - val_accuracy: 0.5141 - val_precision: 0.5760 - val_recall: 0.5070\n",
      "Epoch 156/200\n",
      "426/426 - 1s - loss: 0.5083 - accuracy: 0.8216 - precision: 0.8597 - recall: 0.7770 - val_loss: 1.3303 - val_accuracy: 0.5986 - val_precision: 0.6240 - val_recall: 0.5493\n",
      "Epoch 157/200\n",
      "426/426 - 1s - loss: 0.3868 - accuracy: 0.8638 - precision: 0.8894 - recall: 0.8310 - val_loss: 1.5938 - val_accuracy: 0.5493 - val_precision: 0.5714 - val_recall: 0.5352\n",
      "Epoch 158/200\n",
      "426/426 - 1s - loss: 0.4338 - accuracy: 0.8380 - precision: 0.8631 - recall: 0.8286 - val_loss: 1.3498 - val_accuracy: 0.5986 - val_precision: 0.6183 - val_recall: 0.5704\n",
      "Epoch 159/200\n",
      "426/426 - 1s - loss: 0.4187 - accuracy: 0.8521 - precision: 0.8741 - recall: 0.8310 - val_loss: 1.2432 - val_accuracy: 0.6268 - val_precision: 0.6581 - val_recall: 0.5423\n",
      "Epoch 160/200\n",
      "426/426 - 1s - loss: 0.3236 - accuracy: 0.8732 - precision: 0.8971 - recall: 0.8592 - val_loss: 1.3975 - val_accuracy: 0.6408 - val_precision: 0.6538 - val_recall: 0.5986\n",
      "Epoch 161/200\n",
      "426/426 - 1s - loss: 0.4296 - accuracy: 0.8474 - precision: 0.8731 - recall: 0.8239 - val_loss: 1.3770 - val_accuracy: 0.5845 - val_precision: 0.6183 - val_recall: 0.5704\n",
      "Epoch 162/200\n",
      "426/426 - 1s - loss: 0.3573 - accuracy: 0.8779 - precision: 0.8914 - recall: 0.8474 - val_loss: 1.5309 - val_accuracy: 0.5563 - val_precision: 0.5920 - val_recall: 0.5211\n",
      "Epoch 163/200\n",
      "426/426 - 1s - loss: 0.3124 - accuracy: 0.8779 - precision: 0.9037 - recall: 0.8592 - val_loss: 1.2878 - val_accuracy: 0.6268 - val_precision: 0.6538 - val_recall: 0.5986\n",
      "Epoch 164/200\n",
      "426/426 - 1s - loss: 0.2693 - accuracy: 0.9085 - precision: 0.9338 - recall: 0.8944 - val_loss: 1.4449 - val_accuracy: 0.5775 - val_precision: 0.6190 - val_recall: 0.5493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/200\n",
      "426/426 - 1s - loss: 0.3891 - accuracy: 0.8826 - precision: 0.8960 - recall: 0.8498 - val_loss: 1.2476 - val_accuracy: 0.6268 - val_precision: 0.6772 - val_recall: 0.6056\n",
      "Epoch 166/200\n",
      "426/426 - 1s - loss: 0.3579 - accuracy: 0.8803 - precision: 0.8995 - recall: 0.8615 - val_loss: 1.4189 - val_accuracy: 0.5915 - val_precision: 0.6212 - val_recall: 0.5775\n",
      "Epoch 167/200\n",
      "426/426 - 1s - loss: 0.2906 - accuracy: 0.8920 - precision: 0.9193 - recall: 0.8826 - val_loss: 1.2937 - val_accuracy: 0.6197 - val_precision: 0.6641 - val_recall: 0.6127\n",
      "Epoch 168/200\n",
      "426/426 - 1s - loss: 0.3587 - accuracy: 0.8779 - precision: 0.8927 - recall: 0.8592 - val_loss: 1.3830 - val_accuracy: 0.6127 - val_precision: 0.6462 - val_recall: 0.5915\n",
      "Epoch 169/200\n",
      "426/426 - 1s - loss: 0.3371 - accuracy: 0.8756 - precision: 0.9015 - recall: 0.8592 - val_loss: 1.4272 - val_accuracy: 0.5986 - val_precision: 0.6183 - val_recall: 0.5704\n",
      "Epoch 170/200\n",
      "426/426 - 1s - loss: 0.3256 - accuracy: 0.8944 - precision: 0.9084 - recall: 0.8850 - val_loss: 1.2559 - val_accuracy: 0.5915 - val_precision: 0.6250 - val_recall: 0.5634\n",
      "Epoch 171/200\n",
      "426/426 - 1s - loss: 0.2972 - accuracy: 0.8991 - precision: 0.9148 - recall: 0.8826 - val_loss: 1.4400 - val_accuracy: 0.5775 - val_precision: 0.6063 - val_recall: 0.5423\n",
      "Epoch 172/200\n",
      "426/426 - 1s - loss: 0.4173 - accuracy: 0.8732 - precision: 0.8905 - recall: 0.8592 - val_loss: 1.3855 - val_accuracy: 0.5915 - val_precision: 0.6412 - val_recall: 0.5915\n",
      "Epoch 173/200\n",
      "426/426 - 1s - loss: 0.3303 - accuracy: 0.8803 - precision: 0.9084 - recall: 0.8615 - val_loss: 1.2671 - val_accuracy: 0.6056 - val_precision: 0.6515 - val_recall: 0.6056\n",
      "Epoch 174/200\n",
      "426/426 - 1s - loss: 0.2525 - accuracy: 0.9061 - precision: 0.9185 - recall: 0.8991 - val_loss: 1.2962 - val_accuracy: 0.5634 - val_precision: 0.5909 - val_recall: 0.5493\n",
      "Epoch 175/200\n",
      "426/426 - 1s - loss: 0.2613 - accuracy: 0.8967 - precision: 0.9124 - recall: 0.8803 - val_loss: 1.6757 - val_accuracy: 0.5141 - val_precision: 0.5426 - val_recall: 0.4930\n",
      "Epoch 176/200\n",
      "426/426 - 1s - loss: 0.3403 - accuracy: 0.8826 - precision: 0.8918 - recall: 0.8709 - val_loss: 1.4803 - val_accuracy: 0.6127 - val_precision: 0.6143 - val_recall: 0.6056\n",
      "Epoch 177/200\n",
      "426/426 - 1s - loss: 0.2045 - accuracy: 0.9131 - precision: 0.9281 - recall: 0.9085 - val_loss: 1.3438 - val_accuracy: 0.6127 - val_precision: 0.6316 - val_recall: 0.5915\n",
      "Epoch 178/200\n",
      "426/426 - 1s - loss: 0.2406 - accuracy: 0.9249 - precision: 0.9324 - recall: 0.9061 - val_loss: 1.4085 - val_accuracy: 0.5915 - val_precision: 0.6124 - val_recall: 0.5563\n",
      "Epoch 179/200\n",
      "426/426 - 1s - loss: 0.2443 - accuracy: 0.9131 - precision: 0.9253 - recall: 0.9014 - val_loss: 1.4321 - val_accuracy: 0.6197 - val_precision: 0.6484 - val_recall: 0.5845\n",
      "Epoch 180/200\n",
      "426/426 - 1s - loss: 0.2966 - accuracy: 0.8826 - precision: 0.8935 - recall: 0.8662 - val_loss: 1.4177 - val_accuracy: 0.6197 - val_precision: 0.6308 - val_recall: 0.5775\n",
      "Epoch 181/200\n",
      "426/426 - 1s - loss: 0.2154 - accuracy: 0.9131 - precision: 0.9320 - recall: 0.9014 - val_loss: 1.3944 - val_accuracy: 0.6268 - val_precision: 0.6336 - val_recall: 0.5845\n",
      "Epoch 182/200\n",
      "426/426 - 1s - loss: 0.2572 - accuracy: 0.9061 - precision: 0.9139 - recall: 0.8967 - val_loss: 1.5845 - val_accuracy: 0.5775 - val_precision: 0.5954 - val_recall: 0.5493\n",
      "Epoch 183/200\n",
      "426/426 - 1s - loss: 0.2566 - accuracy: 0.9108 - precision: 0.9183 - recall: 0.8967 - val_loss: 1.5613 - val_accuracy: 0.6056 - val_precision: 0.6131 - val_recall: 0.5915\n",
      "Epoch 184/200\n",
      "426/426 - 1s - loss: 0.3582 - accuracy: 0.8615 - precision: 0.8854 - recall: 0.8521 - val_loss: 1.2346 - val_accuracy: 0.6690 - val_precision: 0.6667 - val_recall: 0.6479\n",
      "Epoch 185/200\n",
      "426/426 - 1s - loss: 0.1947 - accuracy: 0.9272 - precision: 0.9351 - recall: 0.9131 - val_loss: 1.4324 - val_accuracy: 0.6268 - val_precision: 0.6519 - val_recall: 0.6197\n",
      "Epoch 186/200\n",
      "426/426 - 1s - loss: 0.1744 - accuracy: 0.9343 - precision: 0.9474 - recall: 0.9296 - val_loss: 1.5544 - val_accuracy: 0.6056 - val_precision: 0.6176 - val_recall: 0.5915\n",
      "Epoch 187/200\n",
      "426/426 - 1s - loss: 0.1500 - accuracy: 0.9460 - precision: 0.9568 - recall: 0.9366 - val_loss: 1.3722 - val_accuracy: 0.6690 - val_precision: 0.6715 - val_recall: 0.6479\n",
      "Epoch 188/200\n",
      "426/426 - 1s - loss: 0.3570 - accuracy: 0.8967 - precision: 0.9026 - recall: 0.8920 - val_loss: 1.8117 - val_accuracy: 0.5845 - val_precision: 0.5870 - val_recall: 0.5704\n",
      "Epoch 189/200\n",
      "426/426 - 1s - loss: 0.3376 - accuracy: 0.8850 - precision: 0.9062 - recall: 0.8850 - val_loss: 1.3740 - val_accuracy: 0.6549 - val_precision: 0.6642 - val_recall: 0.6408\n",
      "Epoch 190/200\n",
      "426/426 - 1s - loss: 0.2446 - accuracy: 0.9061 - precision: 0.9163 - recall: 0.8991 - val_loss: 1.6210 - val_accuracy: 0.6056 - val_precision: 0.6165 - val_recall: 0.5775\n",
      "Epoch 191/200\n",
      "426/426 - 1s - loss: 0.2523 - accuracy: 0.9155 - precision: 0.9231 - recall: 0.9014 - val_loss: 1.4969 - val_accuracy: 0.6197 - val_precision: 0.6222 - val_recall: 0.5915\n",
      "Epoch 192/200\n",
      "426/426 - 1s - loss: 0.3313 - accuracy: 0.8779 - precision: 0.8937 - recall: 0.8685 - val_loss: 1.4648 - val_accuracy: 0.6127 - val_precision: 0.6269 - val_recall: 0.5915\n",
      "Epoch 193/200\n",
      "426/426 - 1s - loss: 0.1927 - accuracy: 0.9390 - precision: 0.9541 - recall: 0.9272 - val_loss: 1.4717 - val_accuracy: 0.5845 - val_precision: 0.6090 - val_recall: 0.5704\n",
      "Epoch 194/200\n",
      "426/426 - 1s - loss: 0.3298 - accuracy: 0.9038 - precision: 0.9175 - recall: 0.8873 - val_loss: 1.4153 - val_accuracy: 0.5986 - val_precision: 0.6288 - val_recall: 0.5845\n",
      "Epoch 195/200\n",
      "426/426 - 1s - loss: 0.2180 - accuracy: 0.9155 - precision: 0.9301 - recall: 0.9061 - val_loss: 1.5149 - val_accuracy: 0.5986 - val_precision: 0.6077 - val_recall: 0.5563\n",
      "Epoch 196/200\n",
      "426/426 - 1s - loss: 0.2805 - accuracy: 0.9038 - precision: 0.9143 - recall: 0.9014 - val_loss: 1.5183 - val_accuracy: 0.6268 - val_precision: 0.6471 - val_recall: 0.6197\n",
      "Epoch 197/200\n",
      "426/426 - 1s - loss: 0.1851 - accuracy: 0.9343 - precision: 0.9430 - recall: 0.9319 - val_loss: 1.5214 - val_accuracy: 0.6197 - val_precision: 0.6397 - val_recall: 0.6127\n",
      "Epoch 198/200\n",
      "426/426 - 1s - loss: 0.2386 - accuracy: 0.9272 - precision: 0.9349 - recall: 0.9108 - val_loss: 1.5788 - val_accuracy: 0.6127 - val_precision: 0.6204 - val_recall: 0.5986\n",
      "Epoch 199/200\n",
      "426/426 - 1s - loss: 0.2508 - accuracy: 0.9343 - precision: 0.9382 - recall: 0.9272 - val_loss: 1.4477 - val_accuracy: 0.6268 - val_precision: 0.6370 - val_recall: 0.6056\n",
      "Epoch 200/200\n",
      "426/426 - 1s - loss: 0.2325 - accuracy: 0.9178 - precision: 0.9258 - recall: 0.9085 - val_loss: 1.8002 - val_accuracy: 0.5352 - val_precision: 0.5522 - val_recall: 0.5211\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 0ba4021e31e026dd330fdf489741f30d</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6877934336662292</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_1_units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_2_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_End: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_input: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-optimizer: RMSprop</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "{'LSTM_input': 192, 'n_layers': 3, 'LSTM_0_units': 192, 'LSTM_End': 96, 'optimizer': 'Adamax', 'LSTM_1_units': 128, 'LSTM_2_units': 64}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Results in C:\\ML\\Optimization_2020_07_15_201918\\SignLagnuageModelOptimization</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Objective(name='val_accuracy', direction='max')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: d2659a21f40236c9e87c1a968a35c794</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8051643371582031</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_1_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_2_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_End: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_input: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-optimizer: Adamax</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 442de4ecfab311efee97ef64a88bc6e4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7957746386528015</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_1_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_2_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_End: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_input: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-optimizer: Adagrad</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: c149d005c2611a9fa59edf1cc6d79e66</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7089201807975769</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_1_units: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_End: 64</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_input: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-optimizer: RMSprop</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 0ba4021e31e026dd330fdf489741f30d</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6877934336662292</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_0_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_1_units: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_2_units: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-LSTM_End: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-LSTM_input: 192</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-optimizer: RMSprop</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "tuner  = RandomSearch(\n",
    "    build_model_lstm,     #Function to use search in... See different builds above\n",
    "    objective = \"val_accuracy\",  #Chooses \"best model\" looking for highest value of val_accuracy\n",
    "    max_trials = 4,       # Number of different combinations tried Nodes and layers\n",
    "    executions_per_trial = 3, \n",
    "    directory = LOG_DIR,\n",
    "    project_name='SignLagnuageModelOptimization'\n",
    "    )\n",
    "\n",
    "#tuner.search_space_summary()\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, min_delta=0.1, patience=5, min_lr=0.001)\n",
    "\n",
    "tuner.search(x=x_train,      #syntax just like in fit\n",
    "                y= y_train,\n",
    "            epochs=200,\n",
    "            batch_size=32,\n",
    "            validation_data=(x_val,y_val),\n",
    "            verbose=2,\n",
    "            callbacks=[reduce_lr]\n",
    "            #callbacks=[wandb.keras.WandbCallback()]\n",
    "            )\n",
    "\n",
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.results_summary())\n",
    "\n",
    "\n",
    "# wandb.keras.WandbCallback()\n",
    "\n",
    "finished(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Hyperband\n",
    "Variation of RandomSearch http://jmlr.org/papers/volume18/16-558/16-558.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner  = Hyperband(\n",
    "    build_model,\n",
    "    objective = \"val_accuracy\",\n",
    "    hyperband_iterations=2,\n",
    "    max_epochs=150,\n",
    "    directory = LOG_DIR,\n",
    "    project_name='SignLagnuageModelOptimization'\n",
    "    )\n",
    "\n",
    "#tuner.search_space_summary()\n",
    "\n",
    "tuner.search(x=x_train, \n",
    "            y= y_train,\n",
    "            batch_size=32,\n",
    "            validation_data=(x_val,y_val))\n",
    "\n",
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "print(tuner.results_summary())\n",
    "\n",
    "finished(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laut Randomsearch bestes Model am 23.06.2020\n",
    "epochs=170\n",
    "model = Sequential()\n",
    "model.add(layers.LSTM(128, return_sequences=True,\n",
    "               input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(layers.LSTM(64, return_sequences=True)) \n",
    "model.add(layers.LSTM(96))  \n",
    "model.add(layers.Dense(12, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),tf.keras.metrics.AUC()])\n",
    "model.summary()\n",
    "\n",
    "history=model.fit(x_train,y_train,epochs=epochs,validation_data=(x_val,y_val),shuffle=False,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec=history.history['val_precision_2'][epochs-1]\n",
    "rec=history.history['val_recall_2'][epochs-1]\n",
    "print(prec)\n",
    "print(rec)\n",
    "\n",
    "\n",
    "f1= 2*((prec*rec)/(prec+rec))\n",
    "print (f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export tuner object into pickle file\n",
    "so it can be used in other scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"tuner_\"f\"{starttime}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tuner, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get best Trial from Tuner Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 192)          214272    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 192)          295680    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 128)          164352    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 64)           49408     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1164      \n",
      "=================================================================\n",
      "Total params: 786,700\n",
      "Trainable params: 786,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Adamax\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 192)          214272    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 192)          295680    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 128)          164352    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 64)           49408     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 96)                61824     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                1164      \n",
      "=================================================================\n",
      "Total params: 786,700\n",
      "Trainable params: 786,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "bestmodel= tuner.hypermodel.build(best_hp)\n",
    "\n",
    "bestmodel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples, validate on 142 samples\n",
      "Epoch 1/200\n",
      "426/426 - 1s - loss: 2.1184 - accuracy: 0.2089 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9701 - val_accuracy: 0.2746 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      "426/426 - 1s - loss: 1.9338 - accuracy: 0.2629 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8400 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/200\n",
      "426/426 - 1s - loss: 1.8502 - accuracy: 0.2465 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.8005 - val_accuracy: 0.2254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/200\n",
      "426/426 - 1s - loss: 1.8488 - accuracy: 0.2840 - precision: 0.4667 - recall: 0.0164 - val_loss: 1.7787 - val_accuracy: 0.2324 - val_precision: 0.6250 - val_recall: 0.0352\n",
      "Epoch 5/200\n",
      "426/426 - 1s - loss: 1.8208 - accuracy: 0.2676 - precision: 0.5238 - recall: 0.0258 - val_loss: 1.7702 - val_accuracy: 0.2465 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 6/200\n",
      "426/426 - 1s - loss: 1.8131 - accuracy: 0.2887 - precision: 0.5500 - recall: 0.0258 - val_loss: 1.7599 - val_accuracy: 0.2113 - val_precision: 0.8000 - val_recall: 0.0282\n",
      "Epoch 7/200\n",
      "426/426 - 1s - loss: 1.7885 - accuracy: 0.2887 - precision: 0.5882 - recall: 0.0235 - val_loss: 1.7555 - val_accuracy: 0.2042 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 8/200\n",
      "426/426 - 1s - loss: 1.7644 - accuracy: 0.3099 - precision: 0.5263 - recall: 0.0235 - val_loss: 1.7552 - val_accuracy: 0.2324 - val_precision: 1.0000 - val_recall: 0.0282\n",
      "Epoch 9/200\n",
      "426/426 - 1s - loss: 1.7462 - accuracy: 0.2934 - precision: 0.5882 - recall: 0.0235 - val_loss: 1.7468 - val_accuracy: 0.2113 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 10/200\n",
      "426/426 - 1s - loss: 1.7280 - accuracy: 0.3146 - precision: 0.5556 - recall: 0.0235 - val_loss: 1.7382 - val_accuracy: 0.2324 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 11/200\n",
      "426/426 - 1s - loss: 1.7195 - accuracy: 0.3263 - precision: 0.5556 - recall: 0.0235 - val_loss: 1.7462 - val_accuracy: 0.2254 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 12/200\n",
      "426/426 - 1s - loss: 1.7236 - accuracy: 0.3286 - precision: 0.6250 - recall: 0.0235 - val_loss: 1.7746 - val_accuracy: 0.2254 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 13/200\n",
      "426/426 - 1s - loss: 1.6933 - accuracy: 0.3286 - precision: 0.6250 - recall: 0.0235 - val_loss: 1.7295 - val_accuracy: 0.2535 - val_precision: 1.0000 - val_recall: 0.0211\n",
      "Epoch 14/200\n",
      "426/426 - 1s - loss: 1.6427 - accuracy: 0.3662 - precision: 0.6000 - recall: 0.0282 - val_loss: 1.7036 - val_accuracy: 0.2746 - val_precision: 0.7273 - val_recall: 0.0563\n",
      "Epoch 15/200\n",
      "426/426 - 1s - loss: 1.6399 - accuracy: 0.3122 - precision: 0.6667 - recall: 0.0423 - val_loss: 1.6003 - val_accuracy: 0.3028 - val_precision: 0.7500 - val_recall: 0.0634\n",
      "Epoch 16/200\n",
      "426/426 - 1s - loss: 1.5832 - accuracy: 0.3498 - precision: 0.6774 - recall: 0.0493 - val_loss: 1.5356 - val_accuracy: 0.3803 - val_precision: 0.5714 - val_recall: 0.0845\n",
      "Epoch 17/200\n",
      "426/426 - 1s - loss: 1.5342 - accuracy: 0.4178 - precision: 0.6596 - recall: 0.0728 - val_loss: 1.4864 - val_accuracy: 0.3732 - val_precision: 0.6875 - val_recall: 0.0775\n",
      "Epoch 18/200\n",
      "426/426 - 1s - loss: 1.4798 - accuracy: 0.4155 - precision: 0.7671 - recall: 0.1315 - val_loss: 1.4410 - val_accuracy: 0.3873 - val_precision: 0.6944 - val_recall: 0.1761\n",
      "Epoch 19/200\n",
      "426/426 - 1s - loss: 1.4195 - accuracy: 0.4437 - precision: 0.7308 - recall: 0.1784 - val_loss: 1.4453 - val_accuracy: 0.3944 - val_precision: 0.6765 - val_recall: 0.1620\n",
      "Epoch 20/200\n",
      "426/426 - 1s - loss: 1.3803 - accuracy: 0.4507 - precision: 0.7177 - recall: 0.2089 - val_loss: 1.4534 - val_accuracy: 0.4155 - val_precision: 0.6765 - val_recall: 0.1620\n",
      "Epoch 21/200\n",
      "426/426 - 1s - loss: 1.3779 - accuracy: 0.4531 - precision: 0.7016 - recall: 0.2042 - val_loss: 1.4818 - val_accuracy: 0.3662 - val_precision: 0.6053 - val_recall: 0.1620\n",
      "Epoch 22/200\n",
      "426/426 - 1s - loss: 1.3526 - accuracy: 0.4484 - precision: 0.7540 - recall: 0.2230 - val_loss: 1.5522 - val_accuracy: 0.3944 - val_precision: 0.6579 - val_recall: 0.1761\n",
      "Epoch 23/200\n",
      "426/426 - 1s - loss: 1.3580 - accuracy: 0.4812 - precision: 0.6992 - recall: 0.2183 - val_loss: 1.4994 - val_accuracy: 0.3944 - val_precision: 0.6923 - val_recall: 0.1901\n",
      "Epoch 24/200\n",
      "426/426 - 1s - loss: 1.2758 - accuracy: 0.4789 - precision: 0.7803 - recall: 0.2418 - val_loss: 1.3990 - val_accuracy: 0.4577 - val_precision: 0.6316 - val_recall: 0.2535\n",
      "Epoch 25/200\n",
      "426/426 - 1s - loss: 1.2101 - accuracy: 0.5282 - precision: 0.7434 - recall: 0.2653 - val_loss: 1.2987 - val_accuracy: 0.4789 - val_precision: 0.6735 - val_recall: 0.2324\n",
      "Epoch 26/200\n",
      "426/426 - 1s - loss: 1.1692 - accuracy: 0.5423 - precision: 0.7278 - recall: 0.2887 - val_loss: 1.4077 - val_accuracy: 0.4085 - val_precision: 0.6364 - val_recall: 0.2465\n",
      "Epoch 27/200\n",
      "426/426 - 1s - loss: 1.1926 - accuracy: 0.4977 - precision: 0.7432 - recall: 0.3192 - val_loss: 1.1149 - val_accuracy: 0.5845 - val_precision: 0.7937 - val_recall: 0.3521\n",
      "Epoch 28/200\n",
      "426/426 - 1s - loss: 1.0743 - accuracy: 0.5775 - precision: 0.7882 - recall: 0.3146 - val_loss: 1.1404 - val_accuracy: 0.5563 - val_precision: 0.7288 - val_recall: 0.3028\n",
      "Epoch 29/200\n",
      "426/426 - 1s - loss: 1.1281 - accuracy: 0.5587 - precision: 0.6912 - recall: 0.3310 - val_loss: 1.2311 - val_accuracy: 0.4789 - val_precision: 0.6418 - val_recall: 0.3028\n",
      "Epoch 30/200\n",
      "426/426 - 1s - loss: 1.0934 - accuracy: 0.5376 - precision: 0.7602 - recall: 0.3498 - val_loss: 1.2339 - val_accuracy: 0.4789 - val_precision: 0.7000 - val_recall: 0.3451\n",
      "Epoch 31/200\n",
      "426/426 - 1s - loss: 1.0617 - accuracy: 0.5751 - precision: 0.7048 - recall: 0.3756 - val_loss: 1.0873 - val_accuracy: 0.5423 - val_precision: 0.6892 - val_recall: 0.3592\n",
      "Epoch 32/200\n",
      "426/426 - 1s - loss: 1.0000 - accuracy: 0.5798 - precision: 0.7789 - recall: 0.3474 - val_loss: 1.0031 - val_accuracy: 0.5986 - val_precision: 0.8065 - val_recall: 0.3521\n",
      "Epoch 33/200\n",
      "426/426 - 1s - loss: 0.8732 - accuracy: 0.6526 - precision: 0.8041 - recall: 0.4624 - val_loss: 1.2482 - val_accuracy: 0.4930 - val_precision: 0.6585 - val_recall: 0.3803\n",
      "Epoch 34/200\n",
      "426/426 - 1s - loss: 1.0027 - accuracy: 0.6033 - precision: 0.7248 - recall: 0.4390 - val_loss: 1.1454 - val_accuracy: 0.5493 - val_precision: 0.6750 - val_recall: 0.3803\n",
      "Epoch 35/200\n",
      "426/426 - 1s - loss: 1.0291 - accuracy: 0.5892 - precision: 0.6914 - recall: 0.4366 - val_loss: 1.2946 - val_accuracy: 0.5070 - val_precision: 0.6494 - val_recall: 0.3521\n",
      "Epoch 36/200\n",
      "426/426 - 1s - loss: 0.9866 - accuracy: 0.6033 - precision: 0.7500 - recall: 0.4296 - val_loss: 1.0760 - val_accuracy: 0.5352 - val_precision: 0.6875 - val_recall: 0.3873\n",
      "Epoch 37/200\n",
      "426/426 - 1s - loss: 0.9263 - accuracy: 0.6502 - precision: 0.7814 - recall: 0.4531 - val_loss: 1.1984 - val_accuracy: 0.5282 - val_precision: 0.6061 - val_recall: 0.4225\n",
      "Epoch 38/200\n",
      "426/426 - 1s - loss: 0.9208 - accuracy: 0.6268 - precision: 0.7565 - recall: 0.4812 - val_loss: 1.0032 - val_accuracy: 0.5845 - val_precision: 0.7159 - val_recall: 0.4437\n",
      "Epoch 39/200\n",
      "426/426 - 1s - loss: 0.8188 - accuracy: 0.6737 - precision: 0.8007 - recall: 0.5282 - val_loss: 1.3284 - val_accuracy: 0.5070 - val_precision: 0.5701 - val_recall: 0.4296\n",
      "Epoch 40/200\n",
      "426/426 - 1s - loss: 1.1581 - accuracy: 0.5469 - precision: 0.6970 - recall: 0.4319 - val_loss: 1.0626 - val_accuracy: 0.5775 - val_precision: 0.7625 - val_recall: 0.4296\n",
      "Epoch 41/200\n",
      "426/426 - 1s - loss: 0.8795 - accuracy: 0.6549 - precision: 0.8206 - recall: 0.5047 - val_loss: 1.0021 - val_accuracy: 0.5915 - val_precision: 0.7158 - val_recall: 0.4789\n",
      "Epoch 42/200\n",
      "426/426 - 1s - loss: 0.8664 - accuracy: 0.6502 - precision: 0.7782 - recall: 0.5023 - val_loss: 1.1226 - val_accuracy: 0.5423 - val_precision: 0.6882 - val_recall: 0.4507\n",
      "Epoch 43/200\n",
      "426/426 - 1s - loss: 0.8794 - accuracy: 0.6526 - precision: 0.7649 - recall: 0.4812 - val_loss: 1.1568 - val_accuracy: 0.5070 - val_precision: 0.6122 - val_recall: 0.4225\n",
      "Epoch 44/200\n",
      "426/426 - 1s - loss: 0.8726 - accuracy: 0.6526 - precision: 0.7492 - recall: 0.5188 - val_loss: 1.0436 - val_accuracy: 0.5493 - val_precision: 0.6957 - val_recall: 0.4507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200\n",
      "426/426 - 1s - loss: 0.9083 - accuracy: 0.6620 - precision: 0.7601 - recall: 0.5282 - val_loss: 1.5464 - val_accuracy: 0.4296 - val_precision: 0.6173 - val_recall: 0.3521\n",
      "Epoch 46/200\n",
      "426/426 - 1s - loss: 1.3687 - accuracy: 0.4953 - precision: 0.6872 - recall: 0.3404 - val_loss: 1.2339 - val_accuracy: 0.5211 - val_precision: 0.7838 - val_recall: 0.4085\n",
      "Epoch 47/200\n",
      "426/426 - 1s - loss: 1.0951 - accuracy: 0.5610 - precision: 0.7425 - recall: 0.4061 - val_loss: 1.1194 - val_accuracy: 0.5563 - val_precision: 0.7011 - val_recall: 0.4296\n",
      "Epoch 48/200\n",
      "426/426 - 1s - loss: 0.9432 - accuracy: 0.6502 - precision: 0.7978 - recall: 0.5000 - val_loss: 1.1362 - val_accuracy: 0.5352 - val_precision: 0.7412 - val_recall: 0.4437\n",
      "Epoch 49/200\n",
      "426/426 - 1s - loss: 0.7883 - accuracy: 0.6995 - precision: 0.8112 - recall: 0.5446 - val_loss: 0.9849 - val_accuracy: 0.6127 - val_precision: 0.7684 - val_recall: 0.5141\n",
      "Epoch 50/200\n",
      "426/426 - 1s - loss: 0.7147 - accuracy: 0.7418 - precision: 0.8449 - recall: 0.6009 - val_loss: 1.0117 - val_accuracy: 0.6268 - val_precision: 0.7075 - val_recall: 0.5282\n",
      "Epoch 51/200\n",
      "426/426 - 1s - loss: 0.7003 - accuracy: 0.7394 - precision: 0.8217 - recall: 0.6056 - val_loss: 0.9628 - val_accuracy: 0.6197 - val_precision: 0.7500 - val_recall: 0.5282\n",
      "Epoch 52/200\n",
      "426/426 - 1s - loss: 0.7337 - accuracy: 0.7300 - precision: 0.8185 - recall: 0.5822 - val_loss: 0.9114 - val_accuracy: 0.6549 - val_precision: 0.7426 - val_recall: 0.5282\n",
      "Epoch 53/200\n",
      "426/426 - 1s - loss: 0.6936 - accuracy: 0.7371 - precision: 0.8088 - recall: 0.6056 - val_loss: 0.9621 - val_accuracy: 0.6620 - val_precision: 0.7143 - val_recall: 0.5634\n",
      "Epoch 54/200\n",
      "426/426 - 1s - loss: 0.6587 - accuracy: 0.7535 - precision: 0.8101 - recall: 0.6408 - val_loss: 1.0102 - val_accuracy: 0.5775 - val_precision: 0.6857 - val_recall: 0.5070\n",
      "Epoch 55/200\n",
      "426/426 - 1s - loss: 0.6760 - accuracy: 0.7700 - precision: 0.8323 - recall: 0.6291 - val_loss: 0.9641 - val_accuracy: 0.6197 - val_precision: 0.7018 - val_recall: 0.5634\n",
      "Epoch 56/200\n",
      "426/426 - 1s - loss: 0.6264 - accuracy: 0.7629 - precision: 0.8281 - recall: 0.6784 - val_loss: 0.9177 - val_accuracy: 0.6338 - val_precision: 0.7611 - val_recall: 0.6056\n",
      "Epoch 57/200\n",
      "426/426 - 1s - loss: 0.6177 - accuracy: 0.7606 - precision: 0.8167 - recall: 0.6901 - val_loss: 0.9708 - val_accuracy: 0.5915 - val_precision: 0.6930 - val_recall: 0.5563\n",
      "Epoch 58/200\n",
      "426/426 - 1s - loss: 0.7338 - accuracy: 0.7207 - precision: 0.7905 - recall: 0.6643 - val_loss: 1.0648 - val_accuracy: 0.5845 - val_precision: 0.6529 - val_recall: 0.5563\n",
      "Epoch 59/200\n",
      "426/426 - 2s - loss: 0.6589 - accuracy: 0.7535 - precision: 0.8033 - recall: 0.6901 - val_loss: 1.0200 - val_accuracy: 0.5845 - val_precision: 0.6283 - val_recall: 0.5000\n",
      "Epoch 60/200\n",
      "426/426 - 1s - loss: 0.7676 - accuracy: 0.6737 - precision: 0.7337 - recall: 0.5822 - val_loss: 0.9534 - val_accuracy: 0.6056 - val_precision: 0.6721 - val_recall: 0.5775\n",
      "Epoch 61/200\n",
      "426/426 - 1s - loss: 0.7192 - accuracy: 0.7254 - precision: 0.7699 - recall: 0.6596 - val_loss: 0.9752 - val_accuracy: 0.5845 - val_precision: 0.6303 - val_recall: 0.5282\n",
      "Epoch 62/200\n",
      "426/426 - 1s - loss: 0.6172 - accuracy: 0.7629 - precision: 0.8072 - recall: 0.6878 - val_loss: 0.9678 - val_accuracy: 0.6056 - val_precision: 0.6917 - val_recall: 0.5845\n",
      "Epoch 63/200\n",
      "426/426 - 1s - loss: 0.5705 - accuracy: 0.7958 - precision: 0.8462 - recall: 0.7230 - val_loss: 0.9782 - val_accuracy: 0.6338 - val_precision: 0.6935 - val_recall: 0.6056\n",
      "Epoch 64/200\n",
      "426/426 - 1s - loss: 0.7049 - accuracy: 0.7441 - precision: 0.7819 - recall: 0.6901 - val_loss: 1.0137 - val_accuracy: 0.6549 - val_precision: 0.6803 - val_recall: 0.5845\n",
      "Epoch 65/200\n",
      "426/426 - 1s - loss: 0.6244 - accuracy: 0.7746 - precision: 0.8274 - recall: 0.7089 - val_loss: 0.9292 - val_accuracy: 0.6408 - val_precision: 0.7241 - val_recall: 0.5915\n",
      "Epoch 66/200\n",
      "426/426 - 1s - loss: 0.5743 - accuracy: 0.7793 - precision: 0.8329 - recall: 0.7136 - val_loss: 0.9017 - val_accuracy: 0.6479 - val_precision: 0.7281 - val_recall: 0.5845\n",
      "Epoch 67/200\n",
      "426/426 - 1s - loss: 0.5879 - accuracy: 0.7793 - precision: 0.8421 - recall: 0.7136 - val_loss: 0.8696 - val_accuracy: 0.6549 - val_precision: 0.7177 - val_recall: 0.6268\n",
      "Epoch 68/200\n",
      "426/426 - 1s - loss: 0.5464 - accuracy: 0.7981 - precision: 0.8468 - recall: 0.7136 - val_loss: 1.0056 - val_accuracy: 0.6197 - val_precision: 0.6864 - val_recall: 0.5704\n",
      "Epoch 69/200\n",
      "426/426 - 1s - loss: 0.5065 - accuracy: 0.8005 - precision: 0.8634 - recall: 0.7418 - val_loss: 0.9515 - val_accuracy: 0.6408 - val_precision: 0.7054 - val_recall: 0.6408\n",
      "Epoch 70/200\n",
      "426/426 - 1s - loss: 0.5449 - accuracy: 0.7958 - precision: 0.8294 - recall: 0.7418 - val_loss: 0.9071 - val_accuracy: 0.6690 - val_precision: 0.7222 - val_recall: 0.6408\n",
      "Epoch 71/200\n",
      "426/426 - 1s - loss: 0.5011 - accuracy: 0.8192 - precision: 0.8568 - recall: 0.7723 - val_loss: 0.9394 - val_accuracy: 0.5845 - val_precision: 0.6378 - val_recall: 0.5704\n",
      "Epoch 72/200\n",
      "426/426 - 1s - loss: 0.5061 - accuracy: 0.8028 - precision: 0.8468 - recall: 0.7653 - val_loss: 0.8841 - val_accuracy: 0.7113 - val_precision: 0.7209 - val_recall: 0.6549\n",
      "Epoch 73/200\n",
      "426/426 - 1s - loss: 0.5516 - accuracy: 0.8169 - precision: 0.8549 - recall: 0.7746 - val_loss: 1.0602 - val_accuracy: 0.6127 - val_precision: 0.6489 - val_recall: 0.5986\n",
      "Epoch 74/200\n",
      "426/426 - 1s - loss: 0.5971 - accuracy: 0.7934 - precision: 0.8112 - recall: 0.7465 - val_loss: 1.3626 - val_accuracy: 0.5282 - val_precision: 0.5469 - val_recall: 0.4930\n",
      "Epoch 75/200\n",
      "426/426 - 1s - loss: 0.8531 - accuracy: 0.6714 - precision: 0.7193 - recall: 0.6197 - val_loss: 1.1538 - val_accuracy: 0.5493 - val_precision: 0.5902 - val_recall: 0.5070\n",
      "Epoch 76/200\n",
      "426/426 - 1s - loss: 0.6262 - accuracy: 0.7347 - precision: 0.7790 - recall: 0.6784 - val_loss: 1.2117 - val_accuracy: 0.5423 - val_precision: 0.5814 - val_recall: 0.5282\n",
      "Epoch 77/200\n",
      "426/426 - 1s - loss: 0.5749 - accuracy: 0.7934 - precision: 0.8155 - recall: 0.7160 - val_loss: 0.9605 - val_accuracy: 0.6408 - val_precision: 0.6885 - val_recall: 0.5915\n",
      "Epoch 78/200\n",
      "426/426 - 1s - loss: 0.5375 - accuracy: 0.8169 - precision: 0.8389 - recall: 0.7700 - val_loss: 0.8691 - val_accuracy: 0.7183 - val_precision: 0.7440 - val_recall: 0.6549\n",
      "Epoch 79/200\n",
      "426/426 - 1s - loss: 0.4885 - accuracy: 0.8169 - precision: 0.8520 - recall: 0.7840 - val_loss: 0.9183 - val_accuracy: 0.6831 - val_precision: 0.7031 - val_recall: 0.6338\n",
      "Epoch 80/200\n",
      "426/426 - 1s - loss: 0.4300 - accuracy: 0.8451 - precision: 0.8756 - recall: 0.8099 - val_loss: 0.8415 - val_accuracy: 0.7042 - val_precision: 0.7328 - val_recall: 0.6761\n",
      "Epoch 81/200\n",
      "426/426 - 1s - loss: 0.3974 - accuracy: 0.8545 - precision: 0.8886 - recall: 0.8239 - val_loss: 0.9326 - val_accuracy: 0.6620 - val_precision: 0.6917 - val_recall: 0.6479\n",
      "Epoch 82/200\n",
      "426/426 - 1s - loss: 0.4629 - accuracy: 0.8404 - precision: 0.8628 - recall: 0.8122 - val_loss: 0.9165 - val_accuracy: 0.6831 - val_precision: 0.6977 - val_recall: 0.6338\n",
      "Epoch 83/200\n",
      "426/426 - 1s - loss: 0.4304 - accuracy: 0.8474 - precision: 0.8817 - recall: 0.8052 - val_loss: 0.9450 - val_accuracy: 0.6549 - val_precision: 0.6692 - val_recall: 0.6268\n",
      "Epoch 84/200\n",
      "426/426 - 1s - loss: 0.4361 - accuracy: 0.8568 - precision: 0.8800 - recall: 0.8263 - val_loss: 0.8790 - val_accuracy: 0.6901 - val_precision: 0.6985 - val_recall: 0.6690\n",
      "Epoch 85/200\n",
      "426/426 - 1s - loss: 0.4108 - accuracy: 0.8685 - precision: 0.8864 - recall: 0.8427 - val_loss: 0.9875 - val_accuracy: 0.6761 - val_precision: 0.6815 - val_recall: 0.6479\n",
      "Epoch 86/200\n",
      "426/426 - 1s - loss: 0.4771 - accuracy: 0.8427 - precision: 0.8564 - recall: 0.8263 - val_loss: 0.9619 - val_accuracy: 0.6901 - val_precision: 0.6912 - val_recall: 0.6620\n",
      "Epoch 87/200\n",
      "426/426 - 1s - loss: 0.4568 - accuracy: 0.8474 - precision: 0.8753 - recall: 0.8239 - val_loss: 0.8987 - val_accuracy: 0.6620 - val_precision: 0.7023 - val_recall: 0.6479\n",
      "Epoch 88/200\n",
      "426/426 - 1s - loss: 0.3926 - accuracy: 0.8756 - precision: 0.8955 - recall: 0.8451 - val_loss: 1.1205 - val_accuracy: 0.5845 - val_precision: 0.6231 - val_recall: 0.5704\n",
      "Epoch 89/200\n",
      "426/426 - 1s - loss: 0.5529 - accuracy: 0.8122 - precision: 0.8337 - recall: 0.7887 - val_loss: 1.0505 - val_accuracy: 0.6408 - val_precision: 0.6716 - val_recall: 0.6338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200\n",
      "426/426 - 1s - loss: 0.5055 - accuracy: 0.7981 - precision: 0.8284 - recall: 0.7817 - val_loss: 0.8869 - val_accuracy: 0.6831 - val_precision: 0.7323 - val_recall: 0.6549\n",
      "Epoch 91/200\n",
      "426/426 - 1s - loss: 0.3760 - accuracy: 0.8685 - precision: 0.8936 - recall: 0.8474 - val_loss: 0.8648 - val_accuracy: 0.6901 - val_precision: 0.7252 - val_recall: 0.6690\n",
      "Epoch 92/200\n",
      "426/426 - 1s - loss: 0.3770 - accuracy: 0.8685 - precision: 0.8978 - recall: 0.8451 - val_loss: 0.9580 - val_accuracy: 0.6761 - val_precision: 0.6815 - val_recall: 0.6479\n",
      "Epoch 93/200\n",
      "426/426 - 1s - loss: 0.4648 - accuracy: 0.8357 - precision: 0.8564 - recall: 0.8122 - val_loss: 1.0151 - val_accuracy: 0.6620 - val_precision: 0.6889 - val_recall: 0.6549\n",
      "Epoch 94/200\n",
      "426/426 - 1s - loss: 0.4330 - accuracy: 0.8474 - precision: 0.8589 - recall: 0.8286 - val_loss: 0.8576 - val_accuracy: 0.7183 - val_precision: 0.7287 - val_recall: 0.6620\n",
      "Epoch 95/200\n",
      "426/426 - 1s - loss: 0.4142 - accuracy: 0.8568 - precision: 0.8806 - recall: 0.8310 - val_loss: 0.9676 - val_accuracy: 0.6901 - val_precision: 0.7143 - val_recall: 0.6690\n",
      "Epoch 96/200\n",
      "426/426 - 1s - loss: 0.4570 - accuracy: 0.8380 - precision: 0.8633 - recall: 0.8005 - val_loss: 0.9610 - val_accuracy: 0.6972 - val_precision: 0.7328 - val_recall: 0.6761\n",
      "Epoch 97/200\n",
      "426/426 - 1s - loss: 0.4889 - accuracy: 0.8451 - precision: 0.8627 - recall: 0.8263 - val_loss: 0.9632 - val_accuracy: 0.6761 - val_precision: 0.6917 - val_recall: 0.6479\n",
      "Epoch 98/200\n",
      "426/426 - 1s - loss: 0.4319 - accuracy: 0.8545 - precision: 0.8710 - recall: 0.8239 - val_loss: 0.8389 - val_accuracy: 0.7042 - val_precision: 0.7460 - val_recall: 0.6620\n",
      "Epoch 99/200\n",
      "426/426 - 1s - loss: 0.3548 - accuracy: 0.8826 - precision: 0.9005 - recall: 0.8498 - val_loss: 0.9468 - val_accuracy: 0.6549 - val_precision: 0.7063 - val_recall: 0.6268\n",
      "Epoch 100/200\n",
      "426/426 - 1s - loss: 0.3536 - accuracy: 0.8873 - precision: 0.8976 - recall: 0.8638 - val_loss: 0.9902 - val_accuracy: 0.6761 - val_precision: 0.6992 - val_recall: 0.6549\n",
      "Epoch 101/200\n",
      "426/426 - 1s - loss: 0.3743 - accuracy: 0.8732 - precision: 0.8897 - recall: 0.8521 - val_loss: 0.9293 - val_accuracy: 0.6972 - val_precision: 0.7143 - val_recall: 0.6690\n",
      "Epoch 102/200\n",
      "426/426 - 1s - loss: 0.3185 - accuracy: 0.8897 - precision: 0.9091 - recall: 0.8685 - val_loss: 0.8572 - val_accuracy: 0.6972 - val_precision: 0.7132 - val_recall: 0.6831\n",
      "Epoch 103/200\n",
      "426/426 - 1s - loss: 0.2933 - accuracy: 0.9014 - precision: 0.9173 - recall: 0.8850 - val_loss: 0.8262 - val_accuracy: 0.7535 - val_precision: 0.7687 - val_recall: 0.7254\n",
      "Epoch 104/200\n",
      "426/426 - 1s - loss: 0.2907 - accuracy: 0.9155 - precision: 0.9195 - recall: 0.8850 - val_loss: 0.9411 - val_accuracy: 0.6972 - val_precision: 0.7037 - val_recall: 0.6690\n",
      "Epoch 105/200\n",
      "426/426 - 1s - loss: 0.3059 - accuracy: 0.8967 - precision: 0.9165 - recall: 0.8756 - val_loss: 0.8760 - val_accuracy: 0.7394 - val_precision: 0.7537 - val_recall: 0.7113\n",
      "Epoch 106/200\n",
      "426/426 - 1s - loss: 0.2945 - accuracy: 0.9085 - precision: 0.9148 - recall: 0.8826 - val_loss: 0.8173 - val_accuracy: 0.7746 - val_precision: 0.8000 - val_recall: 0.7606\n",
      "Epoch 107/200\n",
      "426/426 - 1s - loss: 0.3491 - accuracy: 0.8897 - precision: 0.9010 - recall: 0.8756 - val_loss: 0.9812 - val_accuracy: 0.6831 - val_precision: 0.6906 - val_recall: 0.6761\n",
      "Epoch 108/200\n",
      "426/426 - 1s - loss: 0.4116 - accuracy: 0.8592 - precision: 0.8837 - recall: 0.8380 - val_loss: 1.0137 - val_accuracy: 0.6690 - val_precision: 0.6884 - val_recall: 0.6690\n",
      "Epoch 109/200\n",
      "426/426 - 1s - loss: 0.3207 - accuracy: 0.8897 - precision: 0.9053 - recall: 0.8756 - val_loss: 1.1250 - val_accuracy: 0.6268 - val_precision: 0.6471 - val_recall: 0.6197\n",
      "Epoch 110/200\n",
      "426/426 - 1s - loss: 0.3443 - accuracy: 0.8826 - precision: 0.8932 - recall: 0.8638 - val_loss: 0.9244 - val_accuracy: 0.6690 - val_precision: 0.6763 - val_recall: 0.6620\n",
      "Epoch 111/200\n",
      "426/426 - 1s - loss: 0.3338 - accuracy: 0.8732 - precision: 0.8900 - recall: 0.8545 - val_loss: 0.7378 - val_accuracy: 0.7535 - val_precision: 0.7895 - val_recall: 0.7394\n",
      "Epoch 112/200\n",
      "426/426 - 1s - loss: 0.3447 - accuracy: 0.8850 - precision: 0.9012 - recall: 0.8779 - val_loss: 0.8658 - val_accuracy: 0.7113 - val_precision: 0.7293 - val_recall: 0.6831\n",
      "Epoch 113/200\n",
      "426/426 - 1s - loss: 0.2950 - accuracy: 0.8967 - precision: 0.9235 - recall: 0.8779 - val_loss: 0.8446 - val_accuracy: 0.6972 - val_precision: 0.7239 - val_recall: 0.6831\n",
      "Epoch 114/200\n",
      "426/426 - 1s - loss: 0.2661 - accuracy: 0.9202 - precision: 0.9279 - recall: 0.9061 - val_loss: 0.8474 - val_accuracy: 0.7394 - val_precision: 0.7591 - val_recall: 0.7324\n",
      "Epoch 115/200\n",
      "426/426 - 1s - loss: 0.2246 - accuracy: 0.9366 - precision: 0.9400 - recall: 0.9202 - val_loss: 0.8695 - val_accuracy: 0.7113 - val_precision: 0.7444 - val_recall: 0.6972\n",
      "Epoch 116/200\n",
      "426/426 - 1s - loss: 0.2405 - accuracy: 0.9202 - precision: 0.9282 - recall: 0.9108 - val_loss: 0.8009 - val_accuracy: 0.7183 - val_precision: 0.7299 - val_recall: 0.7042\n",
      "Epoch 117/200\n",
      "426/426 - 1s - loss: 0.2172 - accuracy: 0.9319 - precision: 0.9357 - recall: 0.9225 - val_loss: 0.9562 - val_accuracy: 0.6901 - val_precision: 0.7185 - val_recall: 0.6831\n",
      "Epoch 118/200\n",
      "426/426 - 1s - loss: 0.3082 - accuracy: 0.8944 - precision: 0.9036 - recall: 0.8803 - val_loss: 0.9575 - val_accuracy: 0.6690 - val_precision: 0.6838 - val_recall: 0.6549\n",
      "Epoch 119/200\n",
      "426/426 - 1s - loss: 0.3875 - accuracy: 0.8545 - precision: 0.8671 - recall: 0.8427 - val_loss: 1.0364 - val_accuracy: 0.6620 - val_precision: 0.6894 - val_recall: 0.6408\n",
      "Epoch 120/200\n",
      "426/426 - 1s - loss: 0.2819 - accuracy: 0.8991 - precision: 0.9165 - recall: 0.8756 - val_loss: 1.0344 - val_accuracy: 0.6690 - val_precision: 0.6842 - val_recall: 0.6408\n",
      "Epoch 121/200\n",
      "426/426 - 1s - loss: 0.2656 - accuracy: 0.9038 - precision: 0.9084 - recall: 0.8850 - val_loss: 0.7581 - val_accuracy: 0.7394 - val_precision: 0.7612 - val_recall: 0.7183\n",
      "Epoch 122/200\n",
      "426/426 - 1s - loss: 0.2182 - accuracy: 0.9343 - precision: 0.9406 - recall: 0.9296 - val_loss: 0.9214 - val_accuracy: 0.7042 - val_precision: 0.7313 - val_recall: 0.6901\n",
      "Epoch 123/200\n",
      "426/426 - 1s - loss: 0.2332 - accuracy: 0.9249 - precision: 0.9327 - recall: 0.9108 - val_loss: 0.7395 - val_accuracy: 0.7676 - val_precision: 0.8045 - val_recall: 0.7535\n",
      "Epoch 124/200\n",
      "426/426 - 1s - loss: 0.2772 - accuracy: 0.9061 - precision: 0.9121 - recall: 0.9014 - val_loss: 0.8846 - val_accuracy: 0.7394 - val_precision: 0.7447 - val_recall: 0.7394\n",
      "Epoch 125/200\n",
      "426/426 - 1s - loss: 0.2550 - accuracy: 0.9178 - precision: 0.9212 - recall: 0.9061 - val_loss: 0.8841 - val_accuracy: 0.7113 - val_precision: 0.7353 - val_recall: 0.7042\n",
      "Epoch 126/200\n",
      "426/426 - 1s - loss: 0.2462 - accuracy: 0.9085 - precision: 0.9249 - recall: 0.8967 - val_loss: 0.7917 - val_accuracy: 0.7746 - val_precision: 0.7868 - val_recall: 0.7535\n",
      "Epoch 127/200\n",
      "426/426 - 1s - loss: 0.3942 - accuracy: 0.8592 - precision: 0.8726 - recall: 0.8521 - val_loss: 1.0018 - val_accuracy: 0.6901 - val_precision: 0.6978 - val_recall: 0.6831\n",
      "Epoch 128/200\n",
      "426/426 - 1s - loss: 0.3431 - accuracy: 0.8779 - precision: 0.8822 - recall: 0.8615 - val_loss: 0.7876 - val_accuracy: 0.7606 - val_precision: 0.7687 - val_recall: 0.7254\n",
      "Epoch 129/200\n",
      "426/426 - 1s - loss: 0.2670 - accuracy: 0.9085 - precision: 0.9179 - recall: 0.8920 - val_loss: 0.9028 - val_accuracy: 0.7254 - val_precision: 0.7357 - val_recall: 0.7254\n",
      "Epoch 130/200\n",
      "426/426 - 1s - loss: 0.2561 - accuracy: 0.9108 - precision: 0.9119 - recall: 0.8991 - val_loss: 0.8695 - val_accuracy: 0.6972 - val_precision: 0.7174 - val_recall: 0.6972\n",
      "Epoch 131/200\n",
      "426/426 - 1s - loss: 0.4433 - accuracy: 0.8615 - precision: 0.8816 - recall: 0.8568 - val_loss: 0.9508 - val_accuracy: 0.6831 - val_precision: 0.7037 - val_recall: 0.6690\n",
      "Epoch 132/200\n",
      "426/426 - 1s - loss: 0.3473 - accuracy: 0.8920 - precision: 0.9069 - recall: 0.8685 - val_loss: 0.8788 - val_accuracy: 0.7606 - val_precision: 0.7609 - val_recall: 0.7394\n",
      "Epoch 133/200\n",
      "426/426 - 1s - loss: 0.3443 - accuracy: 0.8826 - precision: 0.8854 - recall: 0.8709 - val_loss: 0.8874 - val_accuracy: 0.7254 - val_precision: 0.7266 - val_recall: 0.7113\n",
      "Epoch 134/200\n",
      "426/426 - 1s - loss: 0.3595 - accuracy: 0.8756 - precision: 0.9012 - recall: 0.8568 - val_loss: 0.8019 - val_accuracy: 0.7606 - val_precision: 0.7754 - val_recall: 0.7535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/200\n",
      "426/426 - 1s - loss: 0.4687 - accuracy: 0.8239 - precision: 0.8390 - recall: 0.8075 - val_loss: 1.0380 - val_accuracy: 0.6901 - val_precision: 0.7029 - val_recall: 0.6831\n",
      "Epoch 136/200\n",
      "426/426 - 1s - loss: 0.3692 - accuracy: 0.8803 - precision: 0.8832 - recall: 0.8521 - val_loss: 0.9200 - val_accuracy: 0.6831 - val_precision: 0.7068 - val_recall: 0.6620\n",
      "Epoch 137/200\n",
      "426/426 - 1s - loss: 0.3423 - accuracy: 0.8779 - precision: 0.8846 - recall: 0.8638 - val_loss: 0.7519 - val_accuracy: 0.7324 - val_precision: 0.7481 - val_recall: 0.7113\n",
      "Epoch 138/200\n",
      "426/426 - 1s - loss: 0.2915 - accuracy: 0.8967 - precision: 0.9043 - recall: 0.8873 - val_loss: 0.7636 - val_accuracy: 0.7676 - val_precision: 0.7794 - val_recall: 0.7465\n",
      "Epoch 139/200\n",
      "426/426 - 1s - loss: 0.2058 - accuracy: 0.9366 - precision: 0.9405 - recall: 0.9272 - val_loss: 0.9155 - val_accuracy: 0.6831 - val_precision: 0.7176 - val_recall: 0.6620\n",
      "Epoch 140/200\n",
      "426/426 - 1s - loss: 0.3039 - accuracy: 0.8803 - precision: 0.8884 - recall: 0.8779 - val_loss: 0.9013 - val_accuracy: 0.7254 - val_precision: 0.7426 - val_recall: 0.7113\n",
      "Epoch 141/200\n",
      "426/426 - 1s - loss: 0.2616 - accuracy: 0.9155 - precision: 0.9270 - recall: 0.8944 - val_loss: 0.8470 - val_accuracy: 0.7183 - val_precision: 0.7481 - val_recall: 0.7113\n",
      "Epoch 142/200\n",
      "426/426 - 1s - loss: 0.2761 - accuracy: 0.9061 - precision: 0.9205 - recall: 0.8967 - val_loss: 0.9183 - val_accuracy: 0.7183 - val_precision: 0.7444 - val_recall: 0.6972\n",
      "Epoch 143/200\n",
      "426/426 - 1s - loss: 0.2068 - accuracy: 0.9366 - precision: 0.9447 - recall: 0.9225 - val_loss: 0.7787 - val_accuracy: 0.7324 - val_precision: 0.7630 - val_recall: 0.7254\n",
      "Epoch 144/200\n",
      "426/426 - 1s - loss: 0.1733 - accuracy: 0.9460 - precision: 0.9482 - recall: 0.9460 - val_loss: 0.8210 - val_accuracy: 0.7465 - val_precision: 0.7554 - val_recall: 0.7394\n",
      "Epoch 145/200\n",
      "426/426 - 1s - loss: 0.1589 - accuracy: 0.9554 - precision: 0.9568 - recall: 0.9366 - val_loss: 0.8462 - val_accuracy: 0.7394 - val_precision: 0.7554 - val_recall: 0.7394\n",
      "Epoch 146/200\n",
      "426/426 - 1s - loss: 0.1366 - accuracy: 0.9507 - precision: 0.9595 - recall: 0.9460 - val_loss: 0.8386 - val_accuracy: 0.7254 - val_precision: 0.7338 - val_recall: 0.7183\n",
      "Epoch 147/200\n",
      "426/426 - 1s - loss: 0.1300 - accuracy: 0.9601 - precision: 0.9596 - recall: 0.9484 - val_loss: 0.7954 - val_accuracy: 0.7676 - val_precision: 0.7794 - val_recall: 0.7465\n",
      "Epoch 148/200\n",
      "426/426 - 1s - loss: 0.1429 - accuracy: 0.9554 - precision: 0.9643 - recall: 0.9507 - val_loss: 0.8267 - val_accuracy: 0.7394 - val_precision: 0.7574 - val_recall: 0.7254\n",
      "Epoch 149/200\n",
      "426/426 - 1s - loss: 0.1346 - accuracy: 0.9507 - precision: 0.9592 - recall: 0.9390 - val_loss: 0.8285 - val_accuracy: 0.7324 - val_precision: 0.7536 - val_recall: 0.7324\n",
      "Epoch 150/200\n",
      "426/426 - 1s - loss: 0.1158 - accuracy: 0.9695 - precision: 0.9715 - recall: 0.9601 - val_loss: 0.8874 - val_accuracy: 0.7394 - val_precision: 0.7554 - val_recall: 0.7394\n",
      "Epoch 151/200\n",
      "426/426 - 1s - loss: 0.1282 - accuracy: 0.9624 - precision: 0.9714 - recall: 0.9577 - val_loss: 0.8830 - val_accuracy: 0.7113 - val_precision: 0.7246 - val_recall: 0.7042\n",
      "Epoch 152/200\n",
      "426/426 - 1s - loss: 0.1013 - accuracy: 0.9765 - precision: 0.9764 - recall: 0.9695 - val_loss: 1.0028 - val_accuracy: 0.7113 - val_precision: 0.7174 - val_recall: 0.6972\n",
      "Epoch 153/200\n",
      "426/426 - 1s - loss: 0.1824 - accuracy: 0.9413 - precision: 0.9477 - recall: 0.9366 - val_loss: 0.8434 - val_accuracy: 0.7394 - val_precision: 0.7630 - val_recall: 0.7254\n",
      "Epoch 154/200\n",
      "426/426 - 1s - loss: 0.2017 - accuracy: 0.9319 - precision: 0.9336 - recall: 0.9249 - val_loss: 0.7988 - val_accuracy: 0.7113 - val_precision: 0.7299 - val_recall: 0.7042\n",
      "Epoch 155/200\n",
      "426/426 - 1s - loss: 0.3055 - accuracy: 0.9038 - precision: 0.9201 - recall: 0.8920 - val_loss: 0.8843 - val_accuracy: 0.7113 - val_precision: 0.7500 - val_recall: 0.6972\n",
      "Epoch 156/200\n",
      "426/426 - 1s - loss: 0.2410 - accuracy: 0.9038 - precision: 0.9227 - recall: 0.8967 - val_loss: 0.8729 - val_accuracy: 0.7113 - val_precision: 0.7293 - val_recall: 0.6831\n",
      "Epoch 157/200\n",
      "426/426 - 1s - loss: 0.2497 - accuracy: 0.9131 - precision: 0.9258 - recall: 0.9085 - val_loss: 0.7694 - val_accuracy: 0.7746 - val_precision: 0.7868 - val_recall: 0.7535\n",
      "Epoch 158/200\n",
      "426/426 - 1s - loss: 0.2123 - accuracy: 0.9225 - precision: 0.9279 - recall: 0.9061 - val_loss: 0.9164 - val_accuracy: 0.7606 - val_precision: 0.7647 - val_recall: 0.7324\n",
      "Epoch 159/200\n",
      "426/426 - 1s - loss: 0.1443 - accuracy: 0.9554 - precision: 0.9642 - recall: 0.9484 - val_loss: 0.8853 - val_accuracy: 0.7465 - val_precision: 0.7609 - val_recall: 0.7394\n",
      "Epoch 160/200\n",
      "426/426 - 1s - loss: 0.1262 - accuracy: 0.9531 - precision: 0.9597 - recall: 0.9507 - val_loss: 0.8408 - val_accuracy: 0.7606 - val_precision: 0.7664 - val_recall: 0.7394\n",
      "Epoch 161/200\n",
      "426/426 - 1s - loss: 0.1167 - accuracy: 0.9624 - precision: 0.9645 - recall: 0.9577 - val_loss: 0.8187 - val_accuracy: 0.7535 - val_precision: 0.7836 - val_recall: 0.7394\n",
      "Epoch 162/200\n",
      "426/426 - 1s - loss: 0.1334 - accuracy: 0.9460 - precision: 0.9525 - recall: 0.9413 - val_loss: 0.8095 - val_accuracy: 0.7676 - val_precision: 0.7770 - val_recall: 0.7606\n",
      "Epoch 163/200\n",
      "426/426 - 1s - loss: 0.1163 - accuracy: 0.9601 - precision: 0.9714 - recall: 0.9554 - val_loss: 0.8677 - val_accuracy: 0.7606 - val_precision: 0.7810 - val_recall: 0.7535\n",
      "Epoch 164/200\n",
      "426/426 - 1s - loss: 0.0924 - accuracy: 0.9695 - precision: 0.9764 - recall: 0.9695 - val_loss: 0.8078 - val_accuracy: 0.7817 - val_precision: 0.7842 - val_recall: 0.7676\n",
      "Epoch 165/200\n",
      "426/426 - 1s - loss: 0.1018 - accuracy: 0.9624 - precision: 0.9738 - recall: 0.9601 - val_loss: 0.7635 - val_accuracy: 0.7887 - val_precision: 0.8058 - val_recall: 0.7887\n",
      "Epoch 166/200\n",
      "426/426 - 1s - loss: 0.0751 - accuracy: 0.9859 - precision: 0.9882 - recall: 0.9836 - val_loss: 0.7418 - val_accuracy: 0.7887 - val_precision: 0.8116 - val_recall: 0.7887\n",
      "Epoch 167/200\n",
      "426/426 - 1s - loss: 0.0638 - accuracy: 0.9883 - precision: 0.9906 - recall: 0.9859 - val_loss: 0.7357 - val_accuracy: 0.7887 - val_precision: 0.7971 - val_recall: 0.7746\n",
      "Epoch 168/200\n",
      "426/426 - 1s - loss: 0.0757 - accuracy: 0.9789 - precision: 0.9835 - recall: 0.9765 - val_loss: 0.7370 - val_accuracy: 0.7887 - val_precision: 0.8058 - val_recall: 0.7887\n",
      "Epoch 169/200\n",
      "426/426 - 1s - loss: 0.0731 - accuracy: 0.9789 - precision: 0.9834 - recall: 0.9742 - val_loss: 0.7658 - val_accuracy: 0.7887 - val_precision: 0.8043 - val_recall: 0.7817\n",
      "Epoch 170/200\n",
      "426/426 - 1s - loss: 0.0624 - accuracy: 0.9883 - precision: 0.9953 - recall: 0.9883 - val_loss: 0.7531 - val_accuracy: 0.8028 - val_precision: 0.8209 - val_recall: 0.7746\n",
      "Epoch 171/200\n",
      "426/426 - 1s - loss: 0.0625 - accuracy: 0.9906 - precision: 0.9906 - recall: 0.9859 - val_loss: 0.8063 - val_accuracy: 0.7535 - val_precision: 0.7681 - val_recall: 0.7465\n",
      "Epoch 172/200\n",
      "426/426 - 1s - loss: 0.0733 - accuracy: 0.9836 - precision: 0.9835 - recall: 0.9812 - val_loss: 0.7805 - val_accuracy: 0.7958 - val_precision: 0.8129 - val_recall: 0.7958\n",
      "Epoch 173/200\n",
      "426/426 - 1s - loss: 0.0549 - accuracy: 0.9883 - precision: 0.9882 - recall: 0.9859 - val_loss: 0.7453 - val_accuracy: 0.8028 - val_precision: 0.8188 - val_recall: 0.7958\n",
      "Epoch 174/200\n",
      "426/426 - 1s - loss: 0.0540 - accuracy: 0.9859 - precision: 0.9859 - recall: 0.9836 - val_loss: 0.7470 - val_accuracy: 0.8099 - val_precision: 0.8201 - val_recall: 0.8028\n",
      "Epoch 175/200\n",
      "426/426 - 1s - loss: 0.0494 - accuracy: 0.9930 - precision: 0.9929 - recall: 0.9883 - val_loss: 0.7280 - val_accuracy: 0.7887 - val_precision: 0.8000 - val_recall: 0.7887\n",
      "Epoch 176/200\n",
      "426/426 - 1s - loss: 0.0568 - accuracy: 0.9836 - precision: 0.9835 - recall: 0.9812 - val_loss: 0.7806 - val_accuracy: 0.7958 - val_precision: 0.8000 - val_recall: 0.7887\n",
      "Epoch 177/200\n",
      "426/426 - 1s - loss: 0.0454 - accuracy: 0.9883 - precision: 0.9882 - recall: 0.9836 - val_loss: 0.7450 - val_accuracy: 0.7817 - val_precision: 0.7914 - val_recall: 0.7746\n",
      "Epoch 178/200\n",
      "426/426 - 1s - loss: 0.0627 - accuracy: 0.9859 - precision: 0.9859 - recall: 0.9836 - val_loss: 0.8220 - val_accuracy: 0.8028 - val_precision: 0.8071 - val_recall: 0.7958\n",
      "Epoch 179/200\n",
      "426/426 - 1s - loss: 0.1743 - accuracy: 0.9484 - precision: 0.9481 - recall: 0.9437 - val_loss: 0.9417 - val_accuracy: 0.7394 - val_precision: 0.7536 - val_recall: 0.7324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/200\n",
      "426/426 - 1s - loss: 0.2447 - accuracy: 0.9249 - precision: 0.9238 - recall: 0.9108 - val_loss: 1.0409 - val_accuracy: 0.7183 - val_precision: 0.7319 - val_recall: 0.7113\n",
      "Epoch 181/200\n",
      "426/426 - 1s - loss: 0.2418 - accuracy: 0.8991 - precision: 0.9233 - recall: 0.8756 - val_loss: 1.0065 - val_accuracy: 0.7183 - val_precision: 0.7481 - val_recall: 0.7113\n",
      "Epoch 182/200\n",
      "426/426 - 1s - loss: 0.1991 - accuracy: 0.9225 - precision: 0.9327 - recall: 0.9108 - val_loss: 0.9117 - val_accuracy: 0.7606 - val_precision: 0.7770 - val_recall: 0.7606\n",
      "Epoch 183/200\n",
      "426/426 - 1s - loss: 0.1075 - accuracy: 0.9577 - precision: 0.9668 - recall: 0.9577 - val_loss: 0.8826 - val_accuracy: 0.7676 - val_precision: 0.7794 - val_recall: 0.7465\n",
      "Epoch 184/200\n",
      "426/426 - 1s - loss: 0.1701 - accuracy: 0.9390 - precision: 0.9455 - recall: 0.9366 - val_loss: 0.8796 - val_accuracy: 0.7958 - val_precision: 0.8000 - val_recall: 0.7887\n",
      "Epoch 185/200\n",
      "426/426 - 1s - loss: 0.1589 - accuracy: 0.9460 - precision: 0.9525 - recall: 0.9413 - val_loss: 0.8569 - val_accuracy: 0.7676 - val_precision: 0.8000 - val_recall: 0.7606\n",
      "Epoch 186/200\n",
      "426/426 - 1s - loss: 0.1012 - accuracy: 0.9671 - precision: 0.9785 - recall: 0.9624 - val_loss: 0.8454 - val_accuracy: 0.7746 - val_precision: 0.7971 - val_recall: 0.7746\n",
      "Epoch 187/200\n",
      "426/426 - 1s - loss: 0.0744 - accuracy: 0.9836 - precision: 0.9835 - recall: 0.9812 - val_loss: 0.9128 - val_accuracy: 0.7887 - val_precision: 0.7857 - val_recall: 0.7746\n",
      "Epoch 188/200\n",
      "426/426 - 1s - loss: 0.1092 - accuracy: 0.9624 - precision: 0.9716 - recall: 0.9624 - val_loss: 0.8871 - val_accuracy: 0.7958 - val_precision: 0.7971 - val_recall: 0.7746\n",
      "Epoch 189/200\n",
      "426/426 - 1s - loss: 0.1028 - accuracy: 0.9695 - precision: 0.9717 - recall: 0.9671 - val_loss: 0.9030 - val_accuracy: 0.7324 - val_precision: 0.7500 - val_recall: 0.7183\n",
      "Epoch 190/200\n",
      "426/426 - 1s - loss: 0.1262 - accuracy: 0.9718 - precision: 0.9741 - recall: 0.9695 - val_loss: 0.9096 - val_accuracy: 0.7746 - val_precision: 0.7883 - val_recall: 0.7606\n",
      "Epoch 191/200\n",
      "426/426 - 1s - loss: 0.0995 - accuracy: 0.9742 - precision: 0.9787 - recall: 0.9718 - val_loss: 0.8954 - val_accuracy: 0.7606 - val_precision: 0.7609 - val_recall: 0.7394\n",
      "Epoch 192/200\n",
      "426/426 - 1s - loss: 0.0674 - accuracy: 0.9883 - precision: 0.9906 - recall: 0.9859 - val_loss: 0.8639 - val_accuracy: 0.7606 - val_precision: 0.7810 - val_recall: 0.7535\n",
      "Epoch 193/200\n",
      "426/426 - 1s - loss: 0.0583 - accuracy: 0.9930 - precision: 0.9953 - recall: 0.9930 - val_loss: 0.8492 - val_accuracy: 0.7746 - val_precision: 0.8000 - val_recall: 0.7606\n",
      "Epoch 194/200\n",
      "426/426 - 1s - loss: 0.0384 - accuracy: 0.9953 - precision: 0.9953 - recall: 0.9953 - val_loss: 0.8986 - val_accuracy: 0.7746 - val_precision: 0.7956 - val_recall: 0.7676\n",
      "Epoch 195/200\n",
      "426/426 - 1s - loss: 0.0615 - accuracy: 0.9859 - precision: 0.9882 - recall: 0.9812 - val_loss: 0.7590 - val_accuracy: 0.7887 - val_precision: 0.7986 - val_recall: 0.7817\n",
      "Epoch 196/200\n",
      "426/426 - 1s - loss: 0.0362 - accuracy: 0.9930 - precision: 0.9953 - recall: 0.9906 - val_loss: 0.8180 - val_accuracy: 0.7817 - val_precision: 0.7872 - val_recall: 0.7817\n",
      "Epoch 197/200\n",
      "426/426 - 1s - loss: 0.0274 - accuracy: 0.9977 - precision: 0.9976 - recall: 0.9953 - val_loss: 0.7905 - val_accuracy: 0.8028 - val_precision: 0.8143 - val_recall: 0.8028\n",
      "Epoch 198/200\n",
      "426/426 - 1s - loss: 0.0235 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7699 - val_accuracy: 0.8099 - val_precision: 0.8214 - val_recall: 0.8099\n",
      "Epoch 199/200\n",
      "426/426 - 1s - loss: 0.0213 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7731 - val_accuracy: 0.8169 - val_precision: 0.8214 - val_recall: 0.8099\n",
      "Epoch 200/200\n",
      "426/426 - 1s - loss: 0.0201 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7763 - val_accuracy: 0.8169 - val_precision: 0.8214 - val_recall: 0.8099\n"
     ]
    }
   ],
   "source": [
    "#tmp_chekpoints= \"tmp\\epoch{epoch:02d}-{val_accuracy:.2f}-{val_loss:.2f}.hdf5\"\n",
    "#tmp_chekpoints= \"C:\\\\ML\\\\checkpoints\\\\tmp\\\\epoch{epoch:02d}-{val_accuracy:.2f}-{val_loss:.2f}.hdf5\"\n",
    "tmp_chekpoints= \"C:\\\\ML\\\\checkpoints\\\\tmp\\\\epoch{epoch:02d}-{val_accuracy:.2f}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "#csv_log = tf.keras.callbacks.CSVLogger(\"log.csv\", separator=',', append=False)\n",
    "csv_log = tf.keras.callbacks.CSVLogger(\"C:\\\\ML\\\\logs\\\\log.csv\", separator=',', append=False)\n",
    "\n",
    "#tb = tf.keras.callbacks.TensorBoard(log_dir='logs', histogram_freq=1, write_graph=False, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=1, embeddings_metadata=None)\n",
    "tb = tf.keras.callbacks.TensorBoard(log_dir='C:\\ML\\logs', histogram_freq=1, write_graph=False, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=1, embeddings_metadata=None)\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=20, verbose=0, mode='max', baseline=None, restore_best_weights=True)\n",
    "chk= tf.keras.callbacks.ModelCheckpoint(tmp_chekpoints, monitor='val_accuracy', verbose=0, save_best_only=False, save_weights_only=False, mode='max', save_freq='epoch')\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, min_delta=0.1, patience=5, min_lr=0.001)\n",
    "\n",
    "history = bestmodel.fit(x_train,y_train,epochs=200,batch_size=32, validation_data=(x_val,y_val),shuffle=False, verbose=2, callbacks=[csv_log, chk,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Adamax', 'learning_rate': 0.001, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07}\n"
     ]
    }
   ],
   "source": [
    "print(bestmodel.optimizer.get_config())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training history of your LSTM models can be used to diagnose the behavior of your model.\n",
    "\n",
    "You can plot the performance of your model using the Matplotlib library. For example, you can plot training loss vs test loss as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.savefig(\"C:/ML/loss\"f\"{starttime}.png\")\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.plot(history.history['accuracy'])\n",
    "pyplot.plot(history.history['val_accuracy'])\n",
    "pyplot.title('model train vs validation accuracy')\n",
    "pyplot.ylabel('accuracy')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='lower right')\n",
    "pyplot.savefig(\"C:/ML/accuracy_\"f\"{starttime}.png\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Underfit Example\n",
    "Running this example produces a plot of train and validation loss showing the characteristic of an underfit model. In this case, performance may be improved by increasing the number of training epochs.\n",
    "\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-an-Underfit-Model.png\" width=\"400\">\n",
    "\n",
    "\n",
    "Running this example shows the characteristic of an underfit model that appears under-provisioned.\n",
    "In this case, performance may be improved by increasing the capacity of the model, such as the number of memory cells in a hidden layer or number of hidden layers.\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-an-Underfit-Model-via-Status.png\" width=\"400\">\n",
    "\n",
    "#### Good Fit Example\n",
    "Running the example creates a line plot showing the train and validation loss meeting.\n",
    "Ideally, we would like to see model performance like this if possible, although this may not be possible on challenging problems with a lot of data.\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-a-Good-Fit-for-a-Model.png\" width=\"400\">\n",
    "\n",
    "#### Overfit Example\n",
    "Running this example creates a plot showing the characteristic inflection point in validation loss of an overfit model.\n",
    "This may be a sign of too many training epochs.\n",
    "In this case, the model training could be stopped at the inflection point. Alternately, the number of training examples could be increased.\n",
    "\n",
    "<img src=\"assets/Diagnostic-Line-Plot-Showing-an-Overfit-Model.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model('./tmp/epoch49-0.90-0.39.hdf5')\n",
    "\n",
    "\n",
    "#bestmodel.evaluate(x=x_test, y=y_test, verbose=2)\n",
    "model.evaluate(x=x_test, y=y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodel.save(\"sign_lang_recognition_tuned.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
